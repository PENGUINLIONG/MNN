// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_MNN_MNN_H_
#define FLATBUFFERS_GENERATED_MNN_MNN_H_

#include "flatbuffers/flatbuffers.h"

#include "CaffeOp_generated.h"
#include "GpuLibrary_generated.h"
#include "TFQuantizeOp_generated.h"
#include "Tensor_generated.h"
#include "TensorflowOp_generated.h"
#include "Type_generated.h"
#include "UserDefine_generated.h"

namespace MNN {

struct Plugin;
struct PluginBuilder;
struct PluginT;

struct Extra;
struct ExtraBuilder;
struct ExtraT;

struct StringVec;
struct StringVecBuilder;
struct StringVecT;

struct WhileParam;
struct WhileParamBuilder;
struct WhileParamT;

struct IfParam;
struct IfParamBuilder;
struct IfParamT;

struct Op;
struct OpBuilder;
struct OpT;

struct View;
struct ViewBuilder;
struct ViewT;

struct Region;
struct RegionBuilder;
struct RegionT;

struct TensorDescribe;
struct TensorDescribeBuilder;
struct TensorDescribeT;

struct SubGraphProto;
struct SubGraphProtoBuilder;
struct SubGraphProtoT;

struct TensorQuantInfo;
struct TensorQuantInfoBuilder;
struct TensorQuantInfoT;

struct Net;
struct NetBuilder;
struct NetT;

inline const flatbuffers::TypeTable *PluginTypeTable();

inline const flatbuffers::TypeTable *ExtraTypeTable();

inline const flatbuffers::TypeTable *StringVecTypeTable();

inline const flatbuffers::TypeTable *WhileParamTypeTable();

inline const flatbuffers::TypeTable *IfParamTypeTable();

inline const flatbuffers::TypeTable *OpTypeTable();

inline const flatbuffers::TypeTable *ViewTypeTable();

inline const flatbuffers::TypeTable *RegionTypeTable();

inline const flatbuffers::TypeTable *TensorDescribeTypeTable();

inline const flatbuffers::TypeTable *SubGraphProtoTypeTable();

inline const flatbuffers::TypeTable *TensorQuantInfoTypeTable();

inline const flatbuffers::TypeTable *NetTypeTable();

enum OpType {
  OpType_AbsVal = 0,
  OpType_QuantizedAdd = 1,
  OpType_ArgMax = 2,
  OpType_AsString = 3,
  OpType_InstanceNorm = 4,
  OpType_BatchToSpaceND = 5,
  OpType_Bias = 6,
  OpType_BinaryOp = 7,
  OpType_Bnll = 8,
  OpType_Cast = 9,
  OpType_Concat = 10,
  OpType_Const = 11,
  OpType_Convolution = 12,
  OpType_ConvolutionDepthwise = 13,
  OpType_Crop = 14,
  OpType_CropAndResize = 15,
  OpType_Cubic = 16,
  OpType_Deconvolution = 17,
  OpType_DeconvolutionDepthwise = 18,
  OpType_Dequantize = 19,
  OpType_DetectionOutput = 20,
  OpType_Dropout = 21,
  OpType_Eltwise = 22,
  OpType_ELU = 23,
  OpType_Embed = 24,
  OpType_Exp = 25,
  OpType_ExpandDims = 26,
  OpType_Fill = 27,
  OpType_Flatten = 28,
  OpType_FloorMod = 29,
  OpType_Gather = 30,
  OpType_GatherV2 = 31,
  OpType_Im2Seq = 32,
  OpType_InnerProduct = 33,
  OpType_Input = 34,
  OpType_Interp = 35,
  OpType_Log = 36,
  OpType_LRN = 37,
  OpType_LSTM = 38,
  OpType_MatMul = 39,
  OpType_MVN = 40,
  OpType_NonMaxSuppression = 41,
  OpType_NonMaxSuppressionV2 = 42,
  OpType_Normalize = 43,
  OpType_Pack = 44,
  OpType_Padding = 45,
  OpType_Permute = 46,
  OpType_Pooling = 47,
  OpType_Power = 48,
  OpType_PReLU = 49,
  OpType_PriorBox = 50,
  OpType_Proposal = 51,
  OpType_QuantizedAvgPool = 52,
  OpType_QuantizedBiasAdd = 53,
  OpType_QuantizedConcat = 54,
  OpType_QuantizedDepthwiseConv2D = 55,
  OpType_QuantizedLogistic = 56,
  OpType_QuantizedMatMul = 57,
  OpType_QuantizedMaxPool = 58,
  OpType_QuantizedRelu = 59,
  OpType_QuantizedRelu6 = 60,
  OpType_QuantizedReshape = 61,
  OpType_QuantizedSoftmax = 62,
  OpType_QuantizeMaxMin = 63,
  OpType_QuantizeV2 = 64,
  OpType_Range = 65,
  OpType_Rank = 66,
  OpType_ReduceJoin = 67,
  OpType_Reduction = 68,
  OpType_ReLU = 69,
  OpType_ReLU6 = 70,
  OpType_RequantizationRange = 71,
  OpType_Requantize = 72,
  OpType_Reshape = 73,
  OpType_Resize = 74,
  OpType_RNN = 75,
  OpType_ROIPooling = 76,
  OpType_Scale = 77,
  OpType_Selu = 78,
  OpType_Seq2Out = 79,
  OpType_Shape = 80,
  OpType_Sigmoid = 81,
  OpType_Size = 82,
  OpType_Slice = 83,
  OpType_SliceTf = 84,
  OpType_Softmax = 85,
  OpType_SpaceToBatchND = 86,
  OpType_SpatialProduct = 87,
  OpType_Split = 88,
  OpType_SPP = 89,
  OpType_Squeeze = 90,
  OpType_StridedSlice = 91,
  OpType_StringJoin = 92,
  OpType_StringSplit = 93,
  OpType_StringToNumber = 94,
  OpType_TanH = 95,
  OpType_TfQuantizedConv2D = 96,
  OpType_Threshold = 97,
  OpType_Tile = 98,
  OpType_TopKV2 = 99,
  OpType_Transpose = 100,
  OpType_UnaryOp = 101,
  OpType_Unpack = 102,
  OpType_Where = 103,
  OpType_Moments = 104,
  OpType_RNNSequenceGRU = 105,
  OpType_BatchMatMul = 106,
  OpType_Unsqueeze = 107,
  OpType_CosineSimilarity = 108,
  OpType_DepthToSpace = 109,
  OpType_SpaceToDepth = 110,
  OpType_ReverseSequence = 111,
  OpType_Pooling3D = 112,
  OpType_Convolution3D = 113,
  OpType_MatrixBandPart = 114,
  OpType_GatherND = 115,
  OpType_DetectionPostProcess = 116,
  OpType_UnravelIndex = 117,
  OpType_ScatterNd = 118,
  OpType_OneHot = 119,
  OpType_BroadcastTo = 120,
  OpType_Dilation2D = 121,
  OpType_Raster = 128,
  OpType_ConvertTensor = 129,
  OpType_ArgMin = 130,
  OpType_LinSpace = 131,
  OpType_RandomUniform = 132,
  OpType_TensorArray = 133,
  OpType_TensorArraySize = 134,
  OpType_TensorArrayRead = 135,
  OpType_TensorArrayWrite = 136,
  OpType_TensorArrayGather = 137,
  OpType_TensorArrayScatter = 138,
  OpType_TensorArraySplit = 139,
  OpType_TensorArrayConcat = 140,
  OpType_LSTMBlockCell = 141,
  OpType_Reverse = 142,
  OpType_Plugin = 256,
  OpType_Select = 257,
  OpType_ZerosLike = 258,
  OpType_Broastcast = 259,
  OpType_SetDiff1D = 260,
  OpType_ReluGrad = 261,
  OpType_Relu6Grad = 262,
  OpType_PoolGrad = 263,
  OpType_SoftmaxGrad = 264,
  OpType_Conv2DBackPropFilter = 265,
  OpType_TrainableParam = 266,
  OpType_BatchNorm = 267,
  OpType_ZeroGrad = 268,
  OpType_Extra = 512,
  OpType_ConvInt8 = 513,
  OpType_Int8ToFloat = 514,
  OpType_DepthwiseConvInt8 = 515,
  OpType_PoolInt8 = 516,
  OpType_FloatToInt8 = 517,
  OpType_EltwiseInt8 = 518,
  OpType_While = 600,
  OpType_If = 601,
  OpType_LayerNorm = 603,
  OpType_GridSample = 604,
  OpType_MIN = OpType_AbsVal,
  OpType_MAX = OpType_GridSample
};

inline const OpType (&EnumValuesOpType())[161] {
  static const OpType values[] = {
    OpType_AbsVal,
    OpType_QuantizedAdd,
    OpType_ArgMax,
    OpType_AsString,
    OpType_InstanceNorm,
    OpType_BatchToSpaceND,
    OpType_Bias,
    OpType_BinaryOp,
    OpType_Bnll,
    OpType_Cast,
    OpType_Concat,
    OpType_Const,
    OpType_Convolution,
    OpType_ConvolutionDepthwise,
    OpType_Crop,
    OpType_CropAndResize,
    OpType_Cubic,
    OpType_Deconvolution,
    OpType_DeconvolutionDepthwise,
    OpType_Dequantize,
    OpType_DetectionOutput,
    OpType_Dropout,
    OpType_Eltwise,
    OpType_ELU,
    OpType_Embed,
    OpType_Exp,
    OpType_ExpandDims,
    OpType_Fill,
    OpType_Flatten,
    OpType_FloorMod,
    OpType_Gather,
    OpType_GatherV2,
    OpType_Im2Seq,
    OpType_InnerProduct,
    OpType_Input,
    OpType_Interp,
    OpType_Log,
    OpType_LRN,
    OpType_LSTM,
    OpType_MatMul,
    OpType_MVN,
    OpType_NonMaxSuppression,
    OpType_NonMaxSuppressionV2,
    OpType_Normalize,
    OpType_Pack,
    OpType_Padding,
    OpType_Permute,
    OpType_Pooling,
    OpType_Power,
    OpType_PReLU,
    OpType_PriorBox,
    OpType_Proposal,
    OpType_QuantizedAvgPool,
    OpType_QuantizedBiasAdd,
    OpType_QuantizedConcat,
    OpType_QuantizedDepthwiseConv2D,
    OpType_QuantizedLogistic,
    OpType_QuantizedMatMul,
    OpType_QuantizedMaxPool,
    OpType_QuantizedRelu,
    OpType_QuantizedRelu6,
    OpType_QuantizedReshape,
    OpType_QuantizedSoftmax,
    OpType_QuantizeMaxMin,
    OpType_QuantizeV2,
    OpType_Range,
    OpType_Rank,
    OpType_ReduceJoin,
    OpType_Reduction,
    OpType_ReLU,
    OpType_ReLU6,
    OpType_RequantizationRange,
    OpType_Requantize,
    OpType_Reshape,
    OpType_Resize,
    OpType_RNN,
    OpType_ROIPooling,
    OpType_Scale,
    OpType_Selu,
    OpType_Seq2Out,
    OpType_Shape,
    OpType_Sigmoid,
    OpType_Size,
    OpType_Slice,
    OpType_SliceTf,
    OpType_Softmax,
    OpType_SpaceToBatchND,
    OpType_SpatialProduct,
    OpType_Split,
    OpType_SPP,
    OpType_Squeeze,
    OpType_StridedSlice,
    OpType_StringJoin,
    OpType_StringSplit,
    OpType_StringToNumber,
    OpType_TanH,
    OpType_TfQuantizedConv2D,
    OpType_Threshold,
    OpType_Tile,
    OpType_TopKV2,
    OpType_Transpose,
    OpType_UnaryOp,
    OpType_Unpack,
    OpType_Where,
    OpType_Moments,
    OpType_RNNSequenceGRU,
    OpType_BatchMatMul,
    OpType_Unsqueeze,
    OpType_CosineSimilarity,
    OpType_DepthToSpace,
    OpType_SpaceToDepth,
    OpType_ReverseSequence,
    OpType_Pooling3D,
    OpType_Convolution3D,
    OpType_MatrixBandPart,
    OpType_GatherND,
    OpType_DetectionPostProcess,
    OpType_UnravelIndex,
    OpType_ScatterNd,
    OpType_OneHot,
    OpType_BroadcastTo,
    OpType_Dilation2D,
    OpType_Raster,
    OpType_ConvertTensor,
    OpType_ArgMin,
    OpType_LinSpace,
    OpType_RandomUniform,
    OpType_TensorArray,
    OpType_TensorArraySize,
    OpType_TensorArrayRead,
    OpType_TensorArrayWrite,
    OpType_TensorArrayGather,
    OpType_TensorArrayScatter,
    OpType_TensorArraySplit,
    OpType_TensorArrayConcat,
    OpType_LSTMBlockCell,
    OpType_Reverse,
    OpType_Plugin,
    OpType_Select,
    OpType_ZerosLike,
    OpType_Broastcast,
    OpType_SetDiff1D,
    OpType_ReluGrad,
    OpType_Relu6Grad,
    OpType_PoolGrad,
    OpType_SoftmaxGrad,
    OpType_Conv2DBackPropFilter,
    OpType_TrainableParam,
    OpType_BatchNorm,
    OpType_ZeroGrad,
    OpType_Extra,
    OpType_ConvInt8,
    OpType_Int8ToFloat,
    OpType_DepthwiseConvInt8,
    OpType_PoolInt8,
    OpType_FloatToInt8,
    OpType_EltwiseInt8,
    OpType_While,
    OpType_If,
    OpType_LayerNorm,
    OpType_GridSample
  };
  return values;
}

inline const char * const *EnumNamesOpType() {
  static const char * const names[606] = {
    "AbsVal",
    "QuantizedAdd",
    "ArgMax",
    "AsString",
    "InstanceNorm",
    "BatchToSpaceND",
    "Bias",
    "BinaryOp",
    "Bnll",
    "Cast",
    "Concat",
    "Const",
    "Convolution",
    "ConvolutionDepthwise",
    "Crop",
    "CropAndResize",
    "Cubic",
    "Deconvolution",
    "DeconvolutionDepthwise",
    "Dequantize",
    "DetectionOutput",
    "Dropout",
    "Eltwise",
    "ELU",
    "Embed",
    "Exp",
    "ExpandDims",
    "Fill",
    "Flatten",
    "FloorMod",
    "Gather",
    "GatherV2",
    "Im2Seq",
    "InnerProduct",
    "Input",
    "Interp",
    "Log",
    "LRN",
    "LSTM",
    "MatMul",
    "MVN",
    "NonMaxSuppression",
    "NonMaxSuppressionV2",
    "Normalize",
    "Pack",
    "Padding",
    "Permute",
    "Pooling",
    "Power",
    "PReLU",
    "PriorBox",
    "Proposal",
    "QuantizedAvgPool",
    "QuantizedBiasAdd",
    "QuantizedConcat",
    "QuantizedDepthwiseConv2D",
    "QuantizedLogistic",
    "QuantizedMatMul",
    "QuantizedMaxPool",
    "QuantizedRelu",
    "QuantizedRelu6",
    "QuantizedReshape",
    "QuantizedSoftmax",
    "QuantizeMaxMin",
    "QuantizeV2",
    "Range",
    "Rank",
    "ReduceJoin",
    "Reduction",
    "ReLU",
    "ReLU6",
    "RequantizationRange",
    "Requantize",
    "Reshape",
    "Resize",
    "RNN",
    "ROIPooling",
    "Scale",
    "Selu",
    "Seq2Out",
    "Shape",
    "Sigmoid",
    "Size",
    "Slice",
    "SliceTf",
    "Softmax",
    "SpaceToBatchND",
    "SpatialProduct",
    "Split",
    "SPP",
    "Squeeze",
    "StridedSlice",
    "StringJoin",
    "StringSplit",
    "StringToNumber",
    "TanH",
    "TfQuantizedConv2D",
    "Threshold",
    "Tile",
    "TopKV2",
    "Transpose",
    "UnaryOp",
    "Unpack",
    "Where",
    "Moments",
    "RNNSequenceGRU",
    "BatchMatMul",
    "Unsqueeze",
    "CosineSimilarity",
    "DepthToSpace",
    "SpaceToDepth",
    "ReverseSequence",
    "Pooling3D",
    "Convolution3D",
    "MatrixBandPart",
    "GatherND",
    "DetectionPostProcess",
    "UnravelIndex",
    "ScatterNd",
    "OneHot",
    "BroadcastTo",
    "Dilation2D",
    "",
    "",
    "",
    "",
    "",
    "",
    "Raster",
    "ConvertTensor",
    "ArgMin",
    "LinSpace",
    "RandomUniform",
    "TensorArray",
    "TensorArraySize",
    "TensorArrayRead",
    "TensorArrayWrite",
    "TensorArrayGather",
    "TensorArrayScatter",
    "TensorArraySplit",
    "TensorArrayConcat",
    "LSTMBlockCell",
    "Reverse",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Plugin",
    "Select",
    "ZerosLike",
    "Broastcast",
    "SetDiff1D",
    "ReluGrad",
    "Relu6Grad",
    "PoolGrad",
    "SoftmaxGrad",
    "Conv2DBackPropFilter",
    "TrainableParam",
    "BatchNorm",
    "ZeroGrad",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "Extra",
    "ConvInt8",
    "Int8ToFloat",
    "DepthwiseConvInt8",
    "PoolInt8",
    "FloatToInt8",
    "EltwiseInt8",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "",
    "While",
    "If",
    "",
    "LayerNorm",
    "GridSample",
    nullptr
  };
  return names;
}

inline const char *EnumNameOpType(OpType e) {
  if (flatbuffers::IsOutRange(e, OpType_AbsVal, OpType_GridSample)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesOpType()[index];
}

enum OpParameter {
  OpParameter_NONE = 0,
  OpParameter_QuantizedAdd = 1,
  OpParameter_ArgMax = 2,
  OpParameter_AsString = 3,
  OpParameter_Axis = 4,
  OpParameter_BatchNorm = 5,
  OpParameter_BinaryOp = 6,
  OpParameter_Blob = 7,
  OpParameter_CastParam = 8,
  OpParameter_Convolution2D = 9,
  OpParameter_Crop = 10,
  OpParameter_CropAndResize = 11,
  OpParameter_Dequantize = 12,
  OpParameter_DetectionOutput = 13,
  OpParameter_Eltwise = 14,
  OpParameter_ExpandDims = 15,
  OpParameter_Fill = 16,
  OpParameter_Flatten = 17,
  OpParameter_Gather = 18,
  OpParameter_GatherV2 = 19,
  OpParameter_InnerProduct = 20,
  OpParameter_Input = 21,
  OpParameter_Interp = 22,
  OpParameter_LRN = 23,
  OpParameter_LSTM = 24,
  OpParameter_MatMul = 25,
  OpParameter_NonMaxSuppressionV2 = 26,
  OpParameter_Normalize = 27,
  OpParameter_PackParam = 28,
  OpParameter_Permute = 29,
  OpParameter_Plugin = 30,
  OpParameter_Pool = 31,
  OpParameter_PRelu = 32,
  OpParameter_PriorBox = 33,
  OpParameter_Proposal = 34,
  OpParameter_QuantizedAvgPool = 35,
  OpParameter_QuantizedBiasAdd = 36,
  OpParameter_QuantizedConcat = 37,
  OpParameter_QuantizedLogistic = 38,
  OpParameter_QuantizedMatMul = 39,
  OpParameter_QuantizedMaxPool = 40,
  OpParameter_QuantizedRelu = 41,
  OpParameter_QuantizedRelu6 = 42,
  OpParameter_QuantizedReshape = 43,
  OpParameter_QuantizedSoftmax = 44,
  OpParameter_QuantizeMaxMin = 45,
  OpParameter_QuantizeV2 = 46,
  OpParameter_Range = 47,
  OpParameter_Rank = 48,
  OpParameter_ReduceJoin = 49,
  OpParameter_ReductionParam = 50,
  OpParameter_Relu = 51,
  OpParameter_Relu6 = 52,
  OpParameter_RequantizationRange = 53,
  OpParameter_Requantize = 54,
  OpParameter_Reshape = 55,
  OpParameter_Resize = 56,
  OpParameter_RoiPooling = 57,
  OpParameter_Scale = 58,
  OpParameter_Selu = 59,
  OpParameter_Size = 60,
  OpParameter_Slice = 61,
  OpParameter_SliceTf = 62,
  OpParameter_SpaceBatch = 63,
  OpParameter_SqueezeParam = 64,
  OpParameter_StridedSliceParam = 65,
  OpParameter_TensorConvertInfo = 66,
  OpParameter_TfQuantizedConv2D = 67,
  OpParameter_TopKV2 = 68,
  OpParameter_Transpose = 69,
  OpParameter_UnaryOp = 70,
  OpParameter_MomentsParam = 71,
  OpParameter_RNNParam = 72,
  OpParameter_BatchMatMulParam = 73,
  OpParameter_QuantizedFloatParam = 74,
  OpParameter_DepthSpaceParam = 75,
  OpParameter_EltwiseInt8 = 76,
  OpParameter_ReverseSequenceParam = 77,
  OpParameter_Extra = 78,
  OpParameter_Pool3D = 79,
  OpParameter_Convolution3D = 80,
  OpParameter_ELU = 81,
  OpParameter_DetectionPostProcessParam = 82,
  OpParameter_OneHotParam = 83,
  OpParameter_PadParam = 84,
  OpParameter_WhileParam = 85,
  OpParameter_IfParam = 86,
  OpParameter_RandomUniform = 87,
  OpParameter_LayerNorm = 88,
  OpParameter_TensorArray = 89,
  OpParameter_LSTMBlockCell = 90,
  OpParameter_GridSample = 91,
  OpParameter_MIN = OpParameter_NONE,
  OpParameter_MAX = OpParameter_GridSample
};

inline const OpParameter (&EnumValuesOpParameter())[92] {
  static const OpParameter values[] = {
    OpParameter_NONE,
    OpParameter_QuantizedAdd,
    OpParameter_ArgMax,
    OpParameter_AsString,
    OpParameter_Axis,
    OpParameter_BatchNorm,
    OpParameter_BinaryOp,
    OpParameter_Blob,
    OpParameter_CastParam,
    OpParameter_Convolution2D,
    OpParameter_Crop,
    OpParameter_CropAndResize,
    OpParameter_Dequantize,
    OpParameter_DetectionOutput,
    OpParameter_Eltwise,
    OpParameter_ExpandDims,
    OpParameter_Fill,
    OpParameter_Flatten,
    OpParameter_Gather,
    OpParameter_GatherV2,
    OpParameter_InnerProduct,
    OpParameter_Input,
    OpParameter_Interp,
    OpParameter_LRN,
    OpParameter_LSTM,
    OpParameter_MatMul,
    OpParameter_NonMaxSuppressionV2,
    OpParameter_Normalize,
    OpParameter_PackParam,
    OpParameter_Permute,
    OpParameter_Plugin,
    OpParameter_Pool,
    OpParameter_PRelu,
    OpParameter_PriorBox,
    OpParameter_Proposal,
    OpParameter_QuantizedAvgPool,
    OpParameter_QuantizedBiasAdd,
    OpParameter_QuantizedConcat,
    OpParameter_QuantizedLogistic,
    OpParameter_QuantizedMatMul,
    OpParameter_QuantizedMaxPool,
    OpParameter_QuantizedRelu,
    OpParameter_QuantizedRelu6,
    OpParameter_QuantizedReshape,
    OpParameter_QuantizedSoftmax,
    OpParameter_QuantizeMaxMin,
    OpParameter_QuantizeV2,
    OpParameter_Range,
    OpParameter_Rank,
    OpParameter_ReduceJoin,
    OpParameter_ReductionParam,
    OpParameter_Relu,
    OpParameter_Relu6,
    OpParameter_RequantizationRange,
    OpParameter_Requantize,
    OpParameter_Reshape,
    OpParameter_Resize,
    OpParameter_RoiPooling,
    OpParameter_Scale,
    OpParameter_Selu,
    OpParameter_Size,
    OpParameter_Slice,
    OpParameter_SliceTf,
    OpParameter_SpaceBatch,
    OpParameter_SqueezeParam,
    OpParameter_StridedSliceParam,
    OpParameter_TensorConvertInfo,
    OpParameter_TfQuantizedConv2D,
    OpParameter_TopKV2,
    OpParameter_Transpose,
    OpParameter_UnaryOp,
    OpParameter_MomentsParam,
    OpParameter_RNNParam,
    OpParameter_BatchMatMulParam,
    OpParameter_QuantizedFloatParam,
    OpParameter_DepthSpaceParam,
    OpParameter_EltwiseInt8,
    OpParameter_ReverseSequenceParam,
    OpParameter_Extra,
    OpParameter_Pool3D,
    OpParameter_Convolution3D,
    OpParameter_ELU,
    OpParameter_DetectionPostProcessParam,
    OpParameter_OneHotParam,
    OpParameter_PadParam,
    OpParameter_WhileParam,
    OpParameter_IfParam,
    OpParameter_RandomUniform,
    OpParameter_LayerNorm,
    OpParameter_TensorArray,
    OpParameter_LSTMBlockCell,
    OpParameter_GridSample
  };
  return values;
}

inline const char * const *EnumNamesOpParameter() {
  static const char * const names[93] = {
    "NONE",
    "QuantizedAdd",
    "ArgMax",
    "AsString",
    "Axis",
    "BatchNorm",
    "BinaryOp",
    "Blob",
    "CastParam",
    "Convolution2D",
    "Crop",
    "CropAndResize",
    "Dequantize",
    "DetectionOutput",
    "Eltwise",
    "ExpandDims",
    "Fill",
    "Flatten",
    "Gather",
    "GatherV2",
    "InnerProduct",
    "Input",
    "Interp",
    "LRN",
    "LSTM",
    "MatMul",
    "NonMaxSuppressionV2",
    "Normalize",
    "PackParam",
    "Permute",
    "Plugin",
    "Pool",
    "PRelu",
    "PriorBox",
    "Proposal",
    "QuantizedAvgPool",
    "QuantizedBiasAdd",
    "QuantizedConcat",
    "QuantizedLogistic",
    "QuantizedMatMul",
    "QuantizedMaxPool",
    "QuantizedRelu",
    "QuantizedRelu6",
    "QuantizedReshape",
    "QuantizedSoftmax",
    "QuantizeMaxMin",
    "QuantizeV2",
    "Range",
    "Rank",
    "ReduceJoin",
    "ReductionParam",
    "Relu",
    "Relu6",
    "RequantizationRange",
    "Requantize",
    "Reshape",
    "Resize",
    "RoiPooling",
    "Scale",
    "Selu",
    "Size",
    "Slice",
    "SliceTf",
    "SpaceBatch",
    "SqueezeParam",
    "StridedSliceParam",
    "TensorConvertInfo",
    "TfQuantizedConv2D",
    "TopKV2",
    "Transpose",
    "UnaryOp",
    "MomentsParam",
    "RNNParam",
    "BatchMatMulParam",
    "QuantizedFloatParam",
    "DepthSpaceParam",
    "EltwiseInt8",
    "ReverseSequenceParam",
    "Extra",
    "Pool3D",
    "Convolution3D",
    "ELU",
    "DetectionPostProcessParam",
    "OneHotParam",
    "PadParam",
    "WhileParam",
    "IfParam",
    "RandomUniform",
    "LayerNorm",
    "TensorArray",
    "LSTMBlockCell",
    "GridSample",
    nullptr
  };
  return names;
}

inline const char *EnumNameOpParameter(OpParameter e) {
  if (flatbuffers::IsOutRange(e, OpParameter_NONE, OpParameter_GridSample)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesOpParameter()[index];
}

template<typename T> struct OpParameterTraits {
  static const OpParameter enum_value = OpParameter_NONE;
};

template<> struct OpParameterTraits<MNN::QuantizedAdd> {
  static const OpParameter enum_value = OpParameter_QuantizedAdd;
};

template<> struct OpParameterTraits<MNN::ArgMax> {
  static const OpParameter enum_value = OpParameter_ArgMax;
};

template<> struct OpParameterTraits<MNN::AsString> {
  static const OpParameter enum_value = OpParameter_AsString;
};

template<> struct OpParameterTraits<MNN::Axis> {
  static const OpParameter enum_value = OpParameter_Axis;
};

template<> struct OpParameterTraits<MNN::BatchNorm> {
  static const OpParameter enum_value = OpParameter_BatchNorm;
};

template<> struct OpParameterTraits<MNN::BinaryOp> {
  static const OpParameter enum_value = OpParameter_BinaryOp;
};

template<> struct OpParameterTraits<MNN::Blob> {
  static const OpParameter enum_value = OpParameter_Blob;
};

template<> struct OpParameterTraits<MNN::CastParam> {
  static const OpParameter enum_value = OpParameter_CastParam;
};

template<> struct OpParameterTraits<MNN::Convolution2D> {
  static const OpParameter enum_value = OpParameter_Convolution2D;
};

template<> struct OpParameterTraits<MNN::Crop> {
  static const OpParameter enum_value = OpParameter_Crop;
};

template<> struct OpParameterTraits<MNN::CropAndResize> {
  static const OpParameter enum_value = OpParameter_CropAndResize;
};

template<> struct OpParameterTraits<MNN::Dequantize> {
  static const OpParameter enum_value = OpParameter_Dequantize;
};

template<> struct OpParameterTraits<MNN::DetectionOutput> {
  static const OpParameter enum_value = OpParameter_DetectionOutput;
};

template<> struct OpParameterTraits<MNN::Eltwise> {
  static const OpParameter enum_value = OpParameter_Eltwise;
};

template<> struct OpParameterTraits<MNN::ExpandDims> {
  static const OpParameter enum_value = OpParameter_ExpandDims;
};

template<> struct OpParameterTraits<MNN::Fill> {
  static const OpParameter enum_value = OpParameter_Fill;
};

template<> struct OpParameterTraits<MNN::Flatten> {
  static const OpParameter enum_value = OpParameter_Flatten;
};

template<> struct OpParameterTraits<MNN::Gather> {
  static const OpParameter enum_value = OpParameter_Gather;
};

template<> struct OpParameterTraits<MNN::GatherV2> {
  static const OpParameter enum_value = OpParameter_GatherV2;
};

template<> struct OpParameterTraits<MNN::InnerProduct> {
  static const OpParameter enum_value = OpParameter_InnerProduct;
};

template<> struct OpParameterTraits<MNN::Input> {
  static const OpParameter enum_value = OpParameter_Input;
};

template<> struct OpParameterTraits<MNN::Interp> {
  static const OpParameter enum_value = OpParameter_Interp;
};

template<> struct OpParameterTraits<MNN::LRN> {
  static const OpParameter enum_value = OpParameter_LRN;
};

template<> struct OpParameterTraits<MNN::LSTM> {
  static const OpParameter enum_value = OpParameter_LSTM;
};

template<> struct OpParameterTraits<MNN::MatMul> {
  static const OpParameter enum_value = OpParameter_MatMul;
};

template<> struct OpParameterTraits<MNN::NonMaxSuppressionV2> {
  static const OpParameter enum_value = OpParameter_NonMaxSuppressionV2;
};

template<> struct OpParameterTraits<MNN::Normalize> {
  static const OpParameter enum_value = OpParameter_Normalize;
};

template<> struct OpParameterTraits<MNN::PackParam> {
  static const OpParameter enum_value = OpParameter_PackParam;
};

template<> struct OpParameterTraits<MNN::Permute> {
  static const OpParameter enum_value = OpParameter_Permute;
};

template<> struct OpParameterTraits<MNN::Plugin> {
  static const OpParameter enum_value = OpParameter_Plugin;
};

template<> struct OpParameterTraits<MNN::Pool> {
  static const OpParameter enum_value = OpParameter_Pool;
};

template<> struct OpParameterTraits<MNN::PRelu> {
  static const OpParameter enum_value = OpParameter_PRelu;
};

template<> struct OpParameterTraits<MNN::PriorBox> {
  static const OpParameter enum_value = OpParameter_PriorBox;
};

template<> struct OpParameterTraits<MNN::Proposal> {
  static const OpParameter enum_value = OpParameter_Proposal;
};

template<> struct OpParameterTraits<MNN::QuantizedAvgPool> {
  static const OpParameter enum_value = OpParameter_QuantizedAvgPool;
};

template<> struct OpParameterTraits<MNN::QuantizedBiasAdd> {
  static const OpParameter enum_value = OpParameter_QuantizedBiasAdd;
};

template<> struct OpParameterTraits<MNN::QuantizedConcat> {
  static const OpParameter enum_value = OpParameter_QuantizedConcat;
};

template<> struct OpParameterTraits<MNN::QuantizedLogistic> {
  static const OpParameter enum_value = OpParameter_QuantizedLogistic;
};

template<> struct OpParameterTraits<MNN::QuantizedMatMul> {
  static const OpParameter enum_value = OpParameter_QuantizedMatMul;
};

template<> struct OpParameterTraits<MNN::QuantizedMaxPool> {
  static const OpParameter enum_value = OpParameter_QuantizedMaxPool;
};

template<> struct OpParameterTraits<MNN::QuantizedRelu> {
  static const OpParameter enum_value = OpParameter_QuantizedRelu;
};

template<> struct OpParameterTraits<MNN::QuantizedRelu6> {
  static const OpParameter enum_value = OpParameter_QuantizedRelu6;
};

template<> struct OpParameterTraits<MNN::QuantizedReshape> {
  static const OpParameter enum_value = OpParameter_QuantizedReshape;
};

template<> struct OpParameterTraits<MNN::QuantizedSoftmax> {
  static const OpParameter enum_value = OpParameter_QuantizedSoftmax;
};

template<> struct OpParameterTraits<MNN::QuantizeMaxMin> {
  static const OpParameter enum_value = OpParameter_QuantizeMaxMin;
};

template<> struct OpParameterTraits<MNN::QuantizeV2> {
  static const OpParameter enum_value = OpParameter_QuantizeV2;
};

template<> struct OpParameterTraits<MNN::Range> {
  static const OpParameter enum_value = OpParameter_Range;
};

template<> struct OpParameterTraits<MNN::Rank> {
  static const OpParameter enum_value = OpParameter_Rank;
};

template<> struct OpParameterTraits<MNN::ReduceJoin> {
  static const OpParameter enum_value = OpParameter_ReduceJoin;
};

template<> struct OpParameterTraits<MNN::ReductionParam> {
  static const OpParameter enum_value = OpParameter_ReductionParam;
};

template<> struct OpParameterTraits<MNN::Relu> {
  static const OpParameter enum_value = OpParameter_Relu;
};

template<> struct OpParameterTraits<MNN::Relu6> {
  static const OpParameter enum_value = OpParameter_Relu6;
};

template<> struct OpParameterTraits<MNN::RequantizationRange> {
  static const OpParameter enum_value = OpParameter_RequantizationRange;
};

template<> struct OpParameterTraits<MNN::Requantize> {
  static const OpParameter enum_value = OpParameter_Requantize;
};

template<> struct OpParameterTraits<MNN::Reshape> {
  static const OpParameter enum_value = OpParameter_Reshape;
};

template<> struct OpParameterTraits<MNN::Resize> {
  static const OpParameter enum_value = OpParameter_Resize;
};

template<> struct OpParameterTraits<MNN::RoiPooling> {
  static const OpParameter enum_value = OpParameter_RoiPooling;
};

template<> struct OpParameterTraits<MNN::Scale> {
  static const OpParameter enum_value = OpParameter_Scale;
};

template<> struct OpParameterTraits<MNN::Selu> {
  static const OpParameter enum_value = OpParameter_Selu;
};

template<> struct OpParameterTraits<MNN::Size> {
  static const OpParameter enum_value = OpParameter_Size;
};

template<> struct OpParameterTraits<MNN::Slice> {
  static const OpParameter enum_value = OpParameter_Slice;
};

template<> struct OpParameterTraits<MNN::SliceTf> {
  static const OpParameter enum_value = OpParameter_SliceTf;
};

template<> struct OpParameterTraits<MNN::SpaceBatch> {
  static const OpParameter enum_value = OpParameter_SpaceBatch;
};

template<> struct OpParameterTraits<MNN::SqueezeParam> {
  static const OpParameter enum_value = OpParameter_SqueezeParam;
};

template<> struct OpParameterTraits<MNN::StridedSliceParam> {
  static const OpParameter enum_value = OpParameter_StridedSliceParam;
};

template<> struct OpParameterTraits<MNN::TensorConvertInfo> {
  static const OpParameter enum_value = OpParameter_TensorConvertInfo;
};

template<> struct OpParameterTraits<MNN::TfQuantizedConv2D> {
  static const OpParameter enum_value = OpParameter_TfQuantizedConv2D;
};

template<> struct OpParameterTraits<MNN::TopKV2> {
  static const OpParameter enum_value = OpParameter_TopKV2;
};

template<> struct OpParameterTraits<MNN::Transpose> {
  static const OpParameter enum_value = OpParameter_Transpose;
};

template<> struct OpParameterTraits<MNN::UnaryOp> {
  static const OpParameter enum_value = OpParameter_UnaryOp;
};

template<> struct OpParameterTraits<MNN::MomentsParam> {
  static const OpParameter enum_value = OpParameter_MomentsParam;
};

template<> struct OpParameterTraits<MNN::RNNParam> {
  static const OpParameter enum_value = OpParameter_RNNParam;
};

template<> struct OpParameterTraits<MNN::BatchMatMulParam> {
  static const OpParameter enum_value = OpParameter_BatchMatMulParam;
};

template<> struct OpParameterTraits<MNN::QuantizedFloatParam> {
  static const OpParameter enum_value = OpParameter_QuantizedFloatParam;
};

template<> struct OpParameterTraits<MNN::DepthSpaceParam> {
  static const OpParameter enum_value = OpParameter_DepthSpaceParam;
};

template<> struct OpParameterTraits<MNN::EltwiseInt8> {
  static const OpParameter enum_value = OpParameter_EltwiseInt8;
};

template<> struct OpParameterTraits<MNN::ReverseSequenceParam> {
  static const OpParameter enum_value = OpParameter_ReverseSequenceParam;
};

template<> struct OpParameterTraits<MNN::Extra> {
  static const OpParameter enum_value = OpParameter_Extra;
};

template<> struct OpParameterTraits<MNN::Pool3D> {
  static const OpParameter enum_value = OpParameter_Pool3D;
};

template<> struct OpParameterTraits<MNN::Convolution3D> {
  static const OpParameter enum_value = OpParameter_Convolution3D;
};

template<> struct OpParameterTraits<MNN::ELU> {
  static const OpParameter enum_value = OpParameter_ELU;
};

template<> struct OpParameterTraits<MNN::DetectionPostProcessParam> {
  static const OpParameter enum_value = OpParameter_DetectionPostProcessParam;
};

template<> struct OpParameterTraits<MNN::OneHotParam> {
  static const OpParameter enum_value = OpParameter_OneHotParam;
};

template<> struct OpParameterTraits<MNN::PadParam> {
  static const OpParameter enum_value = OpParameter_PadParam;
};

template<> struct OpParameterTraits<MNN::WhileParam> {
  static const OpParameter enum_value = OpParameter_WhileParam;
};

template<> struct OpParameterTraits<MNN::IfParam> {
  static const OpParameter enum_value = OpParameter_IfParam;
};

template<> struct OpParameterTraits<MNN::RandomUniform> {
  static const OpParameter enum_value = OpParameter_RandomUniform;
};

template<> struct OpParameterTraits<MNN::LayerNorm> {
  static const OpParameter enum_value = OpParameter_LayerNorm;
};

template<> struct OpParameterTraits<MNN::TensorArray> {
  static const OpParameter enum_value = OpParameter_TensorArray;
};

template<> struct OpParameterTraits<MNN::LSTMBlockCell> {
  static const OpParameter enum_value = OpParameter_LSTMBlockCell;
};

template<> struct OpParameterTraits<MNN::GridSample> {
  static const OpParameter enum_value = OpParameter_GridSample;
};

struct OpParameterUnion {
  OpParameter type;
  void *value;

  OpParameterUnion() : type(OpParameter_NONE), value(nullptr) {}
  OpParameterUnion(OpParameterUnion&& u) FLATBUFFERS_NOEXCEPT :
    type(OpParameter_NONE), value(nullptr)
    { std::swap(type, u.type); std::swap(value, u.value); }
  OpParameterUnion(const OpParameterUnion &);
  OpParameterUnion &operator=(const OpParameterUnion &u)
    { OpParameterUnion t(u); std::swap(type, t.type); std::swap(value, t.value); return *this; }
  OpParameterUnion &operator=(OpParameterUnion &&u) FLATBUFFERS_NOEXCEPT
    { std::swap(type, u.type); std::swap(value, u.value); return *this; }
  ~OpParameterUnion() { Reset(); }

  void Reset();

#ifndef FLATBUFFERS_CPP98_STL
  template <typename T>
  void Set(T&& val) {
    using RT = typename std::remove_reference<T>::type;
    Reset();
    type = OpParameterTraits<typename RT::TableType>::enum_value;
    if (type != OpParameter_NONE) {
      value = new RT(std::forward<T>(val));
    }
  }
#endif  // FLATBUFFERS_CPP98_STL

  static void *UnPack(const void *obj, OpParameter type, const flatbuffers::resolver_function_t *resolver);
  flatbuffers::Offset<void> Pack(flatbuffers::FlatBufferBuilder &_fbb, const flatbuffers::rehasher_function_t *_rehasher = nullptr) const;

  MNN::QuantizedAddT *AsQuantizedAdd() {
    return type == OpParameter_QuantizedAdd ?
      reinterpret_cast<MNN::QuantizedAddT *>(value) : nullptr;
  }
  const MNN::QuantizedAddT *AsQuantizedAdd() const {
    return type == OpParameter_QuantizedAdd ?
      reinterpret_cast<const MNN::QuantizedAddT *>(value) : nullptr;
  }
  MNN::ArgMaxT *AsArgMax() {
    return type == OpParameter_ArgMax ?
      reinterpret_cast<MNN::ArgMaxT *>(value) : nullptr;
  }
  const MNN::ArgMaxT *AsArgMax() const {
    return type == OpParameter_ArgMax ?
      reinterpret_cast<const MNN::ArgMaxT *>(value) : nullptr;
  }
  MNN::AsStringT *AsAsString() {
    return type == OpParameter_AsString ?
      reinterpret_cast<MNN::AsStringT *>(value) : nullptr;
  }
  const MNN::AsStringT *AsAsString() const {
    return type == OpParameter_AsString ?
      reinterpret_cast<const MNN::AsStringT *>(value) : nullptr;
  }
  MNN::AxisT *AsAxis() {
    return type == OpParameter_Axis ?
      reinterpret_cast<MNN::AxisT *>(value) : nullptr;
  }
  const MNN::AxisT *AsAxis() const {
    return type == OpParameter_Axis ?
      reinterpret_cast<const MNN::AxisT *>(value) : nullptr;
  }
  MNN::BatchNormT *AsBatchNorm() {
    return type == OpParameter_BatchNorm ?
      reinterpret_cast<MNN::BatchNormT *>(value) : nullptr;
  }
  const MNN::BatchNormT *AsBatchNorm() const {
    return type == OpParameter_BatchNorm ?
      reinterpret_cast<const MNN::BatchNormT *>(value) : nullptr;
  }
  MNN::BinaryOpT *AsBinaryOp() {
    return type == OpParameter_BinaryOp ?
      reinterpret_cast<MNN::BinaryOpT *>(value) : nullptr;
  }
  const MNN::BinaryOpT *AsBinaryOp() const {
    return type == OpParameter_BinaryOp ?
      reinterpret_cast<const MNN::BinaryOpT *>(value) : nullptr;
  }
  MNN::BlobT *AsBlob() {
    return type == OpParameter_Blob ?
      reinterpret_cast<MNN::BlobT *>(value) : nullptr;
  }
  const MNN::BlobT *AsBlob() const {
    return type == OpParameter_Blob ?
      reinterpret_cast<const MNN::BlobT *>(value) : nullptr;
  }
  MNN::CastParamT *AsCastParam() {
    return type == OpParameter_CastParam ?
      reinterpret_cast<MNN::CastParamT *>(value) : nullptr;
  }
  const MNN::CastParamT *AsCastParam() const {
    return type == OpParameter_CastParam ?
      reinterpret_cast<const MNN::CastParamT *>(value) : nullptr;
  }
  MNN::Convolution2DT *AsConvolution2D() {
    return type == OpParameter_Convolution2D ?
      reinterpret_cast<MNN::Convolution2DT *>(value) : nullptr;
  }
  const MNN::Convolution2DT *AsConvolution2D() const {
    return type == OpParameter_Convolution2D ?
      reinterpret_cast<const MNN::Convolution2DT *>(value) : nullptr;
  }
  MNN::CropT *AsCrop() {
    return type == OpParameter_Crop ?
      reinterpret_cast<MNN::CropT *>(value) : nullptr;
  }
  const MNN::CropT *AsCrop() const {
    return type == OpParameter_Crop ?
      reinterpret_cast<const MNN::CropT *>(value) : nullptr;
  }
  MNN::CropAndResizeT *AsCropAndResize() {
    return type == OpParameter_CropAndResize ?
      reinterpret_cast<MNN::CropAndResizeT *>(value) : nullptr;
  }
  const MNN::CropAndResizeT *AsCropAndResize() const {
    return type == OpParameter_CropAndResize ?
      reinterpret_cast<const MNN::CropAndResizeT *>(value) : nullptr;
  }
  MNN::DequantizeT *AsDequantize() {
    return type == OpParameter_Dequantize ?
      reinterpret_cast<MNN::DequantizeT *>(value) : nullptr;
  }
  const MNN::DequantizeT *AsDequantize() const {
    return type == OpParameter_Dequantize ?
      reinterpret_cast<const MNN::DequantizeT *>(value) : nullptr;
  }
  MNN::DetectionOutputT *AsDetectionOutput() {
    return type == OpParameter_DetectionOutput ?
      reinterpret_cast<MNN::DetectionOutputT *>(value) : nullptr;
  }
  const MNN::DetectionOutputT *AsDetectionOutput() const {
    return type == OpParameter_DetectionOutput ?
      reinterpret_cast<const MNN::DetectionOutputT *>(value) : nullptr;
  }
  MNN::EltwiseT *AsEltwise() {
    return type == OpParameter_Eltwise ?
      reinterpret_cast<MNN::EltwiseT *>(value) : nullptr;
  }
  const MNN::EltwiseT *AsEltwise() const {
    return type == OpParameter_Eltwise ?
      reinterpret_cast<const MNN::EltwiseT *>(value) : nullptr;
  }
  MNN::ExpandDimsT *AsExpandDims() {
    return type == OpParameter_ExpandDims ?
      reinterpret_cast<MNN::ExpandDimsT *>(value) : nullptr;
  }
  const MNN::ExpandDimsT *AsExpandDims() const {
    return type == OpParameter_ExpandDims ?
      reinterpret_cast<const MNN::ExpandDimsT *>(value) : nullptr;
  }
  MNN::FillT *AsFill() {
    return type == OpParameter_Fill ?
      reinterpret_cast<MNN::FillT *>(value) : nullptr;
  }
  const MNN::FillT *AsFill() const {
    return type == OpParameter_Fill ?
      reinterpret_cast<const MNN::FillT *>(value) : nullptr;
  }
  MNN::FlattenT *AsFlatten() {
    return type == OpParameter_Flatten ?
      reinterpret_cast<MNN::FlattenT *>(value) : nullptr;
  }
  const MNN::FlattenT *AsFlatten() const {
    return type == OpParameter_Flatten ?
      reinterpret_cast<const MNN::FlattenT *>(value) : nullptr;
  }
  MNN::GatherT *AsGather() {
    return type == OpParameter_Gather ?
      reinterpret_cast<MNN::GatherT *>(value) : nullptr;
  }
  const MNN::GatherT *AsGather() const {
    return type == OpParameter_Gather ?
      reinterpret_cast<const MNN::GatherT *>(value) : nullptr;
  }
  MNN::GatherV2T *AsGatherV2() {
    return type == OpParameter_GatherV2 ?
      reinterpret_cast<MNN::GatherV2T *>(value) : nullptr;
  }
  const MNN::GatherV2T *AsGatherV2() const {
    return type == OpParameter_GatherV2 ?
      reinterpret_cast<const MNN::GatherV2T *>(value) : nullptr;
  }
  MNN::InnerProductT *AsInnerProduct() {
    return type == OpParameter_InnerProduct ?
      reinterpret_cast<MNN::InnerProductT *>(value) : nullptr;
  }
  const MNN::InnerProductT *AsInnerProduct() const {
    return type == OpParameter_InnerProduct ?
      reinterpret_cast<const MNN::InnerProductT *>(value) : nullptr;
  }
  MNN::InputT *AsInput() {
    return type == OpParameter_Input ?
      reinterpret_cast<MNN::InputT *>(value) : nullptr;
  }
  const MNN::InputT *AsInput() const {
    return type == OpParameter_Input ?
      reinterpret_cast<const MNN::InputT *>(value) : nullptr;
  }
  MNN::InterpT *AsInterp() {
    return type == OpParameter_Interp ?
      reinterpret_cast<MNN::InterpT *>(value) : nullptr;
  }
  const MNN::InterpT *AsInterp() const {
    return type == OpParameter_Interp ?
      reinterpret_cast<const MNN::InterpT *>(value) : nullptr;
  }
  MNN::LRNT *AsLRN() {
    return type == OpParameter_LRN ?
      reinterpret_cast<MNN::LRNT *>(value) : nullptr;
  }
  const MNN::LRNT *AsLRN() const {
    return type == OpParameter_LRN ?
      reinterpret_cast<const MNN::LRNT *>(value) : nullptr;
  }
  MNN::LSTMT *AsLSTM() {
    return type == OpParameter_LSTM ?
      reinterpret_cast<MNN::LSTMT *>(value) : nullptr;
  }
  const MNN::LSTMT *AsLSTM() const {
    return type == OpParameter_LSTM ?
      reinterpret_cast<const MNN::LSTMT *>(value) : nullptr;
  }
  MNN::MatMulT *AsMatMul() {
    return type == OpParameter_MatMul ?
      reinterpret_cast<MNN::MatMulT *>(value) : nullptr;
  }
  const MNN::MatMulT *AsMatMul() const {
    return type == OpParameter_MatMul ?
      reinterpret_cast<const MNN::MatMulT *>(value) : nullptr;
  }
  MNN::NonMaxSuppressionV2T *AsNonMaxSuppressionV2() {
    return type == OpParameter_NonMaxSuppressionV2 ?
      reinterpret_cast<MNN::NonMaxSuppressionV2T *>(value) : nullptr;
  }
  const MNN::NonMaxSuppressionV2T *AsNonMaxSuppressionV2() const {
    return type == OpParameter_NonMaxSuppressionV2 ?
      reinterpret_cast<const MNN::NonMaxSuppressionV2T *>(value) : nullptr;
  }
  MNN::NormalizeT *AsNormalize() {
    return type == OpParameter_Normalize ?
      reinterpret_cast<MNN::NormalizeT *>(value) : nullptr;
  }
  const MNN::NormalizeT *AsNormalize() const {
    return type == OpParameter_Normalize ?
      reinterpret_cast<const MNN::NormalizeT *>(value) : nullptr;
  }
  MNN::PackParamT *AsPackParam() {
    return type == OpParameter_PackParam ?
      reinterpret_cast<MNN::PackParamT *>(value) : nullptr;
  }
  const MNN::PackParamT *AsPackParam() const {
    return type == OpParameter_PackParam ?
      reinterpret_cast<const MNN::PackParamT *>(value) : nullptr;
  }
  MNN::PermuteT *AsPermute() {
    return type == OpParameter_Permute ?
      reinterpret_cast<MNN::PermuteT *>(value) : nullptr;
  }
  const MNN::PermuteT *AsPermute() const {
    return type == OpParameter_Permute ?
      reinterpret_cast<const MNN::PermuteT *>(value) : nullptr;
  }
  MNN::PluginT *AsPlugin() {
    return type == OpParameter_Plugin ?
      reinterpret_cast<MNN::PluginT *>(value) : nullptr;
  }
  const MNN::PluginT *AsPlugin() const {
    return type == OpParameter_Plugin ?
      reinterpret_cast<const MNN::PluginT *>(value) : nullptr;
  }
  MNN::PoolT *AsPool() {
    return type == OpParameter_Pool ?
      reinterpret_cast<MNN::PoolT *>(value) : nullptr;
  }
  const MNN::PoolT *AsPool() const {
    return type == OpParameter_Pool ?
      reinterpret_cast<const MNN::PoolT *>(value) : nullptr;
  }
  MNN::PReluT *AsPRelu() {
    return type == OpParameter_PRelu ?
      reinterpret_cast<MNN::PReluT *>(value) : nullptr;
  }
  const MNN::PReluT *AsPRelu() const {
    return type == OpParameter_PRelu ?
      reinterpret_cast<const MNN::PReluT *>(value) : nullptr;
  }
  MNN::PriorBoxT *AsPriorBox() {
    return type == OpParameter_PriorBox ?
      reinterpret_cast<MNN::PriorBoxT *>(value) : nullptr;
  }
  const MNN::PriorBoxT *AsPriorBox() const {
    return type == OpParameter_PriorBox ?
      reinterpret_cast<const MNN::PriorBoxT *>(value) : nullptr;
  }
  MNN::ProposalT *AsProposal() {
    return type == OpParameter_Proposal ?
      reinterpret_cast<MNN::ProposalT *>(value) : nullptr;
  }
  const MNN::ProposalT *AsProposal() const {
    return type == OpParameter_Proposal ?
      reinterpret_cast<const MNN::ProposalT *>(value) : nullptr;
  }
  MNN::QuantizedAvgPoolT *AsQuantizedAvgPool() {
    return type == OpParameter_QuantizedAvgPool ?
      reinterpret_cast<MNN::QuantizedAvgPoolT *>(value) : nullptr;
  }
  const MNN::QuantizedAvgPoolT *AsQuantizedAvgPool() const {
    return type == OpParameter_QuantizedAvgPool ?
      reinterpret_cast<const MNN::QuantizedAvgPoolT *>(value) : nullptr;
  }
  MNN::QuantizedBiasAddT *AsQuantizedBiasAdd() {
    return type == OpParameter_QuantizedBiasAdd ?
      reinterpret_cast<MNN::QuantizedBiasAddT *>(value) : nullptr;
  }
  const MNN::QuantizedBiasAddT *AsQuantizedBiasAdd() const {
    return type == OpParameter_QuantizedBiasAdd ?
      reinterpret_cast<const MNN::QuantizedBiasAddT *>(value) : nullptr;
  }
  MNN::QuantizedConcatT *AsQuantizedConcat() {
    return type == OpParameter_QuantizedConcat ?
      reinterpret_cast<MNN::QuantizedConcatT *>(value) : nullptr;
  }
  const MNN::QuantizedConcatT *AsQuantizedConcat() const {
    return type == OpParameter_QuantizedConcat ?
      reinterpret_cast<const MNN::QuantizedConcatT *>(value) : nullptr;
  }
  MNN::QuantizedLogisticT *AsQuantizedLogistic() {
    return type == OpParameter_QuantizedLogistic ?
      reinterpret_cast<MNN::QuantizedLogisticT *>(value) : nullptr;
  }
  const MNN::QuantizedLogisticT *AsQuantizedLogistic() const {
    return type == OpParameter_QuantizedLogistic ?
      reinterpret_cast<const MNN::QuantizedLogisticT *>(value) : nullptr;
  }
  MNN::QuantizedMatMulT *AsQuantizedMatMul() {
    return type == OpParameter_QuantizedMatMul ?
      reinterpret_cast<MNN::QuantizedMatMulT *>(value) : nullptr;
  }
  const MNN::QuantizedMatMulT *AsQuantizedMatMul() const {
    return type == OpParameter_QuantizedMatMul ?
      reinterpret_cast<const MNN::QuantizedMatMulT *>(value) : nullptr;
  }
  MNN::QuantizedMaxPoolT *AsQuantizedMaxPool() {
    return type == OpParameter_QuantizedMaxPool ?
      reinterpret_cast<MNN::QuantizedMaxPoolT *>(value) : nullptr;
  }
  const MNN::QuantizedMaxPoolT *AsQuantizedMaxPool() const {
    return type == OpParameter_QuantizedMaxPool ?
      reinterpret_cast<const MNN::QuantizedMaxPoolT *>(value) : nullptr;
  }
  MNN::QuantizedReluT *AsQuantizedRelu() {
    return type == OpParameter_QuantizedRelu ?
      reinterpret_cast<MNN::QuantizedReluT *>(value) : nullptr;
  }
  const MNN::QuantizedReluT *AsQuantizedRelu() const {
    return type == OpParameter_QuantizedRelu ?
      reinterpret_cast<const MNN::QuantizedReluT *>(value) : nullptr;
  }
  MNN::QuantizedRelu6T *AsQuantizedRelu6() {
    return type == OpParameter_QuantizedRelu6 ?
      reinterpret_cast<MNN::QuantizedRelu6T *>(value) : nullptr;
  }
  const MNN::QuantizedRelu6T *AsQuantizedRelu6() const {
    return type == OpParameter_QuantizedRelu6 ?
      reinterpret_cast<const MNN::QuantizedRelu6T *>(value) : nullptr;
  }
  MNN::QuantizedReshapeT *AsQuantizedReshape() {
    return type == OpParameter_QuantizedReshape ?
      reinterpret_cast<MNN::QuantizedReshapeT *>(value) : nullptr;
  }
  const MNN::QuantizedReshapeT *AsQuantizedReshape() const {
    return type == OpParameter_QuantizedReshape ?
      reinterpret_cast<const MNN::QuantizedReshapeT *>(value) : nullptr;
  }
  MNN::QuantizedSoftmaxT *AsQuantizedSoftmax() {
    return type == OpParameter_QuantizedSoftmax ?
      reinterpret_cast<MNN::QuantizedSoftmaxT *>(value) : nullptr;
  }
  const MNN::QuantizedSoftmaxT *AsQuantizedSoftmax() const {
    return type == OpParameter_QuantizedSoftmax ?
      reinterpret_cast<const MNN::QuantizedSoftmaxT *>(value) : nullptr;
  }
  MNN::QuantizeMaxMinT *AsQuantizeMaxMin() {
    return type == OpParameter_QuantizeMaxMin ?
      reinterpret_cast<MNN::QuantizeMaxMinT *>(value) : nullptr;
  }
  const MNN::QuantizeMaxMinT *AsQuantizeMaxMin() const {
    return type == OpParameter_QuantizeMaxMin ?
      reinterpret_cast<const MNN::QuantizeMaxMinT *>(value) : nullptr;
  }
  MNN::QuantizeV2T *AsQuantizeV2() {
    return type == OpParameter_QuantizeV2 ?
      reinterpret_cast<MNN::QuantizeV2T *>(value) : nullptr;
  }
  const MNN::QuantizeV2T *AsQuantizeV2() const {
    return type == OpParameter_QuantizeV2 ?
      reinterpret_cast<const MNN::QuantizeV2T *>(value) : nullptr;
  }
  MNN::RangeT *AsRange() {
    return type == OpParameter_Range ?
      reinterpret_cast<MNN::RangeT *>(value) : nullptr;
  }
  const MNN::RangeT *AsRange() const {
    return type == OpParameter_Range ?
      reinterpret_cast<const MNN::RangeT *>(value) : nullptr;
  }
  MNN::RankT *AsRank() {
    return type == OpParameter_Rank ?
      reinterpret_cast<MNN::RankT *>(value) : nullptr;
  }
  const MNN::RankT *AsRank() const {
    return type == OpParameter_Rank ?
      reinterpret_cast<const MNN::RankT *>(value) : nullptr;
  }
  MNN::ReduceJoinT *AsReduceJoin() {
    return type == OpParameter_ReduceJoin ?
      reinterpret_cast<MNN::ReduceJoinT *>(value) : nullptr;
  }
  const MNN::ReduceJoinT *AsReduceJoin() const {
    return type == OpParameter_ReduceJoin ?
      reinterpret_cast<const MNN::ReduceJoinT *>(value) : nullptr;
  }
  MNN::ReductionParamT *AsReductionParam() {
    return type == OpParameter_ReductionParam ?
      reinterpret_cast<MNN::ReductionParamT *>(value) : nullptr;
  }
  const MNN::ReductionParamT *AsReductionParam() const {
    return type == OpParameter_ReductionParam ?
      reinterpret_cast<const MNN::ReductionParamT *>(value) : nullptr;
  }
  MNN::ReluT *AsRelu() {
    return type == OpParameter_Relu ?
      reinterpret_cast<MNN::ReluT *>(value) : nullptr;
  }
  const MNN::ReluT *AsRelu() const {
    return type == OpParameter_Relu ?
      reinterpret_cast<const MNN::ReluT *>(value) : nullptr;
  }
  MNN::Relu6T *AsRelu6() {
    return type == OpParameter_Relu6 ?
      reinterpret_cast<MNN::Relu6T *>(value) : nullptr;
  }
  const MNN::Relu6T *AsRelu6() const {
    return type == OpParameter_Relu6 ?
      reinterpret_cast<const MNN::Relu6T *>(value) : nullptr;
  }
  MNN::RequantizationRangeT *AsRequantizationRange() {
    return type == OpParameter_RequantizationRange ?
      reinterpret_cast<MNN::RequantizationRangeT *>(value) : nullptr;
  }
  const MNN::RequantizationRangeT *AsRequantizationRange() const {
    return type == OpParameter_RequantizationRange ?
      reinterpret_cast<const MNN::RequantizationRangeT *>(value) : nullptr;
  }
  MNN::RequantizeT *AsRequantize() {
    return type == OpParameter_Requantize ?
      reinterpret_cast<MNN::RequantizeT *>(value) : nullptr;
  }
  const MNN::RequantizeT *AsRequantize() const {
    return type == OpParameter_Requantize ?
      reinterpret_cast<const MNN::RequantizeT *>(value) : nullptr;
  }
  MNN::ReshapeT *AsReshape() {
    return type == OpParameter_Reshape ?
      reinterpret_cast<MNN::ReshapeT *>(value) : nullptr;
  }
  const MNN::ReshapeT *AsReshape() const {
    return type == OpParameter_Reshape ?
      reinterpret_cast<const MNN::ReshapeT *>(value) : nullptr;
  }
  MNN::ResizeT *AsResize() {
    return type == OpParameter_Resize ?
      reinterpret_cast<MNN::ResizeT *>(value) : nullptr;
  }
  const MNN::ResizeT *AsResize() const {
    return type == OpParameter_Resize ?
      reinterpret_cast<const MNN::ResizeT *>(value) : nullptr;
  }
  MNN::RoiPoolingT *AsRoiPooling() {
    return type == OpParameter_RoiPooling ?
      reinterpret_cast<MNN::RoiPoolingT *>(value) : nullptr;
  }
  const MNN::RoiPoolingT *AsRoiPooling() const {
    return type == OpParameter_RoiPooling ?
      reinterpret_cast<const MNN::RoiPoolingT *>(value) : nullptr;
  }
  MNN::ScaleT *AsScale() {
    return type == OpParameter_Scale ?
      reinterpret_cast<MNN::ScaleT *>(value) : nullptr;
  }
  const MNN::ScaleT *AsScale() const {
    return type == OpParameter_Scale ?
      reinterpret_cast<const MNN::ScaleT *>(value) : nullptr;
  }
  MNN::SeluT *AsSelu() {
    return type == OpParameter_Selu ?
      reinterpret_cast<MNN::SeluT *>(value) : nullptr;
  }
  const MNN::SeluT *AsSelu() const {
    return type == OpParameter_Selu ?
      reinterpret_cast<const MNN::SeluT *>(value) : nullptr;
  }
  MNN::SizeT *AsSize() {
    return type == OpParameter_Size ?
      reinterpret_cast<MNN::SizeT *>(value) : nullptr;
  }
  const MNN::SizeT *AsSize() const {
    return type == OpParameter_Size ?
      reinterpret_cast<const MNN::SizeT *>(value) : nullptr;
  }
  MNN::SliceT *AsSlice() {
    return type == OpParameter_Slice ?
      reinterpret_cast<MNN::SliceT *>(value) : nullptr;
  }
  const MNN::SliceT *AsSlice() const {
    return type == OpParameter_Slice ?
      reinterpret_cast<const MNN::SliceT *>(value) : nullptr;
  }
  MNN::SliceTfT *AsSliceTf() {
    return type == OpParameter_SliceTf ?
      reinterpret_cast<MNN::SliceTfT *>(value) : nullptr;
  }
  const MNN::SliceTfT *AsSliceTf() const {
    return type == OpParameter_SliceTf ?
      reinterpret_cast<const MNN::SliceTfT *>(value) : nullptr;
  }
  MNN::SpaceBatchT *AsSpaceBatch() {
    return type == OpParameter_SpaceBatch ?
      reinterpret_cast<MNN::SpaceBatchT *>(value) : nullptr;
  }
  const MNN::SpaceBatchT *AsSpaceBatch() const {
    return type == OpParameter_SpaceBatch ?
      reinterpret_cast<const MNN::SpaceBatchT *>(value) : nullptr;
  }
  MNN::SqueezeParamT *AsSqueezeParam() {
    return type == OpParameter_SqueezeParam ?
      reinterpret_cast<MNN::SqueezeParamT *>(value) : nullptr;
  }
  const MNN::SqueezeParamT *AsSqueezeParam() const {
    return type == OpParameter_SqueezeParam ?
      reinterpret_cast<const MNN::SqueezeParamT *>(value) : nullptr;
  }
  MNN::StridedSliceParamT *AsStridedSliceParam() {
    return type == OpParameter_StridedSliceParam ?
      reinterpret_cast<MNN::StridedSliceParamT *>(value) : nullptr;
  }
  const MNN::StridedSliceParamT *AsStridedSliceParam() const {
    return type == OpParameter_StridedSliceParam ?
      reinterpret_cast<const MNN::StridedSliceParamT *>(value) : nullptr;
  }
  MNN::TensorConvertInfoT *AsTensorConvertInfo() {
    return type == OpParameter_TensorConvertInfo ?
      reinterpret_cast<MNN::TensorConvertInfoT *>(value) : nullptr;
  }
  const MNN::TensorConvertInfoT *AsTensorConvertInfo() const {
    return type == OpParameter_TensorConvertInfo ?
      reinterpret_cast<const MNN::TensorConvertInfoT *>(value) : nullptr;
  }
  MNN::TfQuantizedConv2DT *AsTfQuantizedConv2D() {
    return type == OpParameter_TfQuantizedConv2D ?
      reinterpret_cast<MNN::TfQuantizedConv2DT *>(value) : nullptr;
  }
  const MNN::TfQuantizedConv2DT *AsTfQuantizedConv2D() const {
    return type == OpParameter_TfQuantizedConv2D ?
      reinterpret_cast<const MNN::TfQuantizedConv2DT *>(value) : nullptr;
  }
  MNN::TopKV2T *AsTopKV2() {
    return type == OpParameter_TopKV2 ?
      reinterpret_cast<MNN::TopKV2T *>(value) : nullptr;
  }
  const MNN::TopKV2T *AsTopKV2() const {
    return type == OpParameter_TopKV2 ?
      reinterpret_cast<const MNN::TopKV2T *>(value) : nullptr;
  }
  MNN::TransposeT *AsTranspose() {
    return type == OpParameter_Transpose ?
      reinterpret_cast<MNN::TransposeT *>(value) : nullptr;
  }
  const MNN::TransposeT *AsTranspose() const {
    return type == OpParameter_Transpose ?
      reinterpret_cast<const MNN::TransposeT *>(value) : nullptr;
  }
  MNN::UnaryOpT *AsUnaryOp() {
    return type == OpParameter_UnaryOp ?
      reinterpret_cast<MNN::UnaryOpT *>(value) : nullptr;
  }
  const MNN::UnaryOpT *AsUnaryOp() const {
    return type == OpParameter_UnaryOp ?
      reinterpret_cast<const MNN::UnaryOpT *>(value) : nullptr;
  }
  MNN::MomentsParamT *AsMomentsParam() {
    return type == OpParameter_MomentsParam ?
      reinterpret_cast<MNN::MomentsParamT *>(value) : nullptr;
  }
  const MNN::MomentsParamT *AsMomentsParam() const {
    return type == OpParameter_MomentsParam ?
      reinterpret_cast<const MNN::MomentsParamT *>(value) : nullptr;
  }
  MNN::RNNParamT *AsRNNParam() {
    return type == OpParameter_RNNParam ?
      reinterpret_cast<MNN::RNNParamT *>(value) : nullptr;
  }
  const MNN::RNNParamT *AsRNNParam() const {
    return type == OpParameter_RNNParam ?
      reinterpret_cast<const MNN::RNNParamT *>(value) : nullptr;
  }
  MNN::BatchMatMulParamT *AsBatchMatMulParam() {
    return type == OpParameter_BatchMatMulParam ?
      reinterpret_cast<MNN::BatchMatMulParamT *>(value) : nullptr;
  }
  const MNN::BatchMatMulParamT *AsBatchMatMulParam() const {
    return type == OpParameter_BatchMatMulParam ?
      reinterpret_cast<const MNN::BatchMatMulParamT *>(value) : nullptr;
  }
  MNN::QuantizedFloatParamT *AsQuantizedFloatParam() {
    return type == OpParameter_QuantizedFloatParam ?
      reinterpret_cast<MNN::QuantizedFloatParamT *>(value) : nullptr;
  }
  const MNN::QuantizedFloatParamT *AsQuantizedFloatParam() const {
    return type == OpParameter_QuantizedFloatParam ?
      reinterpret_cast<const MNN::QuantizedFloatParamT *>(value) : nullptr;
  }
  MNN::DepthSpaceParamT *AsDepthSpaceParam() {
    return type == OpParameter_DepthSpaceParam ?
      reinterpret_cast<MNN::DepthSpaceParamT *>(value) : nullptr;
  }
  const MNN::DepthSpaceParamT *AsDepthSpaceParam() const {
    return type == OpParameter_DepthSpaceParam ?
      reinterpret_cast<const MNN::DepthSpaceParamT *>(value) : nullptr;
  }
  MNN::EltwiseInt8T *AsEltwiseInt8() {
    return type == OpParameter_EltwiseInt8 ?
      reinterpret_cast<MNN::EltwiseInt8T *>(value) : nullptr;
  }
  const MNN::EltwiseInt8T *AsEltwiseInt8() const {
    return type == OpParameter_EltwiseInt8 ?
      reinterpret_cast<const MNN::EltwiseInt8T *>(value) : nullptr;
  }
  MNN::ReverseSequenceParamT *AsReverseSequenceParam() {
    return type == OpParameter_ReverseSequenceParam ?
      reinterpret_cast<MNN::ReverseSequenceParamT *>(value) : nullptr;
  }
  const MNN::ReverseSequenceParamT *AsReverseSequenceParam() const {
    return type == OpParameter_ReverseSequenceParam ?
      reinterpret_cast<const MNN::ReverseSequenceParamT *>(value) : nullptr;
  }
  MNN::ExtraT *AsExtra() {
    return type == OpParameter_Extra ?
      reinterpret_cast<MNN::ExtraT *>(value) : nullptr;
  }
  const MNN::ExtraT *AsExtra() const {
    return type == OpParameter_Extra ?
      reinterpret_cast<const MNN::ExtraT *>(value) : nullptr;
  }
  MNN::Pool3DT *AsPool3D() {
    return type == OpParameter_Pool3D ?
      reinterpret_cast<MNN::Pool3DT *>(value) : nullptr;
  }
  const MNN::Pool3DT *AsPool3D() const {
    return type == OpParameter_Pool3D ?
      reinterpret_cast<const MNN::Pool3DT *>(value) : nullptr;
  }
  MNN::Convolution3DT *AsConvolution3D() {
    return type == OpParameter_Convolution3D ?
      reinterpret_cast<MNN::Convolution3DT *>(value) : nullptr;
  }
  const MNN::Convolution3DT *AsConvolution3D() const {
    return type == OpParameter_Convolution3D ?
      reinterpret_cast<const MNN::Convolution3DT *>(value) : nullptr;
  }
  MNN::ELUT *AsELU() {
    return type == OpParameter_ELU ?
      reinterpret_cast<MNN::ELUT *>(value) : nullptr;
  }
  const MNN::ELUT *AsELU() const {
    return type == OpParameter_ELU ?
      reinterpret_cast<const MNN::ELUT *>(value) : nullptr;
  }
  MNN::DetectionPostProcessParamT *AsDetectionPostProcessParam() {
    return type == OpParameter_DetectionPostProcessParam ?
      reinterpret_cast<MNN::DetectionPostProcessParamT *>(value) : nullptr;
  }
  const MNN::DetectionPostProcessParamT *AsDetectionPostProcessParam() const {
    return type == OpParameter_DetectionPostProcessParam ?
      reinterpret_cast<const MNN::DetectionPostProcessParamT *>(value) : nullptr;
  }
  MNN::OneHotParamT *AsOneHotParam() {
    return type == OpParameter_OneHotParam ?
      reinterpret_cast<MNN::OneHotParamT *>(value) : nullptr;
  }
  const MNN::OneHotParamT *AsOneHotParam() const {
    return type == OpParameter_OneHotParam ?
      reinterpret_cast<const MNN::OneHotParamT *>(value) : nullptr;
  }
  MNN::PadParamT *AsPadParam() {
    return type == OpParameter_PadParam ?
      reinterpret_cast<MNN::PadParamT *>(value) : nullptr;
  }
  const MNN::PadParamT *AsPadParam() const {
    return type == OpParameter_PadParam ?
      reinterpret_cast<const MNN::PadParamT *>(value) : nullptr;
  }
  MNN::WhileParamT *AsWhileParam() {
    return type == OpParameter_WhileParam ?
      reinterpret_cast<MNN::WhileParamT *>(value) : nullptr;
  }
  const MNN::WhileParamT *AsWhileParam() const {
    return type == OpParameter_WhileParam ?
      reinterpret_cast<const MNN::WhileParamT *>(value) : nullptr;
  }
  MNN::IfParamT *AsIfParam() {
    return type == OpParameter_IfParam ?
      reinterpret_cast<MNN::IfParamT *>(value) : nullptr;
  }
  const MNN::IfParamT *AsIfParam() const {
    return type == OpParameter_IfParam ?
      reinterpret_cast<const MNN::IfParamT *>(value) : nullptr;
  }
  MNN::RandomUniformT *AsRandomUniform() {
    return type == OpParameter_RandomUniform ?
      reinterpret_cast<MNN::RandomUniformT *>(value) : nullptr;
  }
  const MNN::RandomUniformT *AsRandomUniform() const {
    return type == OpParameter_RandomUniform ?
      reinterpret_cast<const MNN::RandomUniformT *>(value) : nullptr;
  }
  MNN::LayerNormT *AsLayerNorm() {
    return type == OpParameter_LayerNorm ?
      reinterpret_cast<MNN::LayerNormT *>(value) : nullptr;
  }
  const MNN::LayerNormT *AsLayerNorm() const {
    return type == OpParameter_LayerNorm ?
      reinterpret_cast<const MNN::LayerNormT *>(value) : nullptr;
  }
  MNN::TensorArrayT *AsTensorArray() {
    return type == OpParameter_TensorArray ?
      reinterpret_cast<MNN::TensorArrayT *>(value) : nullptr;
  }
  const MNN::TensorArrayT *AsTensorArray() const {
    return type == OpParameter_TensorArray ?
      reinterpret_cast<const MNN::TensorArrayT *>(value) : nullptr;
  }
  MNN::LSTMBlockCellT *AsLSTMBlockCell() {
    return type == OpParameter_LSTMBlockCell ?
      reinterpret_cast<MNN::LSTMBlockCellT *>(value) : nullptr;
  }
  const MNN::LSTMBlockCellT *AsLSTMBlockCell() const {
    return type == OpParameter_LSTMBlockCell ?
      reinterpret_cast<const MNN::LSTMBlockCellT *>(value) : nullptr;
  }
  MNN::GridSampleT *AsGridSample() {
    return type == OpParameter_GridSample ?
      reinterpret_cast<MNN::GridSampleT *>(value) : nullptr;
  }
  const MNN::GridSampleT *AsGridSample() const {
    return type == OpParameter_GridSample ?
      reinterpret_cast<const MNN::GridSampleT *>(value) : nullptr;
  }
};

bool VerifyOpParameter(flatbuffers::Verifier &verifier, const void *obj, OpParameter type);
bool VerifyOpParameterVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types);

enum ForwardType {
  ForwardType_CPU = 0,
  ForwardType_METAL = 1,
  ForwardType_OPENCL = 2,
  ForwardType_OPENGLES = 3,
  ForwardType_VULKAN = 4,
  ForwardType_MIN = ForwardType_CPU,
  ForwardType_MAX = ForwardType_VULKAN
};

inline const ForwardType (&EnumValuesForwardType())[5] {
  static const ForwardType values[] = {
    ForwardType_CPU,
    ForwardType_METAL,
    ForwardType_OPENCL,
    ForwardType_OPENGLES,
    ForwardType_VULKAN
  };
  return values;
}

inline const char * const *EnumNamesForwardType() {
  static const char * const names[6] = {
    "CPU",
    "METAL",
    "OPENCL",
    "OPENGLES",
    "VULKAN",
    nullptr
  };
  return names;
}

inline const char *EnumNameForwardType(ForwardType e) {
  if (flatbuffers::IsOutRange(e, ForwardType_CPU, ForwardType_VULKAN)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesForwardType()[index];
}

enum Usage {
  Usage_INFERENCE = 0,
  Usage_TRAIN = 1,
  Usage_INFERENCE_STATIC = 2,
  Usage_MIN = Usage_INFERENCE,
  Usage_MAX = Usage_INFERENCE_STATIC
};

inline const Usage (&EnumValuesUsage())[3] {
  static const Usage values[] = {
    Usage_INFERENCE,
    Usage_TRAIN,
    Usage_INFERENCE_STATIC
  };
  return values;
}

inline const char * const *EnumNamesUsage() {
  static const char * const names[4] = {
    "INFERENCE",
    "TRAIN",
    "INFERENCE_STATIC",
    nullptr
  };
  return names;
}

inline const char *EnumNameUsage(Usage e) {
  if (flatbuffers::IsOutRange(e, Usage_INFERENCE, Usage_INFERENCE_STATIC)) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesUsage()[index];
}

struct PluginT : public flatbuffers::NativeTable {
  typedef Plugin TableType;
  std::string type;
  std::vector<std::unique_ptr<MNN::AttributeT>> attr;
  PluginT() {
  }
};

struct Plugin FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef PluginT NativeTableType;
  typedef PluginBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return PluginTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TYPE = 4,
    VT_ATTR = 6
  };
  const flatbuffers::String *type() const {
    return GetPointer<const flatbuffers::String *>(VT_TYPE);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>> *attr() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>> *>(VT_ATTR);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_TYPE) &&
           verifier.VerifyString(type()) &&
           VerifyOffset(verifier, VT_ATTR) &&
           verifier.VerifyVector(attr()) &&
           verifier.VerifyVectorOfTables(attr()) &&
           verifier.EndTable();
  }
  PluginT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(PluginT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Plugin> Pack(flatbuffers::FlatBufferBuilder &_fbb, const PluginT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct PluginBuilder {
  typedef Plugin Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_type(flatbuffers::Offset<flatbuffers::String> type) {
    fbb_.AddOffset(Plugin::VT_TYPE, type);
  }
  void add_attr(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>>> attr) {
    fbb_.AddOffset(Plugin::VT_ATTR, attr);
  }
  explicit PluginBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  PluginBuilder &operator=(const PluginBuilder &);
  flatbuffers::Offset<Plugin> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Plugin>(end);
    return o;
  }
};

inline flatbuffers::Offset<Plugin> CreatePlugin(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> type = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>>> attr = 0) {
  PluginBuilder builder_(_fbb);
  builder_.add_attr(attr);
  builder_.add_type(type);
  return builder_.Finish();
}

inline flatbuffers::Offset<Plugin> CreatePluginDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *type = nullptr,
    const std::vector<flatbuffers::Offset<MNN::Attribute>> *attr = nullptr) {
  auto type__ = type ? _fbb.CreateString(type) : 0;
  auto attr__ = attr ? _fbb.CreateVector<flatbuffers::Offset<MNN::Attribute>>(*attr) : 0;
  return MNN::CreatePlugin(
      _fbb,
      type__,
      attr__);
}

flatbuffers::Offset<Plugin> CreatePlugin(flatbuffers::FlatBufferBuilder &_fbb, const PluginT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct ExtraT : public flatbuffers::NativeTable {
  typedef Extra TableType;
  std::string type;
  std::string engine;
  std::vector<int8_t> info;
  std::vector<std::unique_ptr<MNN::AttributeT>> attr;
  ExtraT() {
  }
};

struct Extra FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ExtraT NativeTableType;
  typedef ExtraBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return ExtraTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_TYPE = 4,
    VT_ENGINE = 6,
    VT_INFO = 8,
    VT_ATTR = 10
  };
  const flatbuffers::String *type() const {
    return GetPointer<const flatbuffers::String *>(VT_TYPE);
  }
  const flatbuffers::String *engine() const {
    return GetPointer<const flatbuffers::String *>(VT_ENGINE);
  }
  const flatbuffers::Vector<int8_t> *info() const {
    return GetPointer<const flatbuffers::Vector<int8_t> *>(VT_INFO);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>> *attr() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>> *>(VT_ATTR);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_TYPE) &&
           verifier.VerifyString(type()) &&
           VerifyOffset(verifier, VT_ENGINE) &&
           verifier.VerifyString(engine()) &&
           VerifyOffset(verifier, VT_INFO) &&
           verifier.VerifyVector(info()) &&
           VerifyOffset(verifier, VT_ATTR) &&
           verifier.VerifyVector(attr()) &&
           verifier.VerifyVectorOfTables(attr()) &&
           verifier.EndTable();
  }
  ExtraT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(ExtraT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Extra> Pack(flatbuffers::FlatBufferBuilder &_fbb, const ExtraT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct ExtraBuilder {
  typedef Extra Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_type(flatbuffers::Offset<flatbuffers::String> type) {
    fbb_.AddOffset(Extra::VT_TYPE, type);
  }
  void add_engine(flatbuffers::Offset<flatbuffers::String> engine) {
    fbb_.AddOffset(Extra::VT_ENGINE, engine);
  }
  void add_info(flatbuffers::Offset<flatbuffers::Vector<int8_t>> info) {
    fbb_.AddOffset(Extra::VT_INFO, info);
  }
  void add_attr(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>>> attr) {
    fbb_.AddOffset(Extra::VT_ATTR, attr);
  }
  explicit ExtraBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ExtraBuilder &operator=(const ExtraBuilder &);
  flatbuffers::Offset<Extra> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Extra>(end);
    return o;
  }
};

inline flatbuffers::Offset<Extra> CreateExtra(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> type = 0,
    flatbuffers::Offset<flatbuffers::String> engine = 0,
    flatbuffers::Offset<flatbuffers::Vector<int8_t>> info = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Attribute>>> attr = 0) {
  ExtraBuilder builder_(_fbb);
  builder_.add_attr(attr);
  builder_.add_info(info);
  builder_.add_engine(engine);
  builder_.add_type(type);
  return builder_.Finish();
}

inline flatbuffers::Offset<Extra> CreateExtraDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *type = nullptr,
    const char *engine = nullptr,
    const std::vector<int8_t> *info = nullptr,
    const std::vector<flatbuffers::Offset<MNN::Attribute>> *attr = nullptr) {
  auto type__ = type ? _fbb.CreateString(type) : 0;
  auto engine__ = engine ? _fbb.CreateString(engine) : 0;
  auto info__ = info ? _fbb.CreateVector<int8_t>(*info) : 0;
  auto attr__ = attr ? _fbb.CreateVector<flatbuffers::Offset<MNN::Attribute>>(*attr) : 0;
  return MNN::CreateExtra(
      _fbb,
      type__,
      engine__,
      info__,
      attr__);
}

flatbuffers::Offset<Extra> CreateExtra(flatbuffers::FlatBufferBuilder &_fbb, const ExtraT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct StringVecT : public flatbuffers::NativeTable {
  typedef StringVec TableType;
  std::vector<std::string> data;
  StringVecT() {
  }
};

struct StringVec FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef StringVecT NativeTableType;
  typedef StringVecBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return StringVecTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DATA = 4
  };
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *data() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_DATA);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_DATA) &&
           verifier.VerifyVector(data()) &&
           verifier.VerifyVectorOfStrings(data()) &&
           verifier.EndTable();
  }
  StringVecT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(StringVecT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<StringVec> Pack(flatbuffers::FlatBufferBuilder &_fbb, const StringVecT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct StringVecBuilder {
  typedef StringVec Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_data(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> data) {
    fbb_.AddOffset(StringVec::VT_DATA, data);
  }
  explicit StringVecBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  StringVecBuilder &operator=(const StringVecBuilder &);
  flatbuffers::Offset<StringVec> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<StringVec>(end);
    return o;
  }
};

inline flatbuffers::Offset<StringVec> CreateStringVec(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> data = 0) {
  StringVecBuilder builder_(_fbb);
  builder_.add_data(data);
  return builder_.Finish();
}

inline flatbuffers::Offset<StringVec> CreateStringVecDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *data = nullptr) {
  auto data__ = data ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*data) : 0;
  return MNN::CreateStringVec(
      _fbb,
      data__);
}

flatbuffers::Offset<StringVec> CreateStringVec(flatbuffers::FlatBufferBuilder &_fbb, const StringVecT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct WhileParamT : public flatbuffers::NativeTable {
  typedef WhileParam TableType;
  std::string cond_graph;
  std::string body_graph;
  std::vector<std::unique_ptr<MNN::StringVecT>> aliases_inputs;
  std::vector<std::string> aliases_outputs;
  std::vector<std::unique_ptr<MNN::StringVecT>> aliases_updates;
  WhileParamT() {
  }
};

struct WhileParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef WhileParamT NativeTableType;
  typedef WhileParamBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return WhileParamTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_COND_GRAPH = 4,
    VT_BODY_GRAPH = 6,
    VT_ALIASES_INPUTS = 8,
    VT_ALIASES_OUTPUTS = 10,
    VT_ALIASES_UPDATES = 12
  };
  const flatbuffers::String *cond_graph() const {
    return GetPointer<const flatbuffers::String *>(VT_COND_GRAPH);
  }
  const flatbuffers::String *body_graph() const {
    return GetPointer<const flatbuffers::String *>(VT_BODY_GRAPH);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *aliases_inputs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *>(VT_ALIASES_INPUTS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *aliases_outputs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_ALIASES_OUTPUTS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *aliases_updates() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *>(VT_ALIASES_UPDATES);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_COND_GRAPH) &&
           verifier.VerifyString(cond_graph()) &&
           VerifyOffset(verifier, VT_BODY_GRAPH) &&
           verifier.VerifyString(body_graph()) &&
           VerifyOffset(verifier, VT_ALIASES_INPUTS) &&
           verifier.VerifyVector(aliases_inputs()) &&
           verifier.VerifyVectorOfTables(aliases_inputs()) &&
           VerifyOffset(verifier, VT_ALIASES_OUTPUTS) &&
           verifier.VerifyVector(aliases_outputs()) &&
           verifier.VerifyVectorOfStrings(aliases_outputs()) &&
           VerifyOffset(verifier, VT_ALIASES_UPDATES) &&
           verifier.VerifyVector(aliases_updates()) &&
           verifier.VerifyVectorOfTables(aliases_updates()) &&
           verifier.EndTable();
  }
  WhileParamT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(WhileParamT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<WhileParam> Pack(flatbuffers::FlatBufferBuilder &_fbb, const WhileParamT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct WhileParamBuilder {
  typedef WhileParam Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_cond_graph(flatbuffers::Offset<flatbuffers::String> cond_graph) {
    fbb_.AddOffset(WhileParam::VT_COND_GRAPH, cond_graph);
  }
  void add_body_graph(flatbuffers::Offset<flatbuffers::String> body_graph) {
    fbb_.AddOffset(WhileParam::VT_BODY_GRAPH, body_graph);
  }
  void add_aliases_inputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_inputs) {
    fbb_.AddOffset(WhileParam::VT_ALIASES_INPUTS, aliases_inputs);
  }
  void add_aliases_outputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> aliases_outputs) {
    fbb_.AddOffset(WhileParam::VT_ALIASES_OUTPUTS, aliases_outputs);
  }
  void add_aliases_updates(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_updates) {
    fbb_.AddOffset(WhileParam::VT_ALIASES_UPDATES, aliases_updates);
  }
  explicit WhileParamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  WhileParamBuilder &operator=(const WhileParamBuilder &);
  flatbuffers::Offset<WhileParam> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<WhileParam>(end);
    return o;
  }
};

inline flatbuffers::Offset<WhileParam> CreateWhileParam(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> cond_graph = 0,
    flatbuffers::Offset<flatbuffers::String> body_graph = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_inputs = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> aliases_outputs = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_updates = 0) {
  WhileParamBuilder builder_(_fbb);
  builder_.add_aliases_updates(aliases_updates);
  builder_.add_aliases_outputs(aliases_outputs);
  builder_.add_aliases_inputs(aliases_inputs);
  builder_.add_body_graph(body_graph);
  builder_.add_cond_graph(cond_graph);
  return builder_.Finish();
}

inline flatbuffers::Offset<WhileParam> CreateWhileParamDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *cond_graph = nullptr,
    const char *body_graph = nullptr,
    const std::vector<flatbuffers::Offset<MNN::StringVec>> *aliases_inputs = nullptr,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *aliases_outputs = nullptr,
    const std::vector<flatbuffers::Offset<MNN::StringVec>> *aliases_updates = nullptr) {
  auto cond_graph__ = cond_graph ? _fbb.CreateString(cond_graph) : 0;
  auto body_graph__ = body_graph ? _fbb.CreateString(body_graph) : 0;
  auto aliases_inputs__ = aliases_inputs ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>>(*aliases_inputs) : 0;
  auto aliases_outputs__ = aliases_outputs ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*aliases_outputs) : 0;
  auto aliases_updates__ = aliases_updates ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>>(*aliases_updates) : 0;
  return MNN::CreateWhileParam(
      _fbb,
      cond_graph__,
      body_graph__,
      aliases_inputs__,
      aliases_outputs__,
      aliases_updates__);
}

flatbuffers::Offset<WhileParam> CreateWhileParam(flatbuffers::FlatBufferBuilder &_fbb, const WhileParamT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct IfParamT : public flatbuffers::NativeTable {
  typedef IfParam TableType;
  std::string then_graph;
  std::string else_graph;
  std::vector<std::unique_ptr<MNN::StringVecT>> aliases_inputs;
  std::vector<std::unique_ptr<MNN::StringVecT>> aliases_outputs;
  IfParamT() {
  }
};

struct IfParam FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef IfParamT NativeTableType;
  typedef IfParamBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return IfParamTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_THEN_GRAPH = 4,
    VT_ELSE_GRAPH = 6,
    VT_ALIASES_INPUTS = 8,
    VT_ALIASES_OUTPUTS = 10
  };
  const flatbuffers::String *then_graph() const {
    return GetPointer<const flatbuffers::String *>(VT_THEN_GRAPH);
  }
  const flatbuffers::String *else_graph() const {
    return GetPointer<const flatbuffers::String *>(VT_ELSE_GRAPH);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *aliases_inputs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *>(VT_ALIASES_INPUTS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *aliases_outputs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>> *>(VT_ALIASES_OUTPUTS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_THEN_GRAPH) &&
           verifier.VerifyString(then_graph()) &&
           VerifyOffset(verifier, VT_ELSE_GRAPH) &&
           verifier.VerifyString(else_graph()) &&
           VerifyOffset(verifier, VT_ALIASES_INPUTS) &&
           verifier.VerifyVector(aliases_inputs()) &&
           verifier.VerifyVectorOfTables(aliases_inputs()) &&
           VerifyOffset(verifier, VT_ALIASES_OUTPUTS) &&
           verifier.VerifyVector(aliases_outputs()) &&
           verifier.VerifyVectorOfTables(aliases_outputs()) &&
           verifier.EndTable();
  }
  IfParamT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(IfParamT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<IfParam> Pack(flatbuffers::FlatBufferBuilder &_fbb, const IfParamT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct IfParamBuilder {
  typedef IfParam Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_then_graph(flatbuffers::Offset<flatbuffers::String> then_graph) {
    fbb_.AddOffset(IfParam::VT_THEN_GRAPH, then_graph);
  }
  void add_else_graph(flatbuffers::Offset<flatbuffers::String> else_graph) {
    fbb_.AddOffset(IfParam::VT_ELSE_GRAPH, else_graph);
  }
  void add_aliases_inputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_inputs) {
    fbb_.AddOffset(IfParam::VT_ALIASES_INPUTS, aliases_inputs);
  }
  void add_aliases_outputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_outputs) {
    fbb_.AddOffset(IfParam::VT_ALIASES_OUTPUTS, aliases_outputs);
  }
  explicit IfParamBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  IfParamBuilder &operator=(const IfParamBuilder &);
  flatbuffers::Offset<IfParam> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<IfParam>(end);
    return o;
  }
};

inline flatbuffers::Offset<IfParam> CreateIfParam(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> then_graph = 0,
    flatbuffers::Offset<flatbuffers::String> else_graph = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_inputs = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::StringVec>>> aliases_outputs = 0) {
  IfParamBuilder builder_(_fbb);
  builder_.add_aliases_outputs(aliases_outputs);
  builder_.add_aliases_inputs(aliases_inputs);
  builder_.add_else_graph(else_graph);
  builder_.add_then_graph(then_graph);
  return builder_.Finish();
}

inline flatbuffers::Offset<IfParam> CreateIfParamDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *then_graph = nullptr,
    const char *else_graph = nullptr,
    const std::vector<flatbuffers::Offset<MNN::StringVec>> *aliases_inputs = nullptr,
    const std::vector<flatbuffers::Offset<MNN::StringVec>> *aliases_outputs = nullptr) {
  auto then_graph__ = then_graph ? _fbb.CreateString(then_graph) : 0;
  auto else_graph__ = else_graph ? _fbb.CreateString(else_graph) : 0;
  auto aliases_inputs__ = aliases_inputs ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>>(*aliases_inputs) : 0;
  auto aliases_outputs__ = aliases_outputs ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>>(*aliases_outputs) : 0;
  return MNN::CreateIfParam(
      _fbb,
      then_graph__,
      else_graph__,
      aliases_inputs__,
      aliases_outputs__);
}

flatbuffers::Offset<IfParam> CreateIfParam(flatbuffers::FlatBufferBuilder &_fbb, const IfParamT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct OpT : public flatbuffers::NativeTable {
  typedef Op TableType;
  std::vector<int32_t> inputIndexes;
  MNN::OpParameterUnion main;
  std::string name;
  std::vector<int32_t> outputIndexes;
  MNN::OpType type;
  MNN::MNN_DATA_FORMAT defaultDimentionFormat;
  OpT()
      : type(MNN::OpType_AbsVal),
        defaultDimentionFormat(MNN::MNN_DATA_FORMAT_NHWC) {
  }
};

struct Op FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef OpT NativeTableType;
  typedef OpBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return OpTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_INPUTINDEXES = 4,
    VT_MAIN_TYPE = 6,
    VT_MAIN = 8,
    VT_NAME = 10,
    VT_OUTPUTINDEXES = 12,
    VT_TYPE = 14,
    VT_DEFAULTDIMENTIONFORMAT = 16
  };
  const flatbuffers::Vector<int32_t> *inputIndexes() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_INPUTINDEXES);
  }
  MNN::OpParameter main_type() const {
    return static_cast<MNN::OpParameter>(GetField<uint8_t>(VT_MAIN_TYPE, 0));
  }
  const void *main() const {
    return GetPointer<const void *>(VT_MAIN);
  }
  template<typename T> const T *main_as() const;
  const MNN::QuantizedAdd *main_as_QuantizedAdd() const {
    return main_type() == MNN::OpParameter_QuantizedAdd ? static_cast<const MNN::QuantizedAdd *>(main()) : nullptr;
  }
  const MNN::ArgMax *main_as_ArgMax() const {
    return main_type() == MNN::OpParameter_ArgMax ? static_cast<const MNN::ArgMax *>(main()) : nullptr;
  }
  const MNN::AsString *main_as_AsString() const {
    return main_type() == MNN::OpParameter_AsString ? static_cast<const MNN::AsString *>(main()) : nullptr;
  }
  const MNN::Axis *main_as_Axis() const {
    return main_type() == MNN::OpParameter_Axis ? static_cast<const MNN::Axis *>(main()) : nullptr;
  }
  const MNN::BatchNorm *main_as_BatchNorm() const {
    return main_type() == MNN::OpParameter_BatchNorm ? static_cast<const MNN::BatchNorm *>(main()) : nullptr;
  }
  const MNN::BinaryOp *main_as_BinaryOp() const {
    return main_type() == MNN::OpParameter_BinaryOp ? static_cast<const MNN::BinaryOp *>(main()) : nullptr;
  }
  const MNN::Blob *main_as_Blob() const {
    return main_type() == MNN::OpParameter_Blob ? static_cast<const MNN::Blob *>(main()) : nullptr;
  }
  const MNN::CastParam *main_as_CastParam() const {
    return main_type() == MNN::OpParameter_CastParam ? static_cast<const MNN::CastParam *>(main()) : nullptr;
  }
  const MNN::Convolution2D *main_as_Convolution2D() const {
    return main_type() == MNN::OpParameter_Convolution2D ? static_cast<const MNN::Convolution2D *>(main()) : nullptr;
  }
  const MNN::Crop *main_as_Crop() const {
    return main_type() == MNN::OpParameter_Crop ? static_cast<const MNN::Crop *>(main()) : nullptr;
  }
  const MNN::CropAndResize *main_as_CropAndResize() const {
    return main_type() == MNN::OpParameter_CropAndResize ? static_cast<const MNN::CropAndResize *>(main()) : nullptr;
  }
  const MNN::Dequantize *main_as_Dequantize() const {
    return main_type() == MNN::OpParameter_Dequantize ? static_cast<const MNN::Dequantize *>(main()) : nullptr;
  }
  const MNN::DetectionOutput *main_as_DetectionOutput() const {
    return main_type() == MNN::OpParameter_DetectionOutput ? static_cast<const MNN::DetectionOutput *>(main()) : nullptr;
  }
  const MNN::Eltwise *main_as_Eltwise() const {
    return main_type() == MNN::OpParameter_Eltwise ? static_cast<const MNN::Eltwise *>(main()) : nullptr;
  }
  const MNN::ExpandDims *main_as_ExpandDims() const {
    return main_type() == MNN::OpParameter_ExpandDims ? static_cast<const MNN::ExpandDims *>(main()) : nullptr;
  }
  const MNN::Fill *main_as_Fill() const {
    return main_type() == MNN::OpParameter_Fill ? static_cast<const MNN::Fill *>(main()) : nullptr;
  }
  const MNN::Flatten *main_as_Flatten() const {
    return main_type() == MNN::OpParameter_Flatten ? static_cast<const MNN::Flatten *>(main()) : nullptr;
  }
  const MNN::Gather *main_as_Gather() const {
    return main_type() == MNN::OpParameter_Gather ? static_cast<const MNN::Gather *>(main()) : nullptr;
  }
  const MNN::GatherV2 *main_as_GatherV2() const {
    return main_type() == MNN::OpParameter_GatherV2 ? static_cast<const MNN::GatherV2 *>(main()) : nullptr;
  }
  const MNN::InnerProduct *main_as_InnerProduct() const {
    return main_type() == MNN::OpParameter_InnerProduct ? static_cast<const MNN::InnerProduct *>(main()) : nullptr;
  }
  const MNN::Input *main_as_Input() const {
    return main_type() == MNN::OpParameter_Input ? static_cast<const MNN::Input *>(main()) : nullptr;
  }
  const MNN::Interp *main_as_Interp() const {
    return main_type() == MNN::OpParameter_Interp ? static_cast<const MNN::Interp *>(main()) : nullptr;
  }
  const MNN::LRN *main_as_LRN() const {
    return main_type() == MNN::OpParameter_LRN ? static_cast<const MNN::LRN *>(main()) : nullptr;
  }
  const MNN::LSTM *main_as_LSTM() const {
    return main_type() == MNN::OpParameter_LSTM ? static_cast<const MNN::LSTM *>(main()) : nullptr;
  }
  const MNN::MatMul *main_as_MatMul() const {
    return main_type() == MNN::OpParameter_MatMul ? static_cast<const MNN::MatMul *>(main()) : nullptr;
  }
  const MNN::NonMaxSuppressionV2 *main_as_NonMaxSuppressionV2() const {
    return main_type() == MNN::OpParameter_NonMaxSuppressionV2 ? static_cast<const MNN::NonMaxSuppressionV2 *>(main()) : nullptr;
  }
  const MNN::Normalize *main_as_Normalize() const {
    return main_type() == MNN::OpParameter_Normalize ? static_cast<const MNN::Normalize *>(main()) : nullptr;
  }
  const MNN::PackParam *main_as_PackParam() const {
    return main_type() == MNN::OpParameter_PackParam ? static_cast<const MNN::PackParam *>(main()) : nullptr;
  }
  const MNN::Permute *main_as_Permute() const {
    return main_type() == MNN::OpParameter_Permute ? static_cast<const MNN::Permute *>(main()) : nullptr;
  }
  const MNN::Plugin *main_as_Plugin() const {
    return main_type() == MNN::OpParameter_Plugin ? static_cast<const MNN::Plugin *>(main()) : nullptr;
  }
  const MNN::Pool *main_as_Pool() const {
    return main_type() == MNN::OpParameter_Pool ? static_cast<const MNN::Pool *>(main()) : nullptr;
  }
  const MNN::PRelu *main_as_PRelu() const {
    return main_type() == MNN::OpParameter_PRelu ? static_cast<const MNN::PRelu *>(main()) : nullptr;
  }
  const MNN::PriorBox *main_as_PriorBox() const {
    return main_type() == MNN::OpParameter_PriorBox ? static_cast<const MNN::PriorBox *>(main()) : nullptr;
  }
  const MNN::Proposal *main_as_Proposal() const {
    return main_type() == MNN::OpParameter_Proposal ? static_cast<const MNN::Proposal *>(main()) : nullptr;
  }
  const MNN::QuantizedAvgPool *main_as_QuantizedAvgPool() const {
    return main_type() == MNN::OpParameter_QuantizedAvgPool ? static_cast<const MNN::QuantizedAvgPool *>(main()) : nullptr;
  }
  const MNN::QuantizedBiasAdd *main_as_QuantizedBiasAdd() const {
    return main_type() == MNN::OpParameter_QuantizedBiasAdd ? static_cast<const MNN::QuantizedBiasAdd *>(main()) : nullptr;
  }
  const MNN::QuantizedConcat *main_as_QuantizedConcat() const {
    return main_type() == MNN::OpParameter_QuantizedConcat ? static_cast<const MNN::QuantizedConcat *>(main()) : nullptr;
  }
  const MNN::QuantizedLogistic *main_as_QuantizedLogistic() const {
    return main_type() == MNN::OpParameter_QuantizedLogistic ? static_cast<const MNN::QuantizedLogistic *>(main()) : nullptr;
  }
  const MNN::QuantizedMatMul *main_as_QuantizedMatMul() const {
    return main_type() == MNN::OpParameter_QuantizedMatMul ? static_cast<const MNN::QuantizedMatMul *>(main()) : nullptr;
  }
  const MNN::QuantizedMaxPool *main_as_QuantizedMaxPool() const {
    return main_type() == MNN::OpParameter_QuantizedMaxPool ? static_cast<const MNN::QuantizedMaxPool *>(main()) : nullptr;
  }
  const MNN::QuantizedRelu *main_as_QuantizedRelu() const {
    return main_type() == MNN::OpParameter_QuantizedRelu ? static_cast<const MNN::QuantizedRelu *>(main()) : nullptr;
  }
  const MNN::QuantizedRelu6 *main_as_QuantizedRelu6() const {
    return main_type() == MNN::OpParameter_QuantizedRelu6 ? static_cast<const MNN::QuantizedRelu6 *>(main()) : nullptr;
  }
  const MNN::QuantizedReshape *main_as_QuantizedReshape() const {
    return main_type() == MNN::OpParameter_QuantizedReshape ? static_cast<const MNN::QuantizedReshape *>(main()) : nullptr;
  }
  const MNN::QuantizedSoftmax *main_as_QuantizedSoftmax() const {
    return main_type() == MNN::OpParameter_QuantizedSoftmax ? static_cast<const MNN::QuantizedSoftmax *>(main()) : nullptr;
  }
  const MNN::QuantizeMaxMin *main_as_QuantizeMaxMin() const {
    return main_type() == MNN::OpParameter_QuantizeMaxMin ? static_cast<const MNN::QuantizeMaxMin *>(main()) : nullptr;
  }
  const MNN::QuantizeV2 *main_as_QuantizeV2() const {
    return main_type() == MNN::OpParameter_QuantizeV2 ? static_cast<const MNN::QuantizeV2 *>(main()) : nullptr;
  }
  const MNN::Range *main_as_Range() const {
    return main_type() == MNN::OpParameter_Range ? static_cast<const MNN::Range *>(main()) : nullptr;
  }
  const MNN::Rank *main_as_Rank() const {
    return main_type() == MNN::OpParameter_Rank ? static_cast<const MNN::Rank *>(main()) : nullptr;
  }
  const MNN::ReduceJoin *main_as_ReduceJoin() const {
    return main_type() == MNN::OpParameter_ReduceJoin ? static_cast<const MNN::ReduceJoin *>(main()) : nullptr;
  }
  const MNN::ReductionParam *main_as_ReductionParam() const {
    return main_type() == MNN::OpParameter_ReductionParam ? static_cast<const MNN::ReductionParam *>(main()) : nullptr;
  }
  const MNN::Relu *main_as_Relu() const {
    return main_type() == MNN::OpParameter_Relu ? static_cast<const MNN::Relu *>(main()) : nullptr;
  }
  const MNN::Relu6 *main_as_Relu6() const {
    return main_type() == MNN::OpParameter_Relu6 ? static_cast<const MNN::Relu6 *>(main()) : nullptr;
  }
  const MNN::RequantizationRange *main_as_RequantizationRange() const {
    return main_type() == MNN::OpParameter_RequantizationRange ? static_cast<const MNN::RequantizationRange *>(main()) : nullptr;
  }
  const MNN::Requantize *main_as_Requantize() const {
    return main_type() == MNN::OpParameter_Requantize ? static_cast<const MNN::Requantize *>(main()) : nullptr;
  }
  const MNN::Reshape *main_as_Reshape() const {
    return main_type() == MNN::OpParameter_Reshape ? static_cast<const MNN::Reshape *>(main()) : nullptr;
  }
  const MNN::Resize *main_as_Resize() const {
    return main_type() == MNN::OpParameter_Resize ? static_cast<const MNN::Resize *>(main()) : nullptr;
  }
  const MNN::RoiPooling *main_as_RoiPooling() const {
    return main_type() == MNN::OpParameter_RoiPooling ? static_cast<const MNN::RoiPooling *>(main()) : nullptr;
  }
  const MNN::Scale *main_as_Scale() const {
    return main_type() == MNN::OpParameter_Scale ? static_cast<const MNN::Scale *>(main()) : nullptr;
  }
  const MNN::Selu *main_as_Selu() const {
    return main_type() == MNN::OpParameter_Selu ? static_cast<const MNN::Selu *>(main()) : nullptr;
  }
  const MNN::Size *main_as_Size() const {
    return main_type() == MNN::OpParameter_Size ? static_cast<const MNN::Size *>(main()) : nullptr;
  }
  const MNN::Slice *main_as_Slice() const {
    return main_type() == MNN::OpParameter_Slice ? static_cast<const MNN::Slice *>(main()) : nullptr;
  }
  const MNN::SliceTf *main_as_SliceTf() const {
    return main_type() == MNN::OpParameter_SliceTf ? static_cast<const MNN::SliceTf *>(main()) : nullptr;
  }
  const MNN::SpaceBatch *main_as_SpaceBatch() const {
    return main_type() == MNN::OpParameter_SpaceBatch ? static_cast<const MNN::SpaceBatch *>(main()) : nullptr;
  }
  const MNN::SqueezeParam *main_as_SqueezeParam() const {
    return main_type() == MNN::OpParameter_SqueezeParam ? static_cast<const MNN::SqueezeParam *>(main()) : nullptr;
  }
  const MNN::StridedSliceParam *main_as_StridedSliceParam() const {
    return main_type() == MNN::OpParameter_StridedSliceParam ? static_cast<const MNN::StridedSliceParam *>(main()) : nullptr;
  }
  const MNN::TensorConvertInfo *main_as_TensorConvertInfo() const {
    return main_type() == MNN::OpParameter_TensorConvertInfo ? static_cast<const MNN::TensorConvertInfo *>(main()) : nullptr;
  }
  const MNN::TfQuantizedConv2D *main_as_TfQuantizedConv2D() const {
    return main_type() == MNN::OpParameter_TfQuantizedConv2D ? static_cast<const MNN::TfQuantizedConv2D *>(main()) : nullptr;
  }
  const MNN::TopKV2 *main_as_TopKV2() const {
    return main_type() == MNN::OpParameter_TopKV2 ? static_cast<const MNN::TopKV2 *>(main()) : nullptr;
  }
  const MNN::Transpose *main_as_Transpose() const {
    return main_type() == MNN::OpParameter_Transpose ? static_cast<const MNN::Transpose *>(main()) : nullptr;
  }
  const MNN::UnaryOp *main_as_UnaryOp() const {
    return main_type() == MNN::OpParameter_UnaryOp ? static_cast<const MNN::UnaryOp *>(main()) : nullptr;
  }
  const MNN::MomentsParam *main_as_MomentsParam() const {
    return main_type() == MNN::OpParameter_MomentsParam ? static_cast<const MNN::MomentsParam *>(main()) : nullptr;
  }
  const MNN::RNNParam *main_as_RNNParam() const {
    return main_type() == MNN::OpParameter_RNNParam ? static_cast<const MNN::RNNParam *>(main()) : nullptr;
  }
  const MNN::BatchMatMulParam *main_as_BatchMatMulParam() const {
    return main_type() == MNN::OpParameter_BatchMatMulParam ? static_cast<const MNN::BatchMatMulParam *>(main()) : nullptr;
  }
  const MNN::QuantizedFloatParam *main_as_QuantizedFloatParam() const {
    return main_type() == MNN::OpParameter_QuantizedFloatParam ? static_cast<const MNN::QuantizedFloatParam *>(main()) : nullptr;
  }
  const MNN::DepthSpaceParam *main_as_DepthSpaceParam() const {
    return main_type() == MNN::OpParameter_DepthSpaceParam ? static_cast<const MNN::DepthSpaceParam *>(main()) : nullptr;
  }
  const MNN::EltwiseInt8 *main_as_EltwiseInt8() const {
    return main_type() == MNN::OpParameter_EltwiseInt8 ? static_cast<const MNN::EltwiseInt8 *>(main()) : nullptr;
  }
  const MNN::ReverseSequenceParam *main_as_ReverseSequenceParam() const {
    return main_type() == MNN::OpParameter_ReverseSequenceParam ? static_cast<const MNN::ReverseSequenceParam *>(main()) : nullptr;
  }
  const MNN::Extra *main_as_Extra() const {
    return main_type() == MNN::OpParameter_Extra ? static_cast<const MNN::Extra *>(main()) : nullptr;
  }
  const MNN::Pool3D *main_as_Pool3D() const {
    return main_type() == MNN::OpParameter_Pool3D ? static_cast<const MNN::Pool3D *>(main()) : nullptr;
  }
  const MNN::Convolution3D *main_as_Convolution3D() const {
    return main_type() == MNN::OpParameter_Convolution3D ? static_cast<const MNN::Convolution3D *>(main()) : nullptr;
  }
  const MNN::ELU *main_as_ELU() const {
    return main_type() == MNN::OpParameter_ELU ? static_cast<const MNN::ELU *>(main()) : nullptr;
  }
  const MNN::DetectionPostProcessParam *main_as_DetectionPostProcessParam() const {
    return main_type() == MNN::OpParameter_DetectionPostProcessParam ? static_cast<const MNN::DetectionPostProcessParam *>(main()) : nullptr;
  }
  const MNN::OneHotParam *main_as_OneHotParam() const {
    return main_type() == MNN::OpParameter_OneHotParam ? static_cast<const MNN::OneHotParam *>(main()) : nullptr;
  }
  const MNN::PadParam *main_as_PadParam() const {
    return main_type() == MNN::OpParameter_PadParam ? static_cast<const MNN::PadParam *>(main()) : nullptr;
  }
  const MNN::WhileParam *main_as_WhileParam() const {
    return main_type() == MNN::OpParameter_WhileParam ? static_cast<const MNN::WhileParam *>(main()) : nullptr;
  }
  const MNN::IfParam *main_as_IfParam() const {
    return main_type() == MNN::OpParameter_IfParam ? static_cast<const MNN::IfParam *>(main()) : nullptr;
  }
  const MNN::RandomUniform *main_as_RandomUniform() const {
    return main_type() == MNN::OpParameter_RandomUniform ? static_cast<const MNN::RandomUniform *>(main()) : nullptr;
  }
  const MNN::LayerNorm *main_as_LayerNorm() const {
    return main_type() == MNN::OpParameter_LayerNorm ? static_cast<const MNN::LayerNorm *>(main()) : nullptr;
  }
  const MNN::TensorArray *main_as_TensorArray() const {
    return main_type() == MNN::OpParameter_TensorArray ? static_cast<const MNN::TensorArray *>(main()) : nullptr;
  }
  const MNN::LSTMBlockCell *main_as_LSTMBlockCell() const {
    return main_type() == MNN::OpParameter_LSTMBlockCell ? static_cast<const MNN::LSTMBlockCell *>(main()) : nullptr;
  }
  const MNN::GridSample *main_as_GridSample() const {
    return main_type() == MNN::OpParameter_GridSample ? static_cast<const MNN::GridSample *>(main()) : nullptr;
  }
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  const flatbuffers::Vector<int32_t> *outputIndexes() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_OUTPUTINDEXES);
  }
  MNN::OpType type() const {
    return static_cast<MNN::OpType>(GetField<int32_t>(VT_TYPE, 0));
  }
  MNN::MNN_DATA_FORMAT defaultDimentionFormat() const {
    return static_cast<MNN::MNN_DATA_FORMAT>(GetField<int8_t>(VT_DEFAULTDIMENTIONFORMAT, 1));
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUTINDEXES) &&
           verifier.VerifyVector(inputIndexes()) &&
           VerifyField<uint8_t>(verifier, VT_MAIN_TYPE) &&
           VerifyOffset(verifier, VT_MAIN) &&
           VerifyOpParameter(verifier, main(), main_type()) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyOffset(verifier, VT_OUTPUTINDEXES) &&
           verifier.VerifyVector(outputIndexes()) &&
           VerifyField<int32_t>(verifier, VT_TYPE) &&
           VerifyField<int8_t>(verifier, VT_DEFAULTDIMENTIONFORMAT) &&
           verifier.EndTable();
  }
  OpT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(OpT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Op> Pack(flatbuffers::FlatBufferBuilder &_fbb, const OpT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

template<> inline const MNN::QuantizedAdd *Op::main_as<MNN::QuantizedAdd>() const {
  return main_as_QuantizedAdd();
}

template<> inline const MNN::ArgMax *Op::main_as<MNN::ArgMax>() const {
  return main_as_ArgMax();
}

template<> inline const MNN::AsString *Op::main_as<MNN::AsString>() const {
  return main_as_AsString();
}

template<> inline const MNN::Axis *Op::main_as<MNN::Axis>() const {
  return main_as_Axis();
}

template<> inline const MNN::BatchNorm *Op::main_as<MNN::BatchNorm>() const {
  return main_as_BatchNorm();
}

template<> inline const MNN::BinaryOp *Op::main_as<MNN::BinaryOp>() const {
  return main_as_BinaryOp();
}

template<> inline const MNN::Blob *Op::main_as<MNN::Blob>() const {
  return main_as_Blob();
}

template<> inline const MNN::CastParam *Op::main_as<MNN::CastParam>() const {
  return main_as_CastParam();
}

template<> inline const MNN::Convolution2D *Op::main_as<MNN::Convolution2D>() const {
  return main_as_Convolution2D();
}

template<> inline const MNN::Crop *Op::main_as<MNN::Crop>() const {
  return main_as_Crop();
}

template<> inline const MNN::CropAndResize *Op::main_as<MNN::CropAndResize>() const {
  return main_as_CropAndResize();
}

template<> inline const MNN::Dequantize *Op::main_as<MNN::Dequantize>() const {
  return main_as_Dequantize();
}

template<> inline const MNN::DetectionOutput *Op::main_as<MNN::DetectionOutput>() const {
  return main_as_DetectionOutput();
}

template<> inline const MNN::Eltwise *Op::main_as<MNN::Eltwise>() const {
  return main_as_Eltwise();
}

template<> inline const MNN::ExpandDims *Op::main_as<MNN::ExpandDims>() const {
  return main_as_ExpandDims();
}

template<> inline const MNN::Fill *Op::main_as<MNN::Fill>() const {
  return main_as_Fill();
}

template<> inline const MNN::Flatten *Op::main_as<MNN::Flatten>() const {
  return main_as_Flatten();
}

template<> inline const MNN::Gather *Op::main_as<MNN::Gather>() const {
  return main_as_Gather();
}

template<> inline const MNN::GatherV2 *Op::main_as<MNN::GatherV2>() const {
  return main_as_GatherV2();
}

template<> inline const MNN::InnerProduct *Op::main_as<MNN::InnerProduct>() const {
  return main_as_InnerProduct();
}

template<> inline const MNN::Input *Op::main_as<MNN::Input>() const {
  return main_as_Input();
}

template<> inline const MNN::Interp *Op::main_as<MNN::Interp>() const {
  return main_as_Interp();
}

template<> inline const MNN::LRN *Op::main_as<MNN::LRN>() const {
  return main_as_LRN();
}

template<> inline const MNN::LSTM *Op::main_as<MNN::LSTM>() const {
  return main_as_LSTM();
}

template<> inline const MNN::MatMul *Op::main_as<MNN::MatMul>() const {
  return main_as_MatMul();
}

template<> inline const MNN::NonMaxSuppressionV2 *Op::main_as<MNN::NonMaxSuppressionV2>() const {
  return main_as_NonMaxSuppressionV2();
}

template<> inline const MNN::Normalize *Op::main_as<MNN::Normalize>() const {
  return main_as_Normalize();
}

template<> inline const MNN::PackParam *Op::main_as<MNN::PackParam>() const {
  return main_as_PackParam();
}

template<> inline const MNN::Permute *Op::main_as<MNN::Permute>() const {
  return main_as_Permute();
}

template<> inline const MNN::Plugin *Op::main_as<MNN::Plugin>() const {
  return main_as_Plugin();
}

template<> inline const MNN::Pool *Op::main_as<MNN::Pool>() const {
  return main_as_Pool();
}

template<> inline const MNN::PRelu *Op::main_as<MNN::PRelu>() const {
  return main_as_PRelu();
}

template<> inline const MNN::PriorBox *Op::main_as<MNN::PriorBox>() const {
  return main_as_PriorBox();
}

template<> inline const MNN::Proposal *Op::main_as<MNN::Proposal>() const {
  return main_as_Proposal();
}

template<> inline const MNN::QuantizedAvgPool *Op::main_as<MNN::QuantizedAvgPool>() const {
  return main_as_QuantizedAvgPool();
}

template<> inline const MNN::QuantizedBiasAdd *Op::main_as<MNN::QuantizedBiasAdd>() const {
  return main_as_QuantizedBiasAdd();
}

template<> inline const MNN::QuantizedConcat *Op::main_as<MNN::QuantizedConcat>() const {
  return main_as_QuantizedConcat();
}

template<> inline const MNN::QuantizedLogistic *Op::main_as<MNN::QuantizedLogistic>() const {
  return main_as_QuantizedLogistic();
}

template<> inline const MNN::QuantizedMatMul *Op::main_as<MNN::QuantizedMatMul>() const {
  return main_as_QuantizedMatMul();
}

template<> inline const MNN::QuantizedMaxPool *Op::main_as<MNN::QuantizedMaxPool>() const {
  return main_as_QuantizedMaxPool();
}

template<> inline const MNN::QuantizedRelu *Op::main_as<MNN::QuantizedRelu>() const {
  return main_as_QuantizedRelu();
}

template<> inline const MNN::QuantizedRelu6 *Op::main_as<MNN::QuantizedRelu6>() const {
  return main_as_QuantizedRelu6();
}

template<> inline const MNN::QuantizedReshape *Op::main_as<MNN::QuantizedReshape>() const {
  return main_as_QuantizedReshape();
}

template<> inline const MNN::QuantizedSoftmax *Op::main_as<MNN::QuantizedSoftmax>() const {
  return main_as_QuantizedSoftmax();
}

template<> inline const MNN::QuantizeMaxMin *Op::main_as<MNN::QuantizeMaxMin>() const {
  return main_as_QuantizeMaxMin();
}

template<> inline const MNN::QuantizeV2 *Op::main_as<MNN::QuantizeV2>() const {
  return main_as_QuantizeV2();
}

template<> inline const MNN::Range *Op::main_as<MNN::Range>() const {
  return main_as_Range();
}

template<> inline const MNN::Rank *Op::main_as<MNN::Rank>() const {
  return main_as_Rank();
}

template<> inline const MNN::ReduceJoin *Op::main_as<MNN::ReduceJoin>() const {
  return main_as_ReduceJoin();
}

template<> inline const MNN::ReductionParam *Op::main_as<MNN::ReductionParam>() const {
  return main_as_ReductionParam();
}

template<> inline const MNN::Relu *Op::main_as<MNN::Relu>() const {
  return main_as_Relu();
}

template<> inline const MNN::Relu6 *Op::main_as<MNN::Relu6>() const {
  return main_as_Relu6();
}

template<> inline const MNN::RequantizationRange *Op::main_as<MNN::RequantizationRange>() const {
  return main_as_RequantizationRange();
}

template<> inline const MNN::Requantize *Op::main_as<MNN::Requantize>() const {
  return main_as_Requantize();
}

template<> inline const MNN::Reshape *Op::main_as<MNN::Reshape>() const {
  return main_as_Reshape();
}

template<> inline const MNN::Resize *Op::main_as<MNN::Resize>() const {
  return main_as_Resize();
}

template<> inline const MNN::RoiPooling *Op::main_as<MNN::RoiPooling>() const {
  return main_as_RoiPooling();
}

template<> inline const MNN::Scale *Op::main_as<MNN::Scale>() const {
  return main_as_Scale();
}

template<> inline const MNN::Selu *Op::main_as<MNN::Selu>() const {
  return main_as_Selu();
}

template<> inline const MNN::Size *Op::main_as<MNN::Size>() const {
  return main_as_Size();
}

template<> inline const MNN::Slice *Op::main_as<MNN::Slice>() const {
  return main_as_Slice();
}

template<> inline const MNN::SliceTf *Op::main_as<MNN::SliceTf>() const {
  return main_as_SliceTf();
}

template<> inline const MNN::SpaceBatch *Op::main_as<MNN::SpaceBatch>() const {
  return main_as_SpaceBatch();
}

template<> inline const MNN::SqueezeParam *Op::main_as<MNN::SqueezeParam>() const {
  return main_as_SqueezeParam();
}

template<> inline const MNN::StridedSliceParam *Op::main_as<MNN::StridedSliceParam>() const {
  return main_as_StridedSliceParam();
}

template<> inline const MNN::TensorConvertInfo *Op::main_as<MNN::TensorConvertInfo>() const {
  return main_as_TensorConvertInfo();
}

template<> inline const MNN::TfQuantizedConv2D *Op::main_as<MNN::TfQuantizedConv2D>() const {
  return main_as_TfQuantizedConv2D();
}

template<> inline const MNN::TopKV2 *Op::main_as<MNN::TopKV2>() const {
  return main_as_TopKV2();
}

template<> inline const MNN::Transpose *Op::main_as<MNN::Transpose>() const {
  return main_as_Transpose();
}

template<> inline const MNN::UnaryOp *Op::main_as<MNN::UnaryOp>() const {
  return main_as_UnaryOp();
}

template<> inline const MNN::MomentsParam *Op::main_as<MNN::MomentsParam>() const {
  return main_as_MomentsParam();
}

template<> inline const MNN::RNNParam *Op::main_as<MNN::RNNParam>() const {
  return main_as_RNNParam();
}

template<> inline const MNN::BatchMatMulParam *Op::main_as<MNN::BatchMatMulParam>() const {
  return main_as_BatchMatMulParam();
}

template<> inline const MNN::QuantizedFloatParam *Op::main_as<MNN::QuantizedFloatParam>() const {
  return main_as_QuantizedFloatParam();
}

template<> inline const MNN::DepthSpaceParam *Op::main_as<MNN::DepthSpaceParam>() const {
  return main_as_DepthSpaceParam();
}

template<> inline const MNN::EltwiseInt8 *Op::main_as<MNN::EltwiseInt8>() const {
  return main_as_EltwiseInt8();
}

template<> inline const MNN::ReverseSequenceParam *Op::main_as<MNN::ReverseSequenceParam>() const {
  return main_as_ReverseSequenceParam();
}

template<> inline const MNN::Extra *Op::main_as<MNN::Extra>() const {
  return main_as_Extra();
}

template<> inline const MNN::Pool3D *Op::main_as<MNN::Pool3D>() const {
  return main_as_Pool3D();
}

template<> inline const MNN::Convolution3D *Op::main_as<MNN::Convolution3D>() const {
  return main_as_Convolution3D();
}

template<> inline const MNN::ELU *Op::main_as<MNN::ELU>() const {
  return main_as_ELU();
}

template<> inline const MNN::DetectionPostProcessParam *Op::main_as<MNN::DetectionPostProcessParam>() const {
  return main_as_DetectionPostProcessParam();
}

template<> inline const MNN::OneHotParam *Op::main_as<MNN::OneHotParam>() const {
  return main_as_OneHotParam();
}

template<> inline const MNN::PadParam *Op::main_as<MNN::PadParam>() const {
  return main_as_PadParam();
}

template<> inline const MNN::WhileParam *Op::main_as<MNN::WhileParam>() const {
  return main_as_WhileParam();
}

template<> inline const MNN::IfParam *Op::main_as<MNN::IfParam>() const {
  return main_as_IfParam();
}

template<> inline const MNN::RandomUniform *Op::main_as<MNN::RandomUniform>() const {
  return main_as_RandomUniform();
}

template<> inline const MNN::LayerNorm *Op::main_as<MNN::LayerNorm>() const {
  return main_as_LayerNorm();
}

template<> inline const MNN::TensorArray *Op::main_as<MNN::TensorArray>() const {
  return main_as_TensorArray();
}

template<> inline const MNN::LSTMBlockCell *Op::main_as<MNN::LSTMBlockCell>() const {
  return main_as_LSTMBlockCell();
}

template<> inline const MNN::GridSample *Op::main_as<MNN::GridSample>() const {
  return main_as_GridSample();
}

struct OpBuilder {
  typedef Op Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_inputIndexes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputIndexes) {
    fbb_.AddOffset(Op::VT_INPUTINDEXES, inputIndexes);
  }
  void add_main_type(MNN::OpParameter main_type) {
    fbb_.AddElement<uint8_t>(Op::VT_MAIN_TYPE, static_cast<uint8_t>(main_type), 0);
  }
  void add_main(flatbuffers::Offset<void> main) {
    fbb_.AddOffset(Op::VT_MAIN, main);
  }
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(Op::VT_NAME, name);
  }
  void add_outputIndexes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputIndexes) {
    fbb_.AddOffset(Op::VT_OUTPUTINDEXES, outputIndexes);
  }
  void add_type(MNN::OpType type) {
    fbb_.AddElement<int32_t>(Op::VT_TYPE, static_cast<int32_t>(type), 0);
  }
  void add_defaultDimentionFormat(MNN::MNN_DATA_FORMAT defaultDimentionFormat) {
    fbb_.AddElement<int8_t>(Op::VT_DEFAULTDIMENTIONFORMAT, static_cast<int8_t>(defaultDimentionFormat), 1);
  }
  explicit OpBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  OpBuilder &operator=(const OpBuilder &);
  flatbuffers::Offset<Op> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Op>(end);
    return o;
  }
};

inline flatbuffers::Offset<Op> CreateOp(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputIndexes = 0,
    MNN::OpParameter main_type = MNN::OpParameter_NONE,
    flatbuffers::Offset<void> main = 0,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputIndexes = 0,
    MNN::OpType type = MNN::OpType_AbsVal,
    MNN::MNN_DATA_FORMAT defaultDimentionFormat = MNN::MNN_DATA_FORMAT_NHWC) {
  OpBuilder builder_(_fbb);
  builder_.add_type(type);
  builder_.add_outputIndexes(outputIndexes);
  builder_.add_name(name);
  builder_.add_main(main);
  builder_.add_inputIndexes(inputIndexes);
  builder_.add_defaultDimentionFormat(defaultDimentionFormat);
  builder_.add_main_type(main_type);
  return builder_.Finish();
}

inline flatbuffers::Offset<Op> CreateOpDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<int32_t> *inputIndexes = nullptr,
    MNN::OpParameter main_type = MNN::OpParameter_NONE,
    flatbuffers::Offset<void> main = 0,
    const char *name = nullptr,
    const std::vector<int32_t> *outputIndexes = nullptr,
    MNN::OpType type = MNN::OpType_AbsVal,
    MNN::MNN_DATA_FORMAT defaultDimentionFormat = MNN::MNN_DATA_FORMAT_NHWC) {
  auto inputIndexes__ = inputIndexes ? _fbb.CreateVector<int32_t>(*inputIndexes) : 0;
  auto name__ = name ? _fbb.CreateString(name) : 0;
  auto outputIndexes__ = outputIndexes ? _fbb.CreateVector<int32_t>(*outputIndexes) : 0;
  return MNN::CreateOp(
      _fbb,
      inputIndexes__,
      main_type,
      main,
      name__,
      outputIndexes__,
      type,
      defaultDimentionFormat);
}

flatbuffers::Offset<Op> CreateOp(flatbuffers::FlatBufferBuilder &_fbb, const OpT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct ViewT : public flatbuffers::NativeTable {
  typedef View TableType;
  int32_t offset;
  std::vector<int32_t> stride;
  ViewT()
      : offset(0) {
  }
};

struct View FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef ViewT NativeTableType;
  typedef ViewBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return ViewTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_OFFSET = 4,
    VT_STRIDE = 6
  };
  int32_t offset() const {
    return GetField<int32_t>(VT_OFFSET, 0);
  }
  const flatbuffers::Vector<int32_t> *stride() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_STRIDE);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int32_t>(verifier, VT_OFFSET) &&
           VerifyOffset(verifier, VT_STRIDE) &&
           verifier.VerifyVector(stride()) &&
           verifier.EndTable();
  }
  ViewT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(ViewT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<View> Pack(flatbuffers::FlatBufferBuilder &_fbb, const ViewT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct ViewBuilder {
  typedef View Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_offset(int32_t offset) {
    fbb_.AddElement<int32_t>(View::VT_OFFSET, offset, 0);
  }
  void add_stride(flatbuffers::Offset<flatbuffers::Vector<int32_t>> stride) {
    fbb_.AddOffset(View::VT_STRIDE, stride);
  }
  explicit ViewBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ViewBuilder &operator=(const ViewBuilder &);
  flatbuffers::Offset<View> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<View>(end);
    return o;
  }
};

inline flatbuffers::Offset<View> CreateView(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t offset = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> stride = 0) {
  ViewBuilder builder_(_fbb);
  builder_.add_stride(stride);
  builder_.add_offset(offset);
  return builder_.Finish();
}

inline flatbuffers::Offset<View> CreateViewDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    int32_t offset = 0,
    const std::vector<int32_t> *stride = nullptr) {
  auto stride__ = stride ? _fbb.CreateVector<int32_t>(*stride) : 0;
  return MNN::CreateView(
      _fbb,
      offset,
      stride__);
}

flatbuffers::Offset<View> CreateView(flatbuffers::FlatBufferBuilder &_fbb, const ViewT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct RegionT : public flatbuffers::NativeTable {
  typedef Region TableType;
  std::unique_ptr<MNN::ViewT> src;
  std::unique_ptr<MNN::ViewT> dst;
  std::vector<int32_t> size;
  int32_t origin;
  RegionT()
      : origin(0) {
  }
};

struct Region FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef RegionT NativeTableType;
  typedef RegionBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return RegionTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_SRC = 4,
    VT_DST = 6,
    VT_SIZE = 8,
    VT_ORIGIN = 10
  };
  const MNN::View *src() const {
    return GetPointer<const MNN::View *>(VT_SRC);
  }
  const MNN::View *dst() const {
    return GetPointer<const MNN::View *>(VT_DST);
  }
  const flatbuffers::Vector<int32_t> *size() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_SIZE);
  }
  int32_t origin() const {
    return GetField<int32_t>(VT_ORIGIN, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_SRC) &&
           verifier.VerifyTable(src()) &&
           VerifyOffset(verifier, VT_DST) &&
           verifier.VerifyTable(dst()) &&
           VerifyOffset(verifier, VT_SIZE) &&
           verifier.VerifyVector(size()) &&
           VerifyField<int32_t>(verifier, VT_ORIGIN) &&
           verifier.EndTable();
  }
  RegionT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(RegionT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Region> Pack(flatbuffers::FlatBufferBuilder &_fbb, const RegionT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct RegionBuilder {
  typedef Region Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_src(flatbuffers::Offset<MNN::View> src) {
    fbb_.AddOffset(Region::VT_SRC, src);
  }
  void add_dst(flatbuffers::Offset<MNN::View> dst) {
    fbb_.AddOffset(Region::VT_DST, dst);
  }
  void add_size(flatbuffers::Offset<flatbuffers::Vector<int32_t>> size) {
    fbb_.AddOffset(Region::VT_SIZE, size);
  }
  void add_origin(int32_t origin) {
    fbb_.AddElement<int32_t>(Region::VT_ORIGIN, origin, 0);
  }
  explicit RegionBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  RegionBuilder &operator=(const RegionBuilder &);
  flatbuffers::Offset<Region> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Region>(end);
    return o;
  }
};

inline flatbuffers::Offset<Region> CreateRegion(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<MNN::View> src = 0,
    flatbuffers::Offset<MNN::View> dst = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> size = 0,
    int32_t origin = 0) {
  RegionBuilder builder_(_fbb);
  builder_.add_origin(origin);
  builder_.add_size(size);
  builder_.add_dst(dst);
  builder_.add_src(src);
  return builder_.Finish();
}

inline flatbuffers::Offset<Region> CreateRegionDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<MNN::View> src = 0,
    flatbuffers::Offset<MNN::View> dst = 0,
    const std::vector<int32_t> *size = nullptr,
    int32_t origin = 0) {
  auto size__ = size ? _fbb.CreateVector<int32_t>(*size) : 0;
  return MNN::CreateRegion(
      _fbb,
      src,
      dst,
      size__,
      origin);
}

flatbuffers::Offset<Region> CreateRegion(flatbuffers::FlatBufferBuilder &_fbb, const RegionT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct TensorDescribeT : public flatbuffers::NativeTable {
  typedef TensorDescribe TableType;
  std::unique_ptr<MNN::BlobT> blob;
  int32_t index;
  std::string name;
  std::vector<std::unique_ptr<MNN::RegionT>> regions;
  std::unique_ptr<MNN::TensorQuantInfoT> quantInfo;
  TensorDescribeT()
      : index(0) {
  }
};

struct TensorDescribe FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TensorDescribeT NativeTableType;
  typedef TensorDescribeBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return TensorDescribeTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_BLOB = 4,
    VT_INDEX = 6,
    VT_NAME = 8,
    VT_REGIONS = 10,
    VT_QUANTINFO = 12
  };
  const MNN::Blob *blob() const {
    return GetPointer<const MNN::Blob *>(VT_BLOB);
  }
  int32_t index() const {
    return GetField<int32_t>(VT_INDEX, 0);
  }
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::Region>> *regions() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Region>> *>(VT_REGIONS);
  }
  const MNN::TensorQuantInfo *quantInfo() const {
    return GetPointer<const MNN::TensorQuantInfo *>(VT_QUANTINFO);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_BLOB) &&
           verifier.VerifyTable(blob()) &&
           VerifyField<int32_t>(verifier, VT_INDEX) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyOffset(verifier, VT_REGIONS) &&
           verifier.VerifyVector(regions()) &&
           verifier.VerifyVectorOfTables(regions()) &&
           VerifyOffset(verifier, VT_QUANTINFO) &&
           verifier.VerifyTable(quantInfo()) &&
           verifier.EndTable();
  }
  TensorDescribeT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(TensorDescribeT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<TensorDescribe> Pack(flatbuffers::FlatBufferBuilder &_fbb, const TensorDescribeT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct TensorDescribeBuilder {
  typedef TensorDescribe Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_blob(flatbuffers::Offset<MNN::Blob> blob) {
    fbb_.AddOffset(TensorDescribe::VT_BLOB, blob);
  }
  void add_index(int32_t index) {
    fbb_.AddElement<int32_t>(TensorDescribe::VT_INDEX, index, 0);
  }
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(TensorDescribe::VT_NAME, name);
  }
  void add_regions(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Region>>> regions) {
    fbb_.AddOffset(TensorDescribe::VT_REGIONS, regions);
  }
  void add_quantInfo(flatbuffers::Offset<MNN::TensorQuantInfo> quantInfo) {
    fbb_.AddOffset(TensorDescribe::VT_QUANTINFO, quantInfo);
  }
  explicit TensorDescribeBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TensorDescribeBuilder &operator=(const TensorDescribeBuilder &);
  flatbuffers::Offset<TensorDescribe> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TensorDescribe>(end);
    return o;
  }
};

inline flatbuffers::Offset<TensorDescribe> CreateTensorDescribe(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<MNN::Blob> blob = 0,
    int32_t index = 0,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Region>>> regions = 0,
    flatbuffers::Offset<MNN::TensorQuantInfo> quantInfo = 0) {
  TensorDescribeBuilder builder_(_fbb);
  builder_.add_quantInfo(quantInfo);
  builder_.add_regions(regions);
  builder_.add_name(name);
  builder_.add_index(index);
  builder_.add_blob(blob);
  return builder_.Finish();
}

inline flatbuffers::Offset<TensorDescribe> CreateTensorDescribeDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<MNN::Blob> blob = 0,
    int32_t index = 0,
    const char *name = nullptr,
    const std::vector<flatbuffers::Offset<MNN::Region>> *regions = nullptr,
    flatbuffers::Offset<MNN::TensorQuantInfo> quantInfo = 0) {
  auto name__ = name ? _fbb.CreateString(name) : 0;
  auto regions__ = regions ? _fbb.CreateVector<flatbuffers::Offset<MNN::Region>>(*regions) : 0;
  return MNN::CreateTensorDescribe(
      _fbb,
      blob,
      index,
      name__,
      regions__,
      quantInfo);
}

flatbuffers::Offset<TensorDescribe> CreateTensorDescribe(flatbuffers::FlatBufferBuilder &_fbb, const TensorDescribeT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct SubGraphProtoT : public flatbuffers::NativeTable {
  typedef SubGraphProto TableType;
  std::string name;
  std::vector<int32_t> inputs;
  std::vector<int32_t> outputs;
  std::vector<std::string> tensors;
  std::vector<std::unique_ptr<MNN::OpT>> nodes;
  std::vector<std::unique_ptr<MNN::TensorDescribeT>> extraTensorDescribe;
  SubGraphProtoT() {
  }
};

struct SubGraphProto FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef SubGraphProtoT NativeTableType;
  typedef SubGraphProtoBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return SubGraphProtoTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_NAME = 4,
    VT_INPUTS = 6,
    VT_OUTPUTS = 8,
    VT_TENSORS = 10,
    VT_NODES = 12,
    VT_EXTRATENSORDESCRIBE = 14
  };
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  const flatbuffers::Vector<int32_t> *inputs() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_INPUTS);
  }
  const flatbuffers::Vector<int32_t> *outputs() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_OUTPUTS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *tensors() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_TENSORS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::Op>> *nodes() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Op>> *>(VT_NODES);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>> *extraTensorDescribe() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>> *>(VT_EXTRATENSORDESCRIBE);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           VerifyOffset(verifier, VT_INPUTS) &&
           verifier.VerifyVector(inputs()) &&
           VerifyOffset(verifier, VT_OUTPUTS) &&
           verifier.VerifyVector(outputs()) &&
           VerifyOffset(verifier, VT_TENSORS) &&
           verifier.VerifyVector(tensors()) &&
           verifier.VerifyVectorOfStrings(tensors()) &&
           VerifyOffset(verifier, VT_NODES) &&
           verifier.VerifyVector(nodes()) &&
           verifier.VerifyVectorOfTables(nodes()) &&
           VerifyOffset(verifier, VT_EXTRATENSORDESCRIBE) &&
           verifier.VerifyVector(extraTensorDescribe()) &&
           verifier.VerifyVectorOfTables(extraTensorDescribe()) &&
           verifier.EndTable();
  }
  SubGraphProtoT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(SubGraphProtoT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<SubGraphProto> Pack(flatbuffers::FlatBufferBuilder &_fbb, const SubGraphProtoT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct SubGraphProtoBuilder {
  typedef SubGraphProto Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(SubGraphProto::VT_NAME, name);
  }
  void add_inputs(flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputs) {
    fbb_.AddOffset(SubGraphProto::VT_INPUTS, inputs);
  }
  void add_outputs(flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputs) {
    fbb_.AddOffset(SubGraphProto::VT_OUTPUTS, outputs);
  }
  void add_tensors(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> tensors) {
    fbb_.AddOffset(SubGraphProto::VT_TENSORS, tensors);
  }
  void add_nodes(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Op>>> nodes) {
    fbb_.AddOffset(SubGraphProto::VT_NODES, nodes);
  }
  void add_extraTensorDescribe(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>>> extraTensorDescribe) {
    fbb_.AddOffset(SubGraphProto::VT_EXTRATENSORDESCRIBE, extraTensorDescribe);
  }
  explicit SubGraphProtoBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  SubGraphProtoBuilder &operator=(const SubGraphProtoBuilder &);
  flatbuffers::Offset<SubGraphProto> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<SubGraphProto>(end);
    return o;
  }
};

inline flatbuffers::Offset<SubGraphProto> CreateSubGraphProto(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> name = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> inputs = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> outputs = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> tensors = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Op>>> nodes = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>>> extraTensorDescribe = 0) {
  SubGraphProtoBuilder builder_(_fbb);
  builder_.add_extraTensorDescribe(extraTensorDescribe);
  builder_.add_nodes(nodes);
  builder_.add_tensors(tensors);
  builder_.add_outputs(outputs);
  builder_.add_inputs(inputs);
  builder_.add_name(name);
  return builder_.Finish();
}

inline flatbuffers::Offset<SubGraphProto> CreateSubGraphProtoDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *name = nullptr,
    const std::vector<int32_t> *inputs = nullptr,
    const std::vector<int32_t> *outputs = nullptr,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *tensors = nullptr,
    const std::vector<flatbuffers::Offset<MNN::Op>> *nodes = nullptr,
    const std::vector<flatbuffers::Offset<MNN::TensorDescribe>> *extraTensorDescribe = nullptr) {
  auto name__ = name ? _fbb.CreateString(name) : 0;
  auto inputs__ = inputs ? _fbb.CreateVector<int32_t>(*inputs) : 0;
  auto outputs__ = outputs ? _fbb.CreateVector<int32_t>(*outputs) : 0;
  auto tensors__ = tensors ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*tensors) : 0;
  auto nodes__ = nodes ? _fbb.CreateVector<flatbuffers::Offset<MNN::Op>>(*nodes) : 0;
  auto extraTensorDescribe__ = extraTensorDescribe ? _fbb.CreateVector<flatbuffers::Offset<MNN::TensorDescribe>>(*extraTensorDescribe) : 0;
  return MNN::CreateSubGraphProto(
      _fbb,
      name__,
      inputs__,
      outputs__,
      tensors__,
      nodes__,
      extraTensorDescribe__);
}

flatbuffers::Offset<SubGraphProto> CreateSubGraphProto(flatbuffers::FlatBufferBuilder &_fbb, const SubGraphProtoT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct TensorQuantInfoT : public flatbuffers::NativeTable {
  typedef TensorQuantInfo TableType;
  float scale;
  float zero;
  float min;
  float max;
  MNN::DataType type;
  TensorQuantInfoT()
      : scale(0.0f),
        zero(0.0f),
        min(-128.0f),
        max(127.0f),
        type(MNN::DataType_DT_INVALID) {
  }
};

struct TensorQuantInfo FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef TensorQuantInfoT NativeTableType;
  typedef TensorQuantInfoBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return TensorQuantInfoTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_SCALE = 4,
    VT_ZERO = 6,
    VT_MIN = 8,
    VT_MAX = 10,
    VT_TYPE = 12
  };
  float scale() const {
    return GetField<float>(VT_SCALE, 0.0f);
  }
  float zero() const {
    return GetField<float>(VT_ZERO, 0.0f);
  }
  float min() const {
    return GetField<float>(VT_MIN, -128.0f);
  }
  float max() const {
    return GetField<float>(VT_MAX, 127.0f);
  }
  MNN::DataType type() const {
    return static_cast<MNN::DataType>(GetField<int32_t>(VT_TYPE, 0));
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<float>(verifier, VT_SCALE) &&
           VerifyField<float>(verifier, VT_ZERO) &&
           VerifyField<float>(verifier, VT_MIN) &&
           VerifyField<float>(verifier, VT_MAX) &&
           VerifyField<int32_t>(verifier, VT_TYPE) &&
           verifier.EndTable();
  }
  TensorQuantInfoT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(TensorQuantInfoT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<TensorQuantInfo> Pack(flatbuffers::FlatBufferBuilder &_fbb, const TensorQuantInfoT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct TensorQuantInfoBuilder {
  typedef TensorQuantInfo Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_scale(float scale) {
    fbb_.AddElement<float>(TensorQuantInfo::VT_SCALE, scale, 0.0f);
  }
  void add_zero(float zero) {
    fbb_.AddElement<float>(TensorQuantInfo::VT_ZERO, zero, 0.0f);
  }
  void add_min(float min) {
    fbb_.AddElement<float>(TensorQuantInfo::VT_MIN, min, -128.0f);
  }
  void add_max(float max) {
    fbb_.AddElement<float>(TensorQuantInfo::VT_MAX, max, 127.0f);
  }
  void add_type(MNN::DataType type) {
    fbb_.AddElement<int32_t>(TensorQuantInfo::VT_TYPE, static_cast<int32_t>(type), 0);
  }
  explicit TensorQuantInfoBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TensorQuantInfoBuilder &operator=(const TensorQuantInfoBuilder &);
  flatbuffers::Offset<TensorQuantInfo> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<TensorQuantInfo>(end);
    return o;
  }
};

inline flatbuffers::Offset<TensorQuantInfo> CreateTensorQuantInfo(
    flatbuffers::FlatBufferBuilder &_fbb,
    float scale = 0.0f,
    float zero = 0.0f,
    float min = -128.0f,
    float max = 127.0f,
    MNN::DataType type = MNN::DataType_DT_INVALID) {
  TensorQuantInfoBuilder builder_(_fbb);
  builder_.add_type(type);
  builder_.add_max(max);
  builder_.add_min(min);
  builder_.add_zero(zero);
  builder_.add_scale(scale);
  return builder_.Finish();
}

flatbuffers::Offset<TensorQuantInfo> CreateTensorQuantInfo(flatbuffers::FlatBufferBuilder &_fbb, const TensorQuantInfoT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

struct NetT : public flatbuffers::NativeTable {
  typedef Net TableType;
  std::string bizCode;
  std::vector<std::unique_ptr<MNN::TensorDescribeT>> extraTensorDescribe;
  std::unique_ptr<MNN::GpuLibraryT> gpulibrary;
  std::vector<std::unique_ptr<MNN::OpT>> oplists;
  std::vector<std::string> outputName;
  MNN::ForwardType preferForwardType;
  MNN::NetSource sourceType;
  std::vector<std::string> tensorName;
  int32_t tensorNumber;
  MNN::Usage usage;
  std::vector<std::unique_ptr<MNN::SubGraphProtoT>> subgraphs;
  NetT()
      : preferForwardType(MNN::ForwardType_CPU),
        sourceType(MNN::NetSource_CAFFE),
        tensorNumber(0),
        usage(MNN::Usage_INFERENCE) {
  }
};

struct Net FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  typedef NetT NativeTableType;
  typedef NetBuilder Builder;
  static const flatbuffers::TypeTable *MiniReflectTypeTable() {
    return NetTypeTable();
  }
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_BIZCODE = 4,
    VT_EXTRATENSORDESCRIBE = 6,
    VT_GPULIBRARY = 8,
    VT_OPLISTS = 10,
    VT_OUTPUTNAME = 12,
    VT_PREFERFORWARDTYPE = 14,
    VT_SOURCETYPE = 16,
    VT_TENSORNAME = 18,
    VT_TENSORNUMBER = 20,
    VT_USAGE = 22,
    VT_SUBGRAPHS = 24
  };
  const flatbuffers::String *bizCode() const {
    return GetPointer<const flatbuffers::String *>(VT_BIZCODE);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>> *extraTensorDescribe() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>> *>(VT_EXTRATENSORDESCRIBE);
  }
  const MNN::GpuLibrary *gpulibrary() const {
    return GetPointer<const MNN::GpuLibrary *>(VT_GPULIBRARY);
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::Op>> *oplists() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::Op>> *>(VT_OPLISTS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *outputName() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_OUTPUTNAME);
  }
  MNN::ForwardType preferForwardType() const {
    return static_cast<MNN::ForwardType>(GetField<int8_t>(VT_PREFERFORWARDTYPE, 0));
  }
  MNN::NetSource sourceType() const {
    return static_cast<MNN::NetSource>(GetField<int8_t>(VT_SOURCETYPE, 0));
  }
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *tensorName() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_TENSORNAME);
  }
  int32_t tensorNumber() const {
    return GetField<int32_t>(VT_TENSORNUMBER, 0);
  }
  MNN::Usage usage() const {
    return static_cast<MNN::Usage>(GetField<int8_t>(VT_USAGE, 0));
  }
  const flatbuffers::Vector<flatbuffers::Offset<MNN::SubGraphProto>> *subgraphs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<MNN::SubGraphProto>> *>(VT_SUBGRAPHS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_BIZCODE) &&
           verifier.VerifyString(bizCode()) &&
           VerifyOffset(verifier, VT_EXTRATENSORDESCRIBE) &&
           verifier.VerifyVector(extraTensorDescribe()) &&
           verifier.VerifyVectorOfTables(extraTensorDescribe()) &&
           VerifyOffset(verifier, VT_GPULIBRARY) &&
           verifier.VerifyTable(gpulibrary()) &&
           VerifyOffset(verifier, VT_OPLISTS) &&
           verifier.VerifyVector(oplists()) &&
           verifier.VerifyVectorOfTables(oplists()) &&
           VerifyOffset(verifier, VT_OUTPUTNAME) &&
           verifier.VerifyVector(outputName()) &&
           verifier.VerifyVectorOfStrings(outputName()) &&
           VerifyField<int8_t>(verifier, VT_PREFERFORWARDTYPE) &&
           VerifyField<int8_t>(verifier, VT_SOURCETYPE) &&
           VerifyOffset(verifier, VT_TENSORNAME) &&
           verifier.VerifyVector(tensorName()) &&
           verifier.VerifyVectorOfStrings(tensorName()) &&
           VerifyField<int32_t>(verifier, VT_TENSORNUMBER) &&
           VerifyField<int8_t>(verifier, VT_USAGE) &&
           VerifyOffset(verifier, VT_SUBGRAPHS) &&
           verifier.VerifyVector(subgraphs()) &&
           verifier.VerifyVectorOfTables(subgraphs()) &&
           verifier.EndTable();
  }
  NetT *UnPack(const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(NetT *_o, const flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static flatbuffers::Offset<Net> Pack(flatbuffers::FlatBufferBuilder &_fbb, const NetT* _o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct NetBuilder {
  typedef Net Table;
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_bizCode(flatbuffers::Offset<flatbuffers::String> bizCode) {
    fbb_.AddOffset(Net::VT_BIZCODE, bizCode);
  }
  void add_extraTensorDescribe(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>>> extraTensorDescribe) {
    fbb_.AddOffset(Net::VT_EXTRATENSORDESCRIBE, extraTensorDescribe);
  }
  void add_gpulibrary(flatbuffers::Offset<MNN::GpuLibrary> gpulibrary) {
    fbb_.AddOffset(Net::VT_GPULIBRARY, gpulibrary);
  }
  void add_oplists(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Op>>> oplists) {
    fbb_.AddOffset(Net::VT_OPLISTS, oplists);
  }
  void add_outputName(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> outputName) {
    fbb_.AddOffset(Net::VT_OUTPUTNAME, outputName);
  }
  void add_preferForwardType(MNN::ForwardType preferForwardType) {
    fbb_.AddElement<int8_t>(Net::VT_PREFERFORWARDTYPE, static_cast<int8_t>(preferForwardType), 0);
  }
  void add_sourceType(MNN::NetSource sourceType) {
    fbb_.AddElement<int8_t>(Net::VT_SOURCETYPE, static_cast<int8_t>(sourceType), 0);
  }
  void add_tensorName(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> tensorName) {
    fbb_.AddOffset(Net::VT_TENSORNAME, tensorName);
  }
  void add_tensorNumber(int32_t tensorNumber) {
    fbb_.AddElement<int32_t>(Net::VT_TENSORNUMBER, tensorNumber, 0);
  }
  void add_usage(MNN::Usage usage) {
    fbb_.AddElement<int8_t>(Net::VT_USAGE, static_cast<int8_t>(usage), 0);
  }
  void add_subgraphs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::SubGraphProto>>> subgraphs) {
    fbb_.AddOffset(Net::VT_SUBGRAPHS, subgraphs);
  }
  explicit NetBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  NetBuilder &operator=(const NetBuilder &);
  flatbuffers::Offset<Net> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Net>(end);
    return o;
  }
};

inline flatbuffers::Offset<Net> CreateNet(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> bizCode = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::TensorDescribe>>> extraTensorDescribe = 0,
    flatbuffers::Offset<MNN::GpuLibrary> gpulibrary = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::Op>>> oplists = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> outputName = 0,
    MNN::ForwardType preferForwardType = MNN::ForwardType_CPU,
    MNN::NetSource sourceType = MNN::NetSource_CAFFE,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> tensorName = 0,
    int32_t tensorNumber = 0,
    MNN::Usage usage = MNN::Usage_INFERENCE,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<MNN::SubGraphProto>>> subgraphs = 0) {
  NetBuilder builder_(_fbb);
  builder_.add_subgraphs(subgraphs);
  builder_.add_tensorNumber(tensorNumber);
  builder_.add_tensorName(tensorName);
  builder_.add_outputName(outputName);
  builder_.add_oplists(oplists);
  builder_.add_gpulibrary(gpulibrary);
  builder_.add_extraTensorDescribe(extraTensorDescribe);
  builder_.add_bizCode(bizCode);
  builder_.add_usage(usage);
  builder_.add_sourceType(sourceType);
  builder_.add_preferForwardType(preferForwardType);
  return builder_.Finish();
}

inline flatbuffers::Offset<Net> CreateNetDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *bizCode = nullptr,
    const std::vector<flatbuffers::Offset<MNN::TensorDescribe>> *extraTensorDescribe = nullptr,
    flatbuffers::Offset<MNN::GpuLibrary> gpulibrary = 0,
    const std::vector<flatbuffers::Offset<MNN::Op>> *oplists = nullptr,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *outputName = nullptr,
    MNN::ForwardType preferForwardType = MNN::ForwardType_CPU,
    MNN::NetSource sourceType = MNN::NetSource_CAFFE,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *tensorName = nullptr,
    int32_t tensorNumber = 0,
    MNN::Usage usage = MNN::Usage_INFERENCE,
    const std::vector<flatbuffers::Offset<MNN::SubGraphProto>> *subgraphs = nullptr) {
  auto bizCode__ = bizCode ? _fbb.CreateString(bizCode) : 0;
  auto extraTensorDescribe__ = extraTensorDescribe ? _fbb.CreateVector<flatbuffers::Offset<MNN::TensorDescribe>>(*extraTensorDescribe) : 0;
  auto oplists__ = oplists ? _fbb.CreateVector<flatbuffers::Offset<MNN::Op>>(*oplists) : 0;
  auto outputName__ = outputName ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*outputName) : 0;
  auto tensorName__ = tensorName ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*tensorName) : 0;
  auto subgraphs__ = subgraphs ? _fbb.CreateVector<flatbuffers::Offset<MNN::SubGraphProto>>(*subgraphs) : 0;
  return MNN::CreateNet(
      _fbb,
      bizCode__,
      extraTensorDescribe__,
      gpulibrary,
      oplists__,
      outputName__,
      preferForwardType,
      sourceType,
      tensorName__,
      tensorNumber,
      usage,
      subgraphs__);
}

flatbuffers::Offset<Net> CreateNet(flatbuffers::FlatBufferBuilder &_fbb, const NetT *_o, const flatbuffers::rehasher_function_t *_rehasher = nullptr);

inline PluginT *Plugin::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::PluginT> _o = std::unique_ptr<MNN::PluginT>(new PluginT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void Plugin::UnPackTo(PluginT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = type(); if (_e) _o->type = _e->str(); }
  { auto _e = attr(); if (_e) { _o->attr.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->attr[_i] = std::unique_ptr<MNN::AttributeT>(_e->Get(_i)->UnPack(_resolver)); } } }
}

inline flatbuffers::Offset<Plugin> Plugin::Pack(flatbuffers::FlatBufferBuilder &_fbb, const PluginT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreatePlugin(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Plugin> CreatePlugin(flatbuffers::FlatBufferBuilder &_fbb, const PluginT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const PluginT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _type = _o->type.empty() ? 0 : _fbb.CreateString(_o->type);
  auto _attr = _o->attr.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Attribute>> (_o->attr.size(), [](size_t i, _VectorArgs *__va) { return CreateAttribute(*__va->__fbb, __va->__o->attr[i].get(), __va->__rehasher); }, &_va ) : 0;
  return MNN::CreatePlugin(
      _fbb,
      _type,
      _attr);
}

inline ExtraT *Extra::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::ExtraT> _o = std::unique_ptr<MNN::ExtraT>(new ExtraT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void Extra::UnPackTo(ExtraT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = type(); if (_e) _o->type = _e->str(); }
  { auto _e = engine(); if (_e) _o->engine = _e->str(); }
  { auto _e = info(); if (_e) { _o->info.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->info[_i] = _e->Get(_i); } } }
  { auto _e = attr(); if (_e) { _o->attr.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->attr[_i] = std::unique_ptr<MNN::AttributeT>(_e->Get(_i)->UnPack(_resolver)); } } }
}

inline flatbuffers::Offset<Extra> Extra::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ExtraT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateExtra(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Extra> CreateExtra(flatbuffers::FlatBufferBuilder &_fbb, const ExtraT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const ExtraT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _type = _o->type.empty() ? 0 : _fbb.CreateString(_o->type);
  auto _engine = _o->engine.empty() ? 0 : _fbb.CreateString(_o->engine);
  auto _info = _o->info.size() ? _fbb.CreateVector(_o->info) : 0;
  auto _attr = _o->attr.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Attribute>> (_o->attr.size(), [](size_t i, _VectorArgs *__va) { return CreateAttribute(*__va->__fbb, __va->__o->attr[i].get(), __va->__rehasher); }, &_va ) : 0;
  return MNN::CreateExtra(
      _fbb,
      _type,
      _engine,
      _info,
      _attr);
}

inline StringVecT *StringVec::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::StringVecT> _o = std::unique_ptr<MNN::StringVecT>(new StringVecT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void StringVec::UnPackTo(StringVecT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = data(); if (_e) { _o->data.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->data[_i] = _e->Get(_i)->str(); } } }
}

inline flatbuffers::Offset<StringVec> StringVec::Pack(flatbuffers::FlatBufferBuilder &_fbb, const StringVecT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateStringVec(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<StringVec> CreateStringVec(flatbuffers::FlatBufferBuilder &_fbb, const StringVecT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const StringVecT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _data = _o->data.size() ? _fbb.CreateVectorOfStrings(_o->data) : 0;
  return MNN::CreateStringVec(
      _fbb,
      _data);
}

inline WhileParamT *WhileParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::WhileParamT> _o = std::unique_ptr<MNN::WhileParamT>(new WhileParamT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void WhileParam::UnPackTo(WhileParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = cond_graph(); if (_e) _o->cond_graph = _e->str(); }
  { auto _e = body_graph(); if (_e) _o->body_graph = _e->str(); }
  { auto _e = aliases_inputs(); if (_e) { _o->aliases_inputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_inputs[_i] = std::unique_ptr<MNN::StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = aliases_outputs(); if (_e) { _o->aliases_outputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_outputs[_i] = _e->Get(_i)->str(); } } }
  { auto _e = aliases_updates(); if (_e) { _o->aliases_updates.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_updates[_i] = std::unique_ptr<MNN::StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } }
}

inline flatbuffers::Offset<WhileParam> WhileParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const WhileParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateWhileParam(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<WhileParam> CreateWhileParam(flatbuffers::FlatBufferBuilder &_fbb, const WhileParamT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const WhileParamT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _cond_graph = _o->cond_graph.empty() ? 0 : _fbb.CreateString(_o->cond_graph);
  auto _body_graph = _o->body_graph.empty() ? 0 : _fbb.CreateString(_o->body_graph);
  auto _aliases_inputs = _o->aliases_inputs.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>> (_o->aliases_inputs.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_inputs[i].get(), __va->__rehasher); }, &_va ) : 0;
  auto _aliases_outputs = _o->aliases_outputs.size() ? _fbb.CreateVectorOfStrings(_o->aliases_outputs) : 0;
  auto _aliases_updates = _o->aliases_updates.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>> (_o->aliases_updates.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_updates[i].get(), __va->__rehasher); }, &_va ) : 0;
  return MNN::CreateWhileParam(
      _fbb,
      _cond_graph,
      _body_graph,
      _aliases_inputs,
      _aliases_outputs,
      _aliases_updates);
}

inline IfParamT *IfParam::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::IfParamT> _o = std::unique_ptr<MNN::IfParamT>(new IfParamT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void IfParam::UnPackTo(IfParamT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = then_graph(); if (_e) _o->then_graph = _e->str(); }
  { auto _e = else_graph(); if (_e) _o->else_graph = _e->str(); }
  { auto _e = aliases_inputs(); if (_e) { _o->aliases_inputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_inputs[_i] = std::unique_ptr<MNN::StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = aliases_outputs(); if (_e) { _o->aliases_outputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->aliases_outputs[_i] = std::unique_ptr<MNN::StringVecT>(_e->Get(_i)->UnPack(_resolver)); } } }
}

inline flatbuffers::Offset<IfParam> IfParam::Pack(flatbuffers::FlatBufferBuilder &_fbb, const IfParamT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateIfParam(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<IfParam> CreateIfParam(flatbuffers::FlatBufferBuilder &_fbb, const IfParamT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const IfParamT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _then_graph = _o->then_graph.empty() ? 0 : _fbb.CreateString(_o->then_graph);
  auto _else_graph = _o->else_graph.empty() ? 0 : _fbb.CreateString(_o->else_graph);
  auto _aliases_inputs = _o->aliases_inputs.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>> (_o->aliases_inputs.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_inputs[i].get(), __va->__rehasher); }, &_va ) : 0;
  auto _aliases_outputs = _o->aliases_outputs.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::StringVec>> (_o->aliases_outputs.size(), [](size_t i, _VectorArgs *__va) { return CreateStringVec(*__va->__fbb, __va->__o->aliases_outputs[i].get(), __va->__rehasher); }, &_va ) : 0;
  return MNN::CreateIfParam(
      _fbb,
      _then_graph,
      _else_graph,
      _aliases_inputs,
      _aliases_outputs);
}

inline OpT *Op::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::OpT> _o = std::unique_ptr<MNN::OpT>(new OpT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void Op::UnPackTo(OpT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = inputIndexes(); if (_e) { _o->inputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputIndexes[_i] = _e->Get(_i); } } }
  { auto _e = main_type(); _o->main.type = _e; }
  { auto _e = main(); if (_e) _o->main.value = MNN::OpParameterUnion::UnPack(_e, main_type(), _resolver); }
  { auto _e = name(); if (_e) _o->name = _e->str(); }
  { auto _e = outputIndexes(); if (_e) { _o->outputIndexes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputIndexes[_i] = _e->Get(_i); } } }
  { auto _e = type(); _o->type = _e; }
  { auto _e = defaultDimentionFormat(); _o->defaultDimentionFormat = _e; }
}

inline flatbuffers::Offset<Op> Op::Pack(flatbuffers::FlatBufferBuilder &_fbb, const OpT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateOp(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Op> CreateOp(flatbuffers::FlatBufferBuilder &_fbb, const OpT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const OpT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _inputIndexes = _o->inputIndexes.size() ? _fbb.CreateVector(_o->inputIndexes) : 0;
  auto _main_type = _o->main.type;
  auto _main = _o->main.Pack(_fbb);
  auto _name = _o->name.empty() ? 0 : _fbb.CreateString(_o->name);
  auto _outputIndexes = _o->outputIndexes.size() ? _fbb.CreateVector(_o->outputIndexes) : 0;
  auto _type = _o->type;
  auto _defaultDimentionFormat = _o->defaultDimentionFormat;
  return MNN::CreateOp(
      _fbb,
      _inputIndexes,
      _main_type,
      _main,
      _name,
      _outputIndexes,
      _type,
      _defaultDimentionFormat);
}

inline ViewT *View::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::ViewT> _o = std::unique_ptr<MNN::ViewT>(new ViewT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void View::UnPackTo(ViewT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = offset(); _o->offset = _e; }
  { auto _e = stride(); if (_e) { _o->stride.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->stride[_i] = _e->Get(_i); } } }
}

inline flatbuffers::Offset<View> View::Pack(flatbuffers::FlatBufferBuilder &_fbb, const ViewT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateView(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<View> CreateView(flatbuffers::FlatBufferBuilder &_fbb, const ViewT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const ViewT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _offset = _o->offset;
  auto _stride = _o->stride.size() ? _fbb.CreateVector(_o->stride) : 0;
  return MNN::CreateView(
      _fbb,
      _offset,
      _stride);
}

inline RegionT *Region::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::RegionT> _o = std::unique_ptr<MNN::RegionT>(new RegionT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void Region::UnPackTo(RegionT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = src(); if (_e) _o->src = std::unique_ptr<MNN::ViewT>(_e->UnPack(_resolver)); }
  { auto _e = dst(); if (_e) _o->dst = std::unique_ptr<MNN::ViewT>(_e->UnPack(_resolver)); }
  { auto _e = size(); if (_e) { _o->size.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->size[_i] = _e->Get(_i); } } }
  { auto _e = origin(); _o->origin = _e; }
}

inline flatbuffers::Offset<Region> Region::Pack(flatbuffers::FlatBufferBuilder &_fbb, const RegionT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateRegion(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Region> CreateRegion(flatbuffers::FlatBufferBuilder &_fbb, const RegionT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const RegionT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _src = _o->src ? CreateView(_fbb, _o->src.get(), _rehasher) : 0;
  auto _dst = _o->dst ? CreateView(_fbb, _o->dst.get(), _rehasher) : 0;
  auto _size = _o->size.size() ? _fbb.CreateVector(_o->size) : 0;
  auto _origin = _o->origin;
  return MNN::CreateRegion(
      _fbb,
      _src,
      _dst,
      _size,
      _origin);
}

inline TensorDescribeT *TensorDescribe::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::TensorDescribeT> _o = std::unique_ptr<MNN::TensorDescribeT>(new TensorDescribeT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void TensorDescribe::UnPackTo(TensorDescribeT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = blob(); if (_e) _o->blob = std::unique_ptr<MNN::BlobT>(_e->UnPack(_resolver)); }
  { auto _e = index(); _o->index = _e; }
  { auto _e = name(); if (_e) _o->name = _e->str(); }
  { auto _e = regions(); if (_e) { _o->regions.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->regions[_i] = std::unique_ptr<MNN::RegionT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = quantInfo(); if (_e) _o->quantInfo = std::unique_ptr<MNN::TensorQuantInfoT>(_e->UnPack(_resolver)); }
}

inline flatbuffers::Offset<TensorDescribe> TensorDescribe::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TensorDescribeT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateTensorDescribe(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<TensorDescribe> CreateTensorDescribe(flatbuffers::FlatBufferBuilder &_fbb, const TensorDescribeT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const TensorDescribeT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _blob = _o->blob ? CreateBlob(_fbb, _o->blob.get(), _rehasher) : 0;
  auto _index = _o->index;
  auto _name = _o->name.empty() ? 0 : _fbb.CreateString(_o->name);
  auto _regions = _o->regions.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Region>> (_o->regions.size(), [](size_t i, _VectorArgs *__va) { return CreateRegion(*__va->__fbb, __va->__o->regions[i].get(), __va->__rehasher); }, &_va ) : 0;
  auto _quantInfo = _o->quantInfo ? CreateTensorQuantInfo(_fbb, _o->quantInfo.get(), _rehasher) : 0;
  return MNN::CreateTensorDescribe(
      _fbb,
      _blob,
      _index,
      _name,
      _regions,
      _quantInfo);
}

inline SubGraphProtoT *SubGraphProto::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::SubGraphProtoT> _o = std::unique_ptr<MNN::SubGraphProtoT>(new SubGraphProtoT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void SubGraphProto::UnPackTo(SubGraphProtoT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = name(); if (_e) _o->name = _e->str(); }
  { auto _e = inputs(); if (_e) { _o->inputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->inputs[_i] = _e->Get(_i); } } }
  { auto _e = outputs(); if (_e) { _o->outputs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputs[_i] = _e->Get(_i); } } }
  { auto _e = tensors(); if (_e) { _o->tensors.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->tensors[_i] = _e->Get(_i)->str(); } } }
  { auto _e = nodes(); if (_e) { _o->nodes.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->nodes[_i] = std::unique_ptr<MNN::OpT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = extraTensorDescribe(); if (_e) { _o->extraTensorDescribe.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->extraTensorDescribe[_i] = std::unique_ptr<MNN::TensorDescribeT>(_e->Get(_i)->UnPack(_resolver)); } } }
}

inline flatbuffers::Offset<SubGraphProto> SubGraphProto::Pack(flatbuffers::FlatBufferBuilder &_fbb, const SubGraphProtoT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateSubGraphProto(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<SubGraphProto> CreateSubGraphProto(flatbuffers::FlatBufferBuilder &_fbb, const SubGraphProtoT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const SubGraphProtoT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _name = _o->name.empty() ? 0 : _fbb.CreateString(_o->name);
  auto _inputs = _o->inputs.size() ? _fbb.CreateVector(_o->inputs) : 0;
  auto _outputs = _o->outputs.size() ? _fbb.CreateVector(_o->outputs) : 0;
  auto _tensors = _o->tensors.size() ? _fbb.CreateVectorOfStrings(_o->tensors) : 0;
  auto _nodes = _o->nodes.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Op>> (_o->nodes.size(), [](size_t i, _VectorArgs *__va) { return CreateOp(*__va->__fbb, __va->__o->nodes[i].get(), __va->__rehasher); }, &_va ) : 0;
  auto _extraTensorDescribe = _o->extraTensorDescribe.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::TensorDescribe>> (_o->extraTensorDescribe.size(), [](size_t i, _VectorArgs *__va) { return CreateTensorDescribe(*__va->__fbb, __va->__o->extraTensorDescribe[i].get(), __va->__rehasher); }, &_va ) : 0;
  return MNN::CreateSubGraphProto(
      _fbb,
      _name,
      _inputs,
      _outputs,
      _tensors,
      _nodes,
      _extraTensorDescribe);
}

inline TensorQuantInfoT *TensorQuantInfo::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::TensorQuantInfoT> _o = std::unique_ptr<MNN::TensorQuantInfoT>(new TensorQuantInfoT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void TensorQuantInfo::UnPackTo(TensorQuantInfoT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = scale(); _o->scale = _e; }
  { auto _e = zero(); _o->zero = _e; }
  { auto _e = min(); _o->min = _e; }
  { auto _e = max(); _o->max = _e; }
  { auto _e = type(); _o->type = _e; }
}

inline flatbuffers::Offset<TensorQuantInfo> TensorQuantInfo::Pack(flatbuffers::FlatBufferBuilder &_fbb, const TensorQuantInfoT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateTensorQuantInfo(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<TensorQuantInfo> CreateTensorQuantInfo(flatbuffers::FlatBufferBuilder &_fbb, const TensorQuantInfoT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const TensorQuantInfoT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _scale = _o->scale;
  auto _zero = _o->zero;
  auto _min = _o->min;
  auto _max = _o->max;
  auto _type = _o->type;
  return MNN::CreateTensorQuantInfo(
      _fbb,
      _scale,
      _zero,
      _min,
      _max,
      _type);
}

inline NetT *Net::UnPack(const flatbuffers::resolver_function_t *_resolver) const {
  std::unique_ptr<MNN::NetT> _o = std::unique_ptr<MNN::NetT>(new NetT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void Net::UnPackTo(NetT *_o, const flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = bizCode(); if (_e) _o->bizCode = _e->str(); }
  { auto _e = extraTensorDescribe(); if (_e) { _o->extraTensorDescribe.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->extraTensorDescribe[_i] = std::unique_ptr<MNN::TensorDescribeT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = gpulibrary(); if (_e) _o->gpulibrary = std::unique_ptr<MNN::GpuLibraryT>(_e->UnPack(_resolver)); }
  { auto _e = oplists(); if (_e) { _o->oplists.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->oplists[_i] = std::unique_ptr<MNN::OpT>(_e->Get(_i)->UnPack(_resolver)); } } }
  { auto _e = outputName(); if (_e) { _o->outputName.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->outputName[_i] = _e->Get(_i)->str(); } } }
  { auto _e = preferForwardType(); _o->preferForwardType = _e; }
  { auto _e = sourceType(); _o->sourceType = _e; }
  { auto _e = tensorName(); if (_e) { _o->tensorName.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->tensorName[_i] = _e->Get(_i)->str(); } } }
  { auto _e = tensorNumber(); _o->tensorNumber = _e; }
  { auto _e = usage(); _o->usage = _e; }
  { auto _e = subgraphs(); if (_e) { _o->subgraphs.resize(_e->size()); for (flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->subgraphs[_i] = std::unique_ptr<MNN::SubGraphProtoT>(_e->Get(_i)->UnPack(_resolver)); } } }
}

inline flatbuffers::Offset<Net> Net::Pack(flatbuffers::FlatBufferBuilder &_fbb, const NetT* _o, const flatbuffers::rehasher_function_t *_rehasher) {
  return CreateNet(_fbb, _o, _rehasher);
}

inline flatbuffers::Offset<Net> CreateNet(flatbuffers::FlatBufferBuilder &_fbb, const NetT *_o, const flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { flatbuffers::FlatBufferBuilder *__fbb; const NetT* __o; const flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _bizCode = _o->bizCode.empty() ? 0 : _fbb.CreateString(_o->bizCode);
  auto _extraTensorDescribe = _o->extraTensorDescribe.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::TensorDescribe>> (_o->extraTensorDescribe.size(), [](size_t i, _VectorArgs *__va) { return CreateTensorDescribe(*__va->__fbb, __va->__o->extraTensorDescribe[i].get(), __va->__rehasher); }, &_va ) : 0;
  auto _gpulibrary = _o->gpulibrary ? CreateGpuLibrary(_fbb, _o->gpulibrary.get(), _rehasher) : 0;
  auto _oplists = _o->oplists.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::Op>> (_o->oplists.size(), [](size_t i, _VectorArgs *__va) { return CreateOp(*__va->__fbb, __va->__o->oplists[i].get(), __va->__rehasher); }, &_va ) : 0;
  auto _outputName = _o->outputName.size() ? _fbb.CreateVectorOfStrings(_o->outputName) : 0;
  auto _preferForwardType = _o->preferForwardType;
  auto _sourceType = _o->sourceType;
  auto _tensorName = _o->tensorName.size() ? _fbb.CreateVectorOfStrings(_o->tensorName) : 0;
  auto _tensorNumber = _o->tensorNumber;
  auto _usage = _o->usage;
  auto _subgraphs = _o->subgraphs.size() ? _fbb.CreateVector<flatbuffers::Offset<MNN::SubGraphProto>> (_o->subgraphs.size(), [](size_t i, _VectorArgs *__va) { return CreateSubGraphProto(*__va->__fbb, __va->__o->subgraphs[i].get(), __va->__rehasher); }, &_va ) : 0;
  return MNN::CreateNet(
      _fbb,
      _bizCode,
      _extraTensorDescribe,
      _gpulibrary,
      _oplists,
      _outputName,
      _preferForwardType,
      _sourceType,
      _tensorName,
      _tensorNumber,
      _usage,
      _subgraphs);
}

inline bool VerifyOpParameter(flatbuffers::Verifier &verifier, const void *obj, OpParameter type) {
  switch (type) {
    case OpParameter_NONE: {
      return true;
    }
    case OpParameter_QuantizedAdd: {
      auto ptr = reinterpret_cast<const MNN::QuantizedAdd *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_ArgMax: {
      auto ptr = reinterpret_cast<const MNN::ArgMax *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_AsString: {
      auto ptr = reinterpret_cast<const MNN::AsString *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Axis: {
      auto ptr = reinterpret_cast<const MNN::Axis *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_BatchNorm: {
      auto ptr = reinterpret_cast<const MNN::BatchNorm *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_BinaryOp: {
      auto ptr = reinterpret_cast<const MNN::BinaryOp *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Blob: {
      auto ptr = reinterpret_cast<const MNN::Blob *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_CastParam: {
      auto ptr = reinterpret_cast<const MNN::CastParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Convolution2D: {
      auto ptr = reinterpret_cast<const MNN::Convolution2D *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Crop: {
      auto ptr = reinterpret_cast<const MNN::Crop *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_CropAndResize: {
      auto ptr = reinterpret_cast<const MNN::CropAndResize *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Dequantize: {
      auto ptr = reinterpret_cast<const MNN::Dequantize *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_DetectionOutput: {
      auto ptr = reinterpret_cast<const MNN::DetectionOutput *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Eltwise: {
      auto ptr = reinterpret_cast<const MNN::Eltwise *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_ExpandDims: {
      auto ptr = reinterpret_cast<const MNN::ExpandDims *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Fill: {
      auto ptr = reinterpret_cast<const MNN::Fill *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Flatten: {
      auto ptr = reinterpret_cast<const MNN::Flatten *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Gather: {
      auto ptr = reinterpret_cast<const MNN::Gather *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_GatherV2: {
      auto ptr = reinterpret_cast<const MNN::GatherV2 *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_InnerProduct: {
      auto ptr = reinterpret_cast<const MNN::InnerProduct *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Input: {
      auto ptr = reinterpret_cast<const MNN::Input *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Interp: {
      auto ptr = reinterpret_cast<const MNN::Interp *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_LRN: {
      auto ptr = reinterpret_cast<const MNN::LRN *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_LSTM: {
      auto ptr = reinterpret_cast<const MNN::LSTM *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_MatMul: {
      auto ptr = reinterpret_cast<const MNN::MatMul *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_NonMaxSuppressionV2: {
      auto ptr = reinterpret_cast<const MNN::NonMaxSuppressionV2 *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Normalize: {
      auto ptr = reinterpret_cast<const MNN::Normalize *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_PackParam: {
      auto ptr = reinterpret_cast<const MNN::PackParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Permute: {
      auto ptr = reinterpret_cast<const MNN::Permute *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Plugin: {
      auto ptr = reinterpret_cast<const MNN::Plugin *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Pool: {
      auto ptr = reinterpret_cast<const MNN::Pool *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_PRelu: {
      auto ptr = reinterpret_cast<const MNN::PRelu *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_PriorBox: {
      auto ptr = reinterpret_cast<const MNN::PriorBox *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Proposal: {
      auto ptr = reinterpret_cast<const MNN::Proposal *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedAvgPool: {
      auto ptr = reinterpret_cast<const MNN::QuantizedAvgPool *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedBiasAdd: {
      auto ptr = reinterpret_cast<const MNN::QuantizedBiasAdd *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedConcat: {
      auto ptr = reinterpret_cast<const MNN::QuantizedConcat *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedLogistic: {
      auto ptr = reinterpret_cast<const MNN::QuantizedLogistic *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedMatMul: {
      auto ptr = reinterpret_cast<const MNN::QuantizedMatMul *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedMaxPool: {
      auto ptr = reinterpret_cast<const MNN::QuantizedMaxPool *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedRelu: {
      auto ptr = reinterpret_cast<const MNN::QuantizedRelu *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedRelu6: {
      auto ptr = reinterpret_cast<const MNN::QuantizedRelu6 *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedReshape: {
      auto ptr = reinterpret_cast<const MNN::QuantizedReshape *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedSoftmax: {
      auto ptr = reinterpret_cast<const MNN::QuantizedSoftmax *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizeMaxMin: {
      auto ptr = reinterpret_cast<const MNN::QuantizeMaxMin *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizeV2: {
      auto ptr = reinterpret_cast<const MNN::QuantizeV2 *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Range: {
      auto ptr = reinterpret_cast<const MNN::Range *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Rank: {
      auto ptr = reinterpret_cast<const MNN::Rank *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_ReduceJoin: {
      auto ptr = reinterpret_cast<const MNN::ReduceJoin *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_ReductionParam: {
      auto ptr = reinterpret_cast<const MNN::ReductionParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Relu: {
      auto ptr = reinterpret_cast<const MNN::Relu *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Relu6: {
      auto ptr = reinterpret_cast<const MNN::Relu6 *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_RequantizationRange: {
      auto ptr = reinterpret_cast<const MNN::RequantizationRange *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Requantize: {
      auto ptr = reinterpret_cast<const MNN::Requantize *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Reshape: {
      auto ptr = reinterpret_cast<const MNN::Reshape *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Resize: {
      auto ptr = reinterpret_cast<const MNN::Resize *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_RoiPooling: {
      auto ptr = reinterpret_cast<const MNN::RoiPooling *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Scale: {
      auto ptr = reinterpret_cast<const MNN::Scale *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Selu: {
      auto ptr = reinterpret_cast<const MNN::Selu *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Size: {
      auto ptr = reinterpret_cast<const MNN::Size *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Slice: {
      auto ptr = reinterpret_cast<const MNN::Slice *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_SliceTf: {
      auto ptr = reinterpret_cast<const MNN::SliceTf *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_SpaceBatch: {
      auto ptr = reinterpret_cast<const MNN::SpaceBatch *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_SqueezeParam: {
      auto ptr = reinterpret_cast<const MNN::SqueezeParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_StridedSliceParam: {
      auto ptr = reinterpret_cast<const MNN::StridedSliceParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_TensorConvertInfo: {
      auto ptr = reinterpret_cast<const MNN::TensorConvertInfo *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_TfQuantizedConv2D: {
      auto ptr = reinterpret_cast<const MNN::TfQuantizedConv2D *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_TopKV2: {
      auto ptr = reinterpret_cast<const MNN::TopKV2 *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Transpose: {
      auto ptr = reinterpret_cast<const MNN::Transpose *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_UnaryOp: {
      auto ptr = reinterpret_cast<const MNN::UnaryOp *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_MomentsParam: {
      auto ptr = reinterpret_cast<const MNN::MomentsParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_RNNParam: {
      auto ptr = reinterpret_cast<const MNN::RNNParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_BatchMatMulParam: {
      auto ptr = reinterpret_cast<const MNN::BatchMatMulParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_QuantizedFloatParam: {
      auto ptr = reinterpret_cast<const MNN::QuantizedFloatParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_DepthSpaceParam: {
      auto ptr = reinterpret_cast<const MNN::DepthSpaceParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_EltwiseInt8: {
      auto ptr = reinterpret_cast<const MNN::EltwiseInt8 *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_ReverseSequenceParam: {
      auto ptr = reinterpret_cast<const MNN::ReverseSequenceParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Extra: {
      auto ptr = reinterpret_cast<const MNN::Extra *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Pool3D: {
      auto ptr = reinterpret_cast<const MNN::Pool3D *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_Convolution3D: {
      auto ptr = reinterpret_cast<const MNN::Convolution3D *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_ELU: {
      auto ptr = reinterpret_cast<const MNN::ELU *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_DetectionPostProcessParam: {
      auto ptr = reinterpret_cast<const MNN::DetectionPostProcessParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_OneHotParam: {
      auto ptr = reinterpret_cast<const MNN::OneHotParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_PadParam: {
      auto ptr = reinterpret_cast<const MNN::PadParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_WhileParam: {
      auto ptr = reinterpret_cast<const MNN::WhileParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_IfParam: {
      auto ptr = reinterpret_cast<const MNN::IfParam *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_RandomUniform: {
      auto ptr = reinterpret_cast<const MNN::RandomUniform *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_LayerNorm: {
      auto ptr = reinterpret_cast<const MNN::LayerNorm *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_TensorArray: {
      auto ptr = reinterpret_cast<const MNN::TensorArray *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_LSTMBlockCell: {
      auto ptr = reinterpret_cast<const MNN::LSTMBlockCell *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case OpParameter_GridSample: {
      auto ptr = reinterpret_cast<const MNN::GridSample *>(obj);
      return verifier.VerifyTable(ptr);
    }
    default: return true;
  }
}

inline bool VerifyOpParameterVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types) {
  if (!values || !types) return !values && !types;
  if (values->size() != types->size()) return false;
  for (flatbuffers::uoffset_t i = 0; i < values->size(); ++i) {
    if (!VerifyOpParameter(
        verifier,  values->Get(i), types->GetEnum<OpParameter>(i))) {
      return false;
    }
  }
  return true;
}

inline void *OpParameterUnion::UnPack(const void *obj, OpParameter type, const flatbuffers::resolver_function_t *resolver) {
  switch (type) {
    case OpParameter_QuantizedAdd: {
      auto ptr = reinterpret_cast<const MNN::QuantizedAdd *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_ArgMax: {
      auto ptr = reinterpret_cast<const MNN::ArgMax *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_AsString: {
      auto ptr = reinterpret_cast<const MNN::AsString *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Axis: {
      auto ptr = reinterpret_cast<const MNN::Axis *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_BatchNorm: {
      auto ptr = reinterpret_cast<const MNN::BatchNorm *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_BinaryOp: {
      auto ptr = reinterpret_cast<const MNN::BinaryOp *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Blob: {
      auto ptr = reinterpret_cast<const MNN::Blob *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_CastParam: {
      auto ptr = reinterpret_cast<const MNN::CastParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Convolution2D: {
      auto ptr = reinterpret_cast<const MNN::Convolution2D *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Crop: {
      auto ptr = reinterpret_cast<const MNN::Crop *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_CropAndResize: {
      auto ptr = reinterpret_cast<const MNN::CropAndResize *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Dequantize: {
      auto ptr = reinterpret_cast<const MNN::Dequantize *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_DetectionOutput: {
      auto ptr = reinterpret_cast<const MNN::DetectionOutput *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Eltwise: {
      auto ptr = reinterpret_cast<const MNN::Eltwise *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_ExpandDims: {
      auto ptr = reinterpret_cast<const MNN::ExpandDims *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Fill: {
      auto ptr = reinterpret_cast<const MNN::Fill *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Flatten: {
      auto ptr = reinterpret_cast<const MNN::Flatten *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Gather: {
      auto ptr = reinterpret_cast<const MNN::Gather *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_GatherV2: {
      auto ptr = reinterpret_cast<const MNN::GatherV2 *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_InnerProduct: {
      auto ptr = reinterpret_cast<const MNN::InnerProduct *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Input: {
      auto ptr = reinterpret_cast<const MNN::Input *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Interp: {
      auto ptr = reinterpret_cast<const MNN::Interp *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_LRN: {
      auto ptr = reinterpret_cast<const MNN::LRN *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_LSTM: {
      auto ptr = reinterpret_cast<const MNN::LSTM *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_MatMul: {
      auto ptr = reinterpret_cast<const MNN::MatMul *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_NonMaxSuppressionV2: {
      auto ptr = reinterpret_cast<const MNN::NonMaxSuppressionV2 *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Normalize: {
      auto ptr = reinterpret_cast<const MNN::Normalize *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_PackParam: {
      auto ptr = reinterpret_cast<const MNN::PackParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Permute: {
      auto ptr = reinterpret_cast<const MNN::Permute *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Plugin: {
      auto ptr = reinterpret_cast<const MNN::Plugin *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Pool: {
      auto ptr = reinterpret_cast<const MNN::Pool *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_PRelu: {
      auto ptr = reinterpret_cast<const MNN::PRelu *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_PriorBox: {
      auto ptr = reinterpret_cast<const MNN::PriorBox *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Proposal: {
      auto ptr = reinterpret_cast<const MNN::Proposal *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedAvgPool: {
      auto ptr = reinterpret_cast<const MNN::QuantizedAvgPool *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedBiasAdd: {
      auto ptr = reinterpret_cast<const MNN::QuantizedBiasAdd *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedConcat: {
      auto ptr = reinterpret_cast<const MNN::QuantizedConcat *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedLogistic: {
      auto ptr = reinterpret_cast<const MNN::QuantizedLogistic *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedMatMul: {
      auto ptr = reinterpret_cast<const MNN::QuantizedMatMul *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedMaxPool: {
      auto ptr = reinterpret_cast<const MNN::QuantizedMaxPool *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedRelu: {
      auto ptr = reinterpret_cast<const MNN::QuantizedRelu *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedRelu6: {
      auto ptr = reinterpret_cast<const MNN::QuantizedRelu6 *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedReshape: {
      auto ptr = reinterpret_cast<const MNN::QuantizedReshape *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedSoftmax: {
      auto ptr = reinterpret_cast<const MNN::QuantizedSoftmax *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizeMaxMin: {
      auto ptr = reinterpret_cast<const MNN::QuantizeMaxMin *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizeV2: {
      auto ptr = reinterpret_cast<const MNN::QuantizeV2 *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Range: {
      auto ptr = reinterpret_cast<const MNN::Range *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Rank: {
      auto ptr = reinterpret_cast<const MNN::Rank *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_ReduceJoin: {
      auto ptr = reinterpret_cast<const MNN::ReduceJoin *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_ReductionParam: {
      auto ptr = reinterpret_cast<const MNN::ReductionParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Relu: {
      auto ptr = reinterpret_cast<const MNN::Relu *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Relu6: {
      auto ptr = reinterpret_cast<const MNN::Relu6 *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_RequantizationRange: {
      auto ptr = reinterpret_cast<const MNN::RequantizationRange *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Requantize: {
      auto ptr = reinterpret_cast<const MNN::Requantize *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Reshape: {
      auto ptr = reinterpret_cast<const MNN::Reshape *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Resize: {
      auto ptr = reinterpret_cast<const MNN::Resize *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_RoiPooling: {
      auto ptr = reinterpret_cast<const MNN::RoiPooling *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Scale: {
      auto ptr = reinterpret_cast<const MNN::Scale *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Selu: {
      auto ptr = reinterpret_cast<const MNN::Selu *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Size: {
      auto ptr = reinterpret_cast<const MNN::Size *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Slice: {
      auto ptr = reinterpret_cast<const MNN::Slice *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_SliceTf: {
      auto ptr = reinterpret_cast<const MNN::SliceTf *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_SpaceBatch: {
      auto ptr = reinterpret_cast<const MNN::SpaceBatch *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_SqueezeParam: {
      auto ptr = reinterpret_cast<const MNN::SqueezeParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_StridedSliceParam: {
      auto ptr = reinterpret_cast<const MNN::StridedSliceParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_TensorConvertInfo: {
      auto ptr = reinterpret_cast<const MNN::TensorConvertInfo *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_TfQuantizedConv2D: {
      auto ptr = reinterpret_cast<const MNN::TfQuantizedConv2D *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_TopKV2: {
      auto ptr = reinterpret_cast<const MNN::TopKV2 *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Transpose: {
      auto ptr = reinterpret_cast<const MNN::Transpose *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_UnaryOp: {
      auto ptr = reinterpret_cast<const MNN::UnaryOp *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_MomentsParam: {
      auto ptr = reinterpret_cast<const MNN::MomentsParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_RNNParam: {
      auto ptr = reinterpret_cast<const MNN::RNNParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_BatchMatMulParam: {
      auto ptr = reinterpret_cast<const MNN::BatchMatMulParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_QuantizedFloatParam: {
      auto ptr = reinterpret_cast<const MNN::QuantizedFloatParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_DepthSpaceParam: {
      auto ptr = reinterpret_cast<const MNN::DepthSpaceParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_EltwiseInt8: {
      auto ptr = reinterpret_cast<const MNN::EltwiseInt8 *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_ReverseSequenceParam: {
      auto ptr = reinterpret_cast<const MNN::ReverseSequenceParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Extra: {
      auto ptr = reinterpret_cast<const MNN::Extra *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Pool3D: {
      auto ptr = reinterpret_cast<const MNN::Pool3D *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_Convolution3D: {
      auto ptr = reinterpret_cast<const MNN::Convolution3D *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_ELU: {
      auto ptr = reinterpret_cast<const MNN::ELU *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_DetectionPostProcessParam: {
      auto ptr = reinterpret_cast<const MNN::DetectionPostProcessParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_OneHotParam: {
      auto ptr = reinterpret_cast<const MNN::OneHotParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_PadParam: {
      auto ptr = reinterpret_cast<const MNN::PadParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_WhileParam: {
      auto ptr = reinterpret_cast<const MNN::WhileParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_IfParam: {
      auto ptr = reinterpret_cast<const MNN::IfParam *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_RandomUniform: {
      auto ptr = reinterpret_cast<const MNN::RandomUniform *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_LayerNorm: {
      auto ptr = reinterpret_cast<const MNN::LayerNorm *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_TensorArray: {
      auto ptr = reinterpret_cast<const MNN::TensorArray *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_LSTMBlockCell: {
      auto ptr = reinterpret_cast<const MNN::LSTMBlockCell *>(obj);
      return ptr->UnPack(resolver);
    }
    case OpParameter_GridSample: {
      auto ptr = reinterpret_cast<const MNN::GridSample *>(obj);
      return ptr->UnPack(resolver);
    }
    default: return nullptr;
  }
}

inline flatbuffers::Offset<void> OpParameterUnion::Pack(flatbuffers::FlatBufferBuilder &_fbb, const flatbuffers::rehasher_function_t *_rehasher) const {
  switch (type) {
    case OpParameter_QuantizedAdd: {
      auto ptr = reinterpret_cast<const MNN::QuantizedAddT *>(value);
      return CreateQuantizedAdd(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_ArgMax: {
      auto ptr = reinterpret_cast<const MNN::ArgMaxT *>(value);
      return CreateArgMax(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_AsString: {
      auto ptr = reinterpret_cast<const MNN::AsStringT *>(value);
      return CreateAsString(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Axis: {
      auto ptr = reinterpret_cast<const MNN::AxisT *>(value);
      return CreateAxis(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_BatchNorm: {
      auto ptr = reinterpret_cast<const MNN::BatchNormT *>(value);
      return CreateBatchNorm(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_BinaryOp: {
      auto ptr = reinterpret_cast<const MNN::BinaryOpT *>(value);
      return CreateBinaryOp(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Blob: {
      auto ptr = reinterpret_cast<const MNN::BlobT *>(value);
      return CreateBlob(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_CastParam: {
      auto ptr = reinterpret_cast<const MNN::CastParamT *>(value);
      return CreateCastParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Convolution2D: {
      auto ptr = reinterpret_cast<const MNN::Convolution2DT *>(value);
      return CreateConvolution2D(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Crop: {
      auto ptr = reinterpret_cast<const MNN::CropT *>(value);
      return CreateCrop(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_CropAndResize: {
      auto ptr = reinterpret_cast<const MNN::CropAndResizeT *>(value);
      return CreateCropAndResize(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Dequantize: {
      auto ptr = reinterpret_cast<const MNN::DequantizeT *>(value);
      return CreateDequantize(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_DetectionOutput: {
      auto ptr = reinterpret_cast<const MNN::DetectionOutputT *>(value);
      return CreateDetectionOutput(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Eltwise: {
      auto ptr = reinterpret_cast<const MNN::EltwiseT *>(value);
      return CreateEltwise(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_ExpandDims: {
      auto ptr = reinterpret_cast<const MNN::ExpandDimsT *>(value);
      return CreateExpandDims(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Fill: {
      auto ptr = reinterpret_cast<const MNN::FillT *>(value);
      return CreateFill(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Flatten: {
      auto ptr = reinterpret_cast<const MNN::FlattenT *>(value);
      return CreateFlatten(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Gather: {
      auto ptr = reinterpret_cast<const MNN::GatherT *>(value);
      return CreateGather(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_GatherV2: {
      auto ptr = reinterpret_cast<const MNN::GatherV2T *>(value);
      return CreateGatherV2(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_InnerProduct: {
      auto ptr = reinterpret_cast<const MNN::InnerProductT *>(value);
      return CreateInnerProduct(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Input: {
      auto ptr = reinterpret_cast<const MNN::InputT *>(value);
      return CreateInput(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Interp: {
      auto ptr = reinterpret_cast<const MNN::InterpT *>(value);
      return CreateInterp(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_LRN: {
      auto ptr = reinterpret_cast<const MNN::LRNT *>(value);
      return CreateLRN(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_LSTM: {
      auto ptr = reinterpret_cast<const MNN::LSTMT *>(value);
      return CreateLSTM(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_MatMul: {
      auto ptr = reinterpret_cast<const MNN::MatMulT *>(value);
      return CreateMatMul(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_NonMaxSuppressionV2: {
      auto ptr = reinterpret_cast<const MNN::NonMaxSuppressionV2T *>(value);
      return CreateNonMaxSuppressionV2(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Normalize: {
      auto ptr = reinterpret_cast<const MNN::NormalizeT *>(value);
      return CreateNormalize(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_PackParam: {
      auto ptr = reinterpret_cast<const MNN::PackParamT *>(value);
      return CreatePackParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Permute: {
      auto ptr = reinterpret_cast<const MNN::PermuteT *>(value);
      return CreatePermute(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Plugin: {
      auto ptr = reinterpret_cast<const MNN::PluginT *>(value);
      return CreatePlugin(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Pool: {
      auto ptr = reinterpret_cast<const MNN::PoolT *>(value);
      return CreatePool(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_PRelu: {
      auto ptr = reinterpret_cast<const MNN::PReluT *>(value);
      return CreatePRelu(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_PriorBox: {
      auto ptr = reinterpret_cast<const MNN::PriorBoxT *>(value);
      return CreatePriorBox(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Proposal: {
      auto ptr = reinterpret_cast<const MNN::ProposalT *>(value);
      return CreateProposal(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedAvgPool: {
      auto ptr = reinterpret_cast<const MNN::QuantizedAvgPoolT *>(value);
      return CreateQuantizedAvgPool(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedBiasAdd: {
      auto ptr = reinterpret_cast<const MNN::QuantizedBiasAddT *>(value);
      return CreateQuantizedBiasAdd(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedConcat: {
      auto ptr = reinterpret_cast<const MNN::QuantizedConcatT *>(value);
      return CreateQuantizedConcat(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedLogistic: {
      auto ptr = reinterpret_cast<const MNN::QuantizedLogisticT *>(value);
      return CreateQuantizedLogistic(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedMatMul: {
      auto ptr = reinterpret_cast<const MNN::QuantizedMatMulT *>(value);
      return CreateQuantizedMatMul(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedMaxPool: {
      auto ptr = reinterpret_cast<const MNN::QuantizedMaxPoolT *>(value);
      return CreateQuantizedMaxPool(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedRelu: {
      auto ptr = reinterpret_cast<const MNN::QuantizedReluT *>(value);
      return CreateQuantizedRelu(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedRelu6: {
      auto ptr = reinterpret_cast<const MNN::QuantizedRelu6T *>(value);
      return CreateQuantizedRelu6(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedReshape: {
      auto ptr = reinterpret_cast<const MNN::QuantizedReshapeT *>(value);
      return CreateQuantizedReshape(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedSoftmax: {
      auto ptr = reinterpret_cast<const MNN::QuantizedSoftmaxT *>(value);
      return CreateQuantizedSoftmax(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizeMaxMin: {
      auto ptr = reinterpret_cast<const MNN::QuantizeMaxMinT *>(value);
      return CreateQuantizeMaxMin(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizeV2: {
      auto ptr = reinterpret_cast<const MNN::QuantizeV2T *>(value);
      return CreateQuantizeV2(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Range: {
      auto ptr = reinterpret_cast<const MNN::RangeT *>(value);
      return CreateRange(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Rank: {
      auto ptr = reinterpret_cast<const MNN::RankT *>(value);
      return CreateRank(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_ReduceJoin: {
      auto ptr = reinterpret_cast<const MNN::ReduceJoinT *>(value);
      return CreateReduceJoin(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_ReductionParam: {
      auto ptr = reinterpret_cast<const MNN::ReductionParamT *>(value);
      return CreateReductionParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Relu: {
      auto ptr = reinterpret_cast<const MNN::ReluT *>(value);
      return CreateRelu(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Relu6: {
      auto ptr = reinterpret_cast<const MNN::Relu6T *>(value);
      return CreateRelu6(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_RequantizationRange: {
      auto ptr = reinterpret_cast<const MNN::RequantizationRangeT *>(value);
      return CreateRequantizationRange(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Requantize: {
      auto ptr = reinterpret_cast<const MNN::RequantizeT *>(value);
      return CreateRequantize(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Reshape: {
      auto ptr = reinterpret_cast<const MNN::ReshapeT *>(value);
      return CreateReshape(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Resize: {
      auto ptr = reinterpret_cast<const MNN::ResizeT *>(value);
      return CreateResize(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_RoiPooling: {
      auto ptr = reinterpret_cast<const MNN::RoiPoolingT *>(value);
      return CreateRoiPooling(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Scale: {
      auto ptr = reinterpret_cast<const MNN::ScaleT *>(value);
      return CreateScale(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Selu: {
      auto ptr = reinterpret_cast<const MNN::SeluT *>(value);
      return CreateSelu(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Size: {
      auto ptr = reinterpret_cast<const MNN::SizeT *>(value);
      return CreateSize(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Slice: {
      auto ptr = reinterpret_cast<const MNN::SliceT *>(value);
      return CreateSlice(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_SliceTf: {
      auto ptr = reinterpret_cast<const MNN::SliceTfT *>(value);
      return CreateSliceTf(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_SpaceBatch: {
      auto ptr = reinterpret_cast<const MNN::SpaceBatchT *>(value);
      return CreateSpaceBatch(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_SqueezeParam: {
      auto ptr = reinterpret_cast<const MNN::SqueezeParamT *>(value);
      return CreateSqueezeParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_StridedSliceParam: {
      auto ptr = reinterpret_cast<const MNN::StridedSliceParamT *>(value);
      return CreateStridedSliceParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_TensorConvertInfo: {
      auto ptr = reinterpret_cast<const MNN::TensorConvertInfoT *>(value);
      return CreateTensorConvertInfo(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_TfQuantizedConv2D: {
      auto ptr = reinterpret_cast<const MNN::TfQuantizedConv2DT *>(value);
      return CreateTfQuantizedConv2D(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_TopKV2: {
      auto ptr = reinterpret_cast<const MNN::TopKV2T *>(value);
      return CreateTopKV2(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Transpose: {
      auto ptr = reinterpret_cast<const MNN::TransposeT *>(value);
      return CreateTranspose(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_UnaryOp: {
      auto ptr = reinterpret_cast<const MNN::UnaryOpT *>(value);
      return CreateUnaryOp(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_MomentsParam: {
      auto ptr = reinterpret_cast<const MNN::MomentsParamT *>(value);
      return CreateMomentsParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_RNNParam: {
      auto ptr = reinterpret_cast<const MNN::RNNParamT *>(value);
      return CreateRNNParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_BatchMatMulParam: {
      auto ptr = reinterpret_cast<const MNN::BatchMatMulParamT *>(value);
      return CreateBatchMatMulParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_QuantizedFloatParam: {
      auto ptr = reinterpret_cast<const MNN::QuantizedFloatParamT *>(value);
      return CreateQuantizedFloatParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_DepthSpaceParam: {
      auto ptr = reinterpret_cast<const MNN::DepthSpaceParamT *>(value);
      return CreateDepthSpaceParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_EltwiseInt8: {
      auto ptr = reinterpret_cast<const MNN::EltwiseInt8T *>(value);
      return CreateEltwiseInt8(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_ReverseSequenceParam: {
      auto ptr = reinterpret_cast<const MNN::ReverseSequenceParamT *>(value);
      return CreateReverseSequenceParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Extra: {
      auto ptr = reinterpret_cast<const MNN::ExtraT *>(value);
      return CreateExtra(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Pool3D: {
      auto ptr = reinterpret_cast<const MNN::Pool3DT *>(value);
      return CreatePool3D(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_Convolution3D: {
      auto ptr = reinterpret_cast<const MNN::Convolution3DT *>(value);
      return CreateConvolution3D(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_ELU: {
      auto ptr = reinterpret_cast<const MNN::ELUT *>(value);
      return CreateELU(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_DetectionPostProcessParam: {
      auto ptr = reinterpret_cast<const MNN::DetectionPostProcessParamT *>(value);
      return CreateDetectionPostProcessParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_OneHotParam: {
      auto ptr = reinterpret_cast<const MNN::OneHotParamT *>(value);
      return CreateOneHotParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_PadParam: {
      auto ptr = reinterpret_cast<const MNN::PadParamT *>(value);
      return CreatePadParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_WhileParam: {
      auto ptr = reinterpret_cast<const MNN::WhileParamT *>(value);
      return CreateWhileParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_IfParam: {
      auto ptr = reinterpret_cast<const MNN::IfParamT *>(value);
      return CreateIfParam(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_RandomUniform: {
      auto ptr = reinterpret_cast<const MNN::RandomUniformT *>(value);
      return CreateRandomUniform(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_LayerNorm: {
      auto ptr = reinterpret_cast<const MNN::LayerNormT *>(value);
      return CreateLayerNorm(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_TensorArray: {
      auto ptr = reinterpret_cast<const MNN::TensorArrayT *>(value);
      return CreateTensorArray(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_LSTMBlockCell: {
      auto ptr = reinterpret_cast<const MNN::LSTMBlockCellT *>(value);
      return CreateLSTMBlockCell(_fbb, ptr, _rehasher).Union();
    }
    case OpParameter_GridSample: {
      auto ptr = reinterpret_cast<const MNN::GridSampleT *>(value);
      return CreateGridSample(_fbb, ptr, _rehasher).Union();
    }
    default: return 0;
  }
}

inline OpParameterUnion::OpParameterUnion(const OpParameterUnion &u) : type(u.type), value(nullptr) {
  switch (type) {
    case OpParameter_QuantizedAdd: {
      FLATBUFFERS_ASSERT(false);  // MNN::QuantizedAddT not copyable.
      break;
    }
    case OpParameter_ArgMax: {
      value = new MNN::ArgMaxT(*reinterpret_cast<MNN::ArgMaxT *>(u.value));
      break;
    }
    case OpParameter_AsString: {
      value = new MNN::AsStringT(*reinterpret_cast<MNN::AsStringT *>(u.value));
      break;
    }
    case OpParameter_Axis: {
      value = new MNN::AxisT(*reinterpret_cast<MNN::AxisT *>(u.value));
      break;
    }
    case OpParameter_BatchNorm: {
      value = new MNN::BatchNormT(*reinterpret_cast<MNN::BatchNormT *>(u.value));
      break;
    }
    case OpParameter_BinaryOp: {
      value = new MNN::BinaryOpT(*reinterpret_cast<MNN::BinaryOpT *>(u.value));
      break;
    }
    case OpParameter_Blob: {
      value = new MNN::BlobT(*reinterpret_cast<MNN::BlobT *>(u.value));
      break;
    }
    case OpParameter_CastParam: {
      value = new MNN::CastParamT(*reinterpret_cast<MNN::CastParamT *>(u.value));
      break;
    }
    case OpParameter_Convolution2D: {
      FLATBUFFERS_ASSERT(false);  // MNN::Convolution2DT not copyable.
      break;
    }
    case OpParameter_Crop: {
      value = new MNN::CropT(*reinterpret_cast<MNN::CropT *>(u.value));
      break;
    }
    case OpParameter_CropAndResize: {
      value = new MNN::CropAndResizeT(*reinterpret_cast<MNN::CropAndResizeT *>(u.value));
      break;
    }
    case OpParameter_Dequantize: {
      FLATBUFFERS_ASSERT(false);  // MNN::DequantizeT not copyable.
      break;
    }
    case OpParameter_DetectionOutput: {
      value = new MNN::DetectionOutputT(*reinterpret_cast<MNN::DetectionOutputT *>(u.value));
      break;
    }
    case OpParameter_Eltwise: {
      value = new MNN::EltwiseT(*reinterpret_cast<MNN::EltwiseT *>(u.value));
      break;
    }
    case OpParameter_ExpandDims: {
      value = new MNN::ExpandDimsT(*reinterpret_cast<MNN::ExpandDimsT *>(u.value));
      break;
    }
    case OpParameter_Fill: {
      value = new MNN::FillT(*reinterpret_cast<MNN::FillT *>(u.value));
      break;
    }
    case OpParameter_Flatten: {
      value = new MNN::FlattenT(*reinterpret_cast<MNN::FlattenT *>(u.value));
      break;
    }
    case OpParameter_Gather: {
      value = new MNN::GatherT(*reinterpret_cast<MNN::GatherT *>(u.value));
      break;
    }
    case OpParameter_GatherV2: {
      value = new MNN::GatherV2T(*reinterpret_cast<MNN::GatherV2T *>(u.value));
      break;
    }
    case OpParameter_InnerProduct: {
      FLATBUFFERS_ASSERT(false);  // MNN::InnerProductT not copyable.
      break;
    }
    case OpParameter_Input: {
      value = new MNN::InputT(*reinterpret_cast<MNN::InputT *>(u.value));
      break;
    }
    case OpParameter_Interp: {
      value = new MNN::InterpT(*reinterpret_cast<MNN::InterpT *>(u.value));
      break;
    }
    case OpParameter_LRN: {
      value = new MNN::LRNT(*reinterpret_cast<MNN::LRNT *>(u.value));
      break;
    }
    case OpParameter_LSTM: {
      FLATBUFFERS_ASSERT(false);  // MNN::LSTMT not copyable.
      break;
    }
    case OpParameter_MatMul: {
      value = new MNN::MatMulT(*reinterpret_cast<MNN::MatMulT *>(u.value));
      break;
    }
    case OpParameter_NonMaxSuppressionV2: {
      value = new MNN::NonMaxSuppressionV2T(*reinterpret_cast<MNN::NonMaxSuppressionV2T *>(u.value));
      break;
    }
    case OpParameter_Normalize: {
      value = new MNN::NormalizeT(*reinterpret_cast<MNN::NormalizeT *>(u.value));
      break;
    }
    case OpParameter_PackParam: {
      value = new MNN::PackParamT(*reinterpret_cast<MNN::PackParamT *>(u.value));
      break;
    }
    case OpParameter_Permute: {
      value = new MNN::PermuteT(*reinterpret_cast<MNN::PermuteT *>(u.value));
      break;
    }
    case OpParameter_Plugin: {
      FLATBUFFERS_ASSERT(false);  // MNN::PluginT not copyable.
      break;
    }
    case OpParameter_Pool: {
      value = new MNN::PoolT(*reinterpret_cast<MNN::PoolT *>(u.value));
      break;
    }
    case OpParameter_PRelu: {
      value = new MNN::PReluT(*reinterpret_cast<MNN::PReluT *>(u.value));
      break;
    }
    case OpParameter_PriorBox: {
      value = new MNN::PriorBoxT(*reinterpret_cast<MNN::PriorBoxT *>(u.value));
      break;
    }
    case OpParameter_Proposal: {
      FLATBUFFERS_ASSERT(false);  // MNN::ProposalT not copyable.
      break;
    }
    case OpParameter_QuantizedAvgPool: {
      value = new MNN::QuantizedAvgPoolT(*reinterpret_cast<MNN::QuantizedAvgPoolT *>(u.value));
      break;
    }
    case OpParameter_QuantizedBiasAdd: {
      value = new MNN::QuantizedBiasAddT(*reinterpret_cast<MNN::QuantizedBiasAddT *>(u.value));
      break;
    }
    case OpParameter_QuantizedConcat: {
      FLATBUFFERS_ASSERT(false);  // MNN::QuantizedConcatT not copyable.
      break;
    }
    case OpParameter_QuantizedLogistic: {
      FLATBUFFERS_ASSERT(false);  // MNN::QuantizedLogisticT not copyable.
      break;
    }
    case OpParameter_QuantizedMatMul: {
      value = new MNN::QuantizedMatMulT(*reinterpret_cast<MNN::QuantizedMatMulT *>(u.value));
      break;
    }
    case OpParameter_QuantizedMaxPool: {
      value = new MNN::QuantizedMaxPoolT(*reinterpret_cast<MNN::QuantizedMaxPoolT *>(u.value));
      break;
    }
    case OpParameter_QuantizedRelu: {
      value = new MNN::QuantizedReluT(*reinterpret_cast<MNN::QuantizedReluT *>(u.value));
      break;
    }
    case OpParameter_QuantizedRelu6: {
      value = new MNN::QuantizedRelu6T(*reinterpret_cast<MNN::QuantizedRelu6T *>(u.value));
      break;
    }
    case OpParameter_QuantizedReshape: {
      value = new MNN::QuantizedReshapeT(*reinterpret_cast<MNN::QuantizedReshapeT *>(u.value));
      break;
    }
    case OpParameter_QuantizedSoftmax: {
      value = new MNN::QuantizedSoftmaxT(*reinterpret_cast<MNN::QuantizedSoftmaxT *>(u.value));
      break;
    }
    case OpParameter_QuantizeMaxMin: {
      value = new MNN::QuantizeMaxMinT(*reinterpret_cast<MNN::QuantizeMaxMinT *>(u.value));
      break;
    }
    case OpParameter_QuantizeV2: {
      value = new MNN::QuantizeV2T(*reinterpret_cast<MNN::QuantizeV2T *>(u.value));
      break;
    }
    case OpParameter_Range: {
      value = new MNN::RangeT(*reinterpret_cast<MNN::RangeT *>(u.value));
      break;
    }
    case OpParameter_Rank: {
      value = new MNN::RankT(*reinterpret_cast<MNN::RankT *>(u.value));
      break;
    }
    case OpParameter_ReduceJoin: {
      value = new MNN::ReduceJoinT(*reinterpret_cast<MNN::ReduceJoinT *>(u.value));
      break;
    }
    case OpParameter_ReductionParam: {
      value = new MNN::ReductionParamT(*reinterpret_cast<MNN::ReductionParamT *>(u.value));
      break;
    }
    case OpParameter_Relu: {
      value = new MNN::ReluT(*reinterpret_cast<MNN::ReluT *>(u.value));
      break;
    }
    case OpParameter_Relu6: {
      value = new MNN::Relu6T(*reinterpret_cast<MNN::Relu6T *>(u.value));
      break;
    }
    case OpParameter_RequantizationRange: {
      value = new MNN::RequantizationRangeT(*reinterpret_cast<MNN::RequantizationRangeT *>(u.value));
      break;
    }
    case OpParameter_Requantize: {
      value = new MNN::RequantizeT(*reinterpret_cast<MNN::RequantizeT *>(u.value));
      break;
    }
    case OpParameter_Reshape: {
      value = new MNN::ReshapeT(*reinterpret_cast<MNN::ReshapeT *>(u.value));
      break;
    }
    case OpParameter_Resize: {
      value = new MNN::ResizeT(*reinterpret_cast<MNN::ResizeT *>(u.value));
      break;
    }
    case OpParameter_RoiPooling: {
      value = new MNN::RoiPoolingT(*reinterpret_cast<MNN::RoiPoolingT *>(u.value));
      break;
    }
    case OpParameter_Scale: {
      value = new MNN::ScaleT(*reinterpret_cast<MNN::ScaleT *>(u.value));
      break;
    }
    case OpParameter_Selu: {
      value = new MNN::SeluT(*reinterpret_cast<MNN::SeluT *>(u.value));
      break;
    }
    case OpParameter_Size: {
      value = new MNN::SizeT(*reinterpret_cast<MNN::SizeT *>(u.value));
      break;
    }
    case OpParameter_Slice: {
      value = new MNN::SliceT(*reinterpret_cast<MNN::SliceT *>(u.value));
      break;
    }
    case OpParameter_SliceTf: {
      value = new MNN::SliceTfT(*reinterpret_cast<MNN::SliceTfT *>(u.value));
      break;
    }
    case OpParameter_SpaceBatch: {
      FLATBUFFERS_ASSERT(false);  // MNN::SpaceBatchT not copyable.
      break;
    }
    case OpParameter_SqueezeParam: {
      value = new MNN::SqueezeParamT(*reinterpret_cast<MNN::SqueezeParamT *>(u.value));
      break;
    }
    case OpParameter_StridedSliceParam: {
      value = new MNN::StridedSliceParamT(*reinterpret_cast<MNN::StridedSliceParamT *>(u.value));
      break;
    }
    case OpParameter_TensorConvertInfo: {
      value = new MNN::TensorConvertInfoT(*reinterpret_cast<MNN::TensorConvertInfoT *>(u.value));
      break;
    }
    case OpParameter_TfQuantizedConv2D: {
      FLATBUFFERS_ASSERT(false);  // MNN::TfQuantizedConv2DT not copyable.
      break;
    }
    case OpParameter_TopKV2: {
      value = new MNN::TopKV2T(*reinterpret_cast<MNN::TopKV2T *>(u.value));
      break;
    }
    case OpParameter_Transpose: {
      value = new MNN::TransposeT(*reinterpret_cast<MNN::TransposeT *>(u.value));
      break;
    }
    case OpParameter_UnaryOp: {
      value = new MNN::UnaryOpT(*reinterpret_cast<MNN::UnaryOpT *>(u.value));
      break;
    }
    case OpParameter_MomentsParam: {
      value = new MNN::MomentsParamT(*reinterpret_cast<MNN::MomentsParamT *>(u.value));
      break;
    }
    case OpParameter_RNNParam: {
      FLATBUFFERS_ASSERT(false);  // MNN::RNNParamT not copyable.
      break;
    }
    case OpParameter_BatchMatMulParam: {
      value = new MNN::BatchMatMulParamT(*reinterpret_cast<MNN::BatchMatMulParamT *>(u.value));
      break;
    }
    case OpParameter_QuantizedFloatParam: {
      value = new MNN::QuantizedFloatParamT(*reinterpret_cast<MNN::QuantizedFloatParamT *>(u.value));
      break;
    }
    case OpParameter_DepthSpaceParam: {
      value = new MNN::DepthSpaceParamT(*reinterpret_cast<MNN::DepthSpaceParamT *>(u.value));
      break;
    }
    case OpParameter_EltwiseInt8: {
      FLATBUFFERS_ASSERT(false);  // MNN::EltwiseInt8T not copyable.
      break;
    }
    case OpParameter_ReverseSequenceParam: {
      value = new MNN::ReverseSequenceParamT(*reinterpret_cast<MNN::ReverseSequenceParamT *>(u.value));
      break;
    }
    case OpParameter_Extra: {
      FLATBUFFERS_ASSERT(false);  // MNN::ExtraT not copyable.
      break;
    }
    case OpParameter_Pool3D: {
      value = new MNN::Pool3DT(*reinterpret_cast<MNN::Pool3DT *>(u.value));
      break;
    }
    case OpParameter_Convolution3D: {
      FLATBUFFERS_ASSERT(false);  // MNN::Convolution3DT not copyable.
      break;
    }
    case OpParameter_ELU: {
      value = new MNN::ELUT(*reinterpret_cast<MNN::ELUT *>(u.value));
      break;
    }
    case OpParameter_DetectionPostProcessParam: {
      value = new MNN::DetectionPostProcessParamT(*reinterpret_cast<MNN::DetectionPostProcessParamT *>(u.value));
      break;
    }
    case OpParameter_OneHotParam: {
      value = new MNN::OneHotParamT(*reinterpret_cast<MNN::OneHotParamT *>(u.value));
      break;
    }
    case OpParameter_PadParam: {
      value = new MNN::PadParamT(*reinterpret_cast<MNN::PadParamT *>(u.value));
      break;
    }
    case OpParameter_WhileParam: {
      FLATBUFFERS_ASSERT(false);  // MNN::WhileParamT not copyable.
      break;
    }
    case OpParameter_IfParam: {
      FLATBUFFERS_ASSERT(false);  // MNN::IfParamT not copyable.
      break;
    }
    case OpParameter_RandomUniform: {
      value = new MNN::RandomUniformT(*reinterpret_cast<MNN::RandomUniformT *>(u.value));
      break;
    }
    case OpParameter_LayerNorm: {
      value = new MNN::LayerNormT(*reinterpret_cast<MNN::LayerNormT *>(u.value));
      break;
    }
    case OpParameter_TensorArray: {
      value = new MNN::TensorArrayT(*reinterpret_cast<MNN::TensorArrayT *>(u.value));
      break;
    }
    case OpParameter_LSTMBlockCell: {
      value = new MNN::LSTMBlockCellT(*reinterpret_cast<MNN::LSTMBlockCellT *>(u.value));
      break;
    }
    case OpParameter_GridSample: {
      value = new MNN::GridSampleT(*reinterpret_cast<MNN::GridSampleT *>(u.value));
      break;
    }
    default:
      break;
  }
}

inline void OpParameterUnion::Reset() {
  switch (type) {
    case OpParameter_QuantizedAdd: {
      auto ptr = reinterpret_cast<MNN::QuantizedAddT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_ArgMax: {
      auto ptr = reinterpret_cast<MNN::ArgMaxT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_AsString: {
      auto ptr = reinterpret_cast<MNN::AsStringT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Axis: {
      auto ptr = reinterpret_cast<MNN::AxisT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_BatchNorm: {
      auto ptr = reinterpret_cast<MNN::BatchNormT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_BinaryOp: {
      auto ptr = reinterpret_cast<MNN::BinaryOpT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Blob: {
      auto ptr = reinterpret_cast<MNN::BlobT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_CastParam: {
      auto ptr = reinterpret_cast<MNN::CastParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Convolution2D: {
      auto ptr = reinterpret_cast<MNN::Convolution2DT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Crop: {
      auto ptr = reinterpret_cast<MNN::CropT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_CropAndResize: {
      auto ptr = reinterpret_cast<MNN::CropAndResizeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Dequantize: {
      auto ptr = reinterpret_cast<MNN::DequantizeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_DetectionOutput: {
      auto ptr = reinterpret_cast<MNN::DetectionOutputT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Eltwise: {
      auto ptr = reinterpret_cast<MNN::EltwiseT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_ExpandDims: {
      auto ptr = reinterpret_cast<MNN::ExpandDimsT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Fill: {
      auto ptr = reinterpret_cast<MNN::FillT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Flatten: {
      auto ptr = reinterpret_cast<MNN::FlattenT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Gather: {
      auto ptr = reinterpret_cast<MNN::GatherT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_GatherV2: {
      auto ptr = reinterpret_cast<MNN::GatherV2T *>(value);
      delete ptr;
      break;
    }
    case OpParameter_InnerProduct: {
      auto ptr = reinterpret_cast<MNN::InnerProductT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Input: {
      auto ptr = reinterpret_cast<MNN::InputT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Interp: {
      auto ptr = reinterpret_cast<MNN::InterpT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_LRN: {
      auto ptr = reinterpret_cast<MNN::LRNT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_LSTM: {
      auto ptr = reinterpret_cast<MNN::LSTMT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_MatMul: {
      auto ptr = reinterpret_cast<MNN::MatMulT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_NonMaxSuppressionV2: {
      auto ptr = reinterpret_cast<MNN::NonMaxSuppressionV2T *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Normalize: {
      auto ptr = reinterpret_cast<MNN::NormalizeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_PackParam: {
      auto ptr = reinterpret_cast<MNN::PackParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Permute: {
      auto ptr = reinterpret_cast<MNN::PermuteT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Plugin: {
      auto ptr = reinterpret_cast<MNN::PluginT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Pool: {
      auto ptr = reinterpret_cast<MNN::PoolT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_PRelu: {
      auto ptr = reinterpret_cast<MNN::PReluT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_PriorBox: {
      auto ptr = reinterpret_cast<MNN::PriorBoxT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Proposal: {
      auto ptr = reinterpret_cast<MNN::ProposalT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedAvgPool: {
      auto ptr = reinterpret_cast<MNN::QuantizedAvgPoolT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedBiasAdd: {
      auto ptr = reinterpret_cast<MNN::QuantizedBiasAddT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedConcat: {
      auto ptr = reinterpret_cast<MNN::QuantizedConcatT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedLogistic: {
      auto ptr = reinterpret_cast<MNN::QuantizedLogisticT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedMatMul: {
      auto ptr = reinterpret_cast<MNN::QuantizedMatMulT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedMaxPool: {
      auto ptr = reinterpret_cast<MNN::QuantizedMaxPoolT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedRelu: {
      auto ptr = reinterpret_cast<MNN::QuantizedReluT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedRelu6: {
      auto ptr = reinterpret_cast<MNN::QuantizedRelu6T *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedReshape: {
      auto ptr = reinterpret_cast<MNN::QuantizedReshapeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedSoftmax: {
      auto ptr = reinterpret_cast<MNN::QuantizedSoftmaxT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizeMaxMin: {
      auto ptr = reinterpret_cast<MNN::QuantizeMaxMinT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizeV2: {
      auto ptr = reinterpret_cast<MNN::QuantizeV2T *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Range: {
      auto ptr = reinterpret_cast<MNN::RangeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Rank: {
      auto ptr = reinterpret_cast<MNN::RankT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_ReduceJoin: {
      auto ptr = reinterpret_cast<MNN::ReduceJoinT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_ReductionParam: {
      auto ptr = reinterpret_cast<MNN::ReductionParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Relu: {
      auto ptr = reinterpret_cast<MNN::ReluT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Relu6: {
      auto ptr = reinterpret_cast<MNN::Relu6T *>(value);
      delete ptr;
      break;
    }
    case OpParameter_RequantizationRange: {
      auto ptr = reinterpret_cast<MNN::RequantizationRangeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Requantize: {
      auto ptr = reinterpret_cast<MNN::RequantizeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Reshape: {
      auto ptr = reinterpret_cast<MNN::ReshapeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Resize: {
      auto ptr = reinterpret_cast<MNN::ResizeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_RoiPooling: {
      auto ptr = reinterpret_cast<MNN::RoiPoolingT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Scale: {
      auto ptr = reinterpret_cast<MNN::ScaleT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Selu: {
      auto ptr = reinterpret_cast<MNN::SeluT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Size: {
      auto ptr = reinterpret_cast<MNN::SizeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Slice: {
      auto ptr = reinterpret_cast<MNN::SliceT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_SliceTf: {
      auto ptr = reinterpret_cast<MNN::SliceTfT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_SpaceBatch: {
      auto ptr = reinterpret_cast<MNN::SpaceBatchT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_SqueezeParam: {
      auto ptr = reinterpret_cast<MNN::SqueezeParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_StridedSliceParam: {
      auto ptr = reinterpret_cast<MNN::StridedSliceParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_TensorConvertInfo: {
      auto ptr = reinterpret_cast<MNN::TensorConvertInfoT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_TfQuantizedConv2D: {
      auto ptr = reinterpret_cast<MNN::TfQuantizedConv2DT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_TopKV2: {
      auto ptr = reinterpret_cast<MNN::TopKV2T *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Transpose: {
      auto ptr = reinterpret_cast<MNN::TransposeT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_UnaryOp: {
      auto ptr = reinterpret_cast<MNN::UnaryOpT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_MomentsParam: {
      auto ptr = reinterpret_cast<MNN::MomentsParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_RNNParam: {
      auto ptr = reinterpret_cast<MNN::RNNParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_BatchMatMulParam: {
      auto ptr = reinterpret_cast<MNN::BatchMatMulParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_QuantizedFloatParam: {
      auto ptr = reinterpret_cast<MNN::QuantizedFloatParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_DepthSpaceParam: {
      auto ptr = reinterpret_cast<MNN::DepthSpaceParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_EltwiseInt8: {
      auto ptr = reinterpret_cast<MNN::EltwiseInt8T *>(value);
      delete ptr;
      break;
    }
    case OpParameter_ReverseSequenceParam: {
      auto ptr = reinterpret_cast<MNN::ReverseSequenceParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Extra: {
      auto ptr = reinterpret_cast<MNN::ExtraT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Pool3D: {
      auto ptr = reinterpret_cast<MNN::Pool3DT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_Convolution3D: {
      auto ptr = reinterpret_cast<MNN::Convolution3DT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_ELU: {
      auto ptr = reinterpret_cast<MNN::ELUT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_DetectionPostProcessParam: {
      auto ptr = reinterpret_cast<MNN::DetectionPostProcessParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_OneHotParam: {
      auto ptr = reinterpret_cast<MNN::OneHotParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_PadParam: {
      auto ptr = reinterpret_cast<MNN::PadParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_WhileParam: {
      auto ptr = reinterpret_cast<MNN::WhileParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_IfParam: {
      auto ptr = reinterpret_cast<MNN::IfParamT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_RandomUniform: {
      auto ptr = reinterpret_cast<MNN::RandomUniformT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_LayerNorm: {
      auto ptr = reinterpret_cast<MNN::LayerNormT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_TensorArray: {
      auto ptr = reinterpret_cast<MNN::TensorArrayT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_LSTMBlockCell: {
      auto ptr = reinterpret_cast<MNN::LSTMBlockCellT *>(value);
      delete ptr;
      break;
    }
    case OpParameter_GridSample: {
      auto ptr = reinterpret_cast<MNN::GridSampleT *>(value);
      delete ptr;
      break;
    }
    default: break;
  }
  value = nullptr;
  type = OpParameter_NONE;
}

inline const flatbuffers::TypeTable *OpTypeTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 },
    { flatbuffers::ET_INT, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::OpTypeTypeTable
  };
  static const int64_t values[] = { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 512, 513, 514, 515, 516, 517, 518, 600, 601, 603, 604 };
  static const char * const names[] = {
    "AbsVal",
    "QuantizedAdd",
    "ArgMax",
    "AsString",
    "InstanceNorm",
    "BatchToSpaceND",
    "Bias",
    "BinaryOp",
    "Bnll",
    "Cast",
    "Concat",
    "Const",
    "Convolution",
    "ConvolutionDepthwise",
    "Crop",
    "CropAndResize",
    "Cubic",
    "Deconvolution",
    "DeconvolutionDepthwise",
    "Dequantize",
    "DetectionOutput",
    "Dropout",
    "Eltwise",
    "ELU",
    "Embed",
    "Exp",
    "ExpandDims",
    "Fill",
    "Flatten",
    "FloorMod",
    "Gather",
    "GatherV2",
    "Im2Seq",
    "InnerProduct",
    "Input",
    "Interp",
    "Log",
    "LRN",
    "LSTM",
    "MatMul",
    "MVN",
    "NonMaxSuppression",
    "NonMaxSuppressionV2",
    "Normalize",
    "Pack",
    "Padding",
    "Permute",
    "Pooling",
    "Power",
    "PReLU",
    "PriorBox",
    "Proposal",
    "QuantizedAvgPool",
    "QuantizedBiasAdd",
    "QuantizedConcat",
    "QuantizedDepthwiseConv2D",
    "QuantizedLogistic",
    "QuantizedMatMul",
    "QuantizedMaxPool",
    "QuantizedRelu",
    "QuantizedRelu6",
    "QuantizedReshape",
    "QuantizedSoftmax",
    "QuantizeMaxMin",
    "QuantizeV2",
    "Range",
    "Rank",
    "ReduceJoin",
    "Reduction",
    "ReLU",
    "ReLU6",
    "RequantizationRange",
    "Requantize",
    "Reshape",
    "Resize",
    "RNN",
    "ROIPooling",
    "Scale",
    "Selu",
    "Seq2Out",
    "Shape",
    "Sigmoid",
    "Size",
    "Slice",
    "SliceTf",
    "Softmax",
    "SpaceToBatchND",
    "SpatialProduct",
    "Split",
    "SPP",
    "Squeeze",
    "StridedSlice",
    "StringJoin",
    "StringSplit",
    "StringToNumber",
    "TanH",
    "TfQuantizedConv2D",
    "Threshold",
    "Tile",
    "TopKV2",
    "Transpose",
    "UnaryOp",
    "Unpack",
    "Where",
    "Moments",
    "RNNSequenceGRU",
    "BatchMatMul",
    "Unsqueeze",
    "CosineSimilarity",
    "DepthToSpace",
    "SpaceToDepth",
    "ReverseSequence",
    "Pooling3D",
    "Convolution3D",
    "MatrixBandPart",
    "GatherND",
    "DetectionPostProcess",
    "UnravelIndex",
    "ScatterNd",
    "OneHot",
    "BroadcastTo",
    "Dilation2D",
    "Raster",
    "ConvertTensor",
    "ArgMin",
    "LinSpace",
    "RandomUniform",
    "TensorArray",
    "TensorArraySize",
    "TensorArrayRead",
    "TensorArrayWrite",
    "TensorArrayGather",
    "TensorArrayScatter",
    "TensorArraySplit",
    "TensorArrayConcat",
    "LSTMBlockCell",
    "Reverse",
    "Plugin",
    "Select",
    "ZerosLike",
    "Broastcast",
    "SetDiff1D",
    "ReluGrad",
    "Relu6Grad",
    "PoolGrad",
    "SoftmaxGrad",
    "Conv2DBackPropFilter",
    "TrainableParam",
    "BatchNorm",
    "ZeroGrad",
    "Extra",
    "ConvInt8",
    "Int8ToFloat",
    "DepthwiseConvInt8",
    "PoolInt8",
    "FloatToInt8",
    "EltwiseInt8",
    "While",
    "If",
    "LayerNorm",
    "GridSample"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_ENUM, 161, type_codes, type_refs, values, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *OpParameterTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_SEQUENCE, 0, -1 },
    { flatbuffers::ET_SEQUENCE, 0, 0 },
    { flatbuffers::ET_SEQUENCE, 0, 1 },
    { flatbuffers::ET_SEQUENCE, 0, 2 },
    { flatbuffers::ET_SEQUENCE, 0, 3 },
    { flatbuffers::ET_SEQUENCE, 0, 4 },
    { flatbuffers::ET_SEQUENCE, 0, 5 },
    { flatbuffers::ET_SEQUENCE, 0, 6 },
    { flatbuffers::ET_SEQUENCE, 0, 7 },
    { flatbuffers::ET_SEQUENCE, 0, 8 },
    { flatbuffers::ET_SEQUENCE, 0, 9 },
    { flatbuffers::ET_SEQUENCE, 0, 10 },
    { flatbuffers::ET_SEQUENCE, 0, 11 },
    { flatbuffers::ET_SEQUENCE, 0, 12 },
    { flatbuffers::ET_SEQUENCE, 0, 13 },
    { flatbuffers::ET_SEQUENCE, 0, 14 },
    { flatbuffers::ET_SEQUENCE, 0, 15 },
    { flatbuffers::ET_SEQUENCE, 0, 16 },
    { flatbuffers::ET_SEQUENCE, 0, 17 },
    { flatbuffers::ET_SEQUENCE, 0, 18 },
    { flatbuffers::ET_SEQUENCE, 0, 19 },
    { flatbuffers::ET_SEQUENCE, 0, 20 },
    { flatbuffers::ET_SEQUENCE, 0, 21 },
    { flatbuffers::ET_SEQUENCE, 0, 22 },
    { flatbuffers::ET_SEQUENCE, 0, 23 },
    { flatbuffers::ET_SEQUENCE, 0, 24 },
    { flatbuffers::ET_SEQUENCE, 0, 25 },
    { flatbuffers::ET_SEQUENCE, 0, 26 },
    { flatbuffers::ET_SEQUENCE, 0, 27 },
    { flatbuffers::ET_SEQUENCE, 0, 28 },
    { flatbuffers::ET_SEQUENCE, 0, 29 },
    { flatbuffers::ET_SEQUENCE, 0, 30 },
    { flatbuffers::ET_SEQUENCE, 0, 31 },
    { flatbuffers::ET_SEQUENCE, 0, 32 },
    { flatbuffers::ET_SEQUENCE, 0, 33 },
    { flatbuffers::ET_SEQUENCE, 0, 34 },
    { flatbuffers::ET_SEQUENCE, 0, 35 },
    { flatbuffers::ET_SEQUENCE, 0, 36 },
    { flatbuffers::ET_SEQUENCE, 0, 37 },
    { flatbuffers::ET_SEQUENCE, 0, 38 },
    { flatbuffers::ET_SEQUENCE, 0, 39 },
    { flatbuffers::ET_SEQUENCE, 0, 40 },
    { flatbuffers::ET_SEQUENCE, 0, 41 },
    { flatbuffers::ET_SEQUENCE, 0, 42 },
    { flatbuffers::ET_SEQUENCE, 0, 43 },
    { flatbuffers::ET_SEQUENCE, 0, 44 },
    { flatbuffers::ET_SEQUENCE, 0, 45 },
    { flatbuffers::ET_SEQUENCE, 0, 46 },
    { flatbuffers::ET_SEQUENCE, 0, 47 },
    { flatbuffers::ET_SEQUENCE, 0, 48 },
    { flatbuffers::ET_SEQUENCE, 0, 49 },
    { flatbuffers::ET_SEQUENCE, 0, 50 },
    { flatbuffers::ET_SEQUENCE, 0, 51 },
    { flatbuffers::ET_SEQUENCE, 0, 52 },
    { flatbuffers::ET_SEQUENCE, 0, 53 },
    { flatbuffers::ET_SEQUENCE, 0, 54 },
    { flatbuffers::ET_SEQUENCE, 0, 55 },
    { flatbuffers::ET_SEQUENCE, 0, 56 },
    { flatbuffers::ET_SEQUENCE, 0, 57 },
    { flatbuffers::ET_SEQUENCE, 0, 58 },
    { flatbuffers::ET_SEQUENCE, 0, 59 },
    { flatbuffers::ET_SEQUENCE, 0, 60 },
    { flatbuffers::ET_SEQUENCE, 0, 61 },
    { flatbuffers::ET_SEQUENCE, 0, 62 },
    { flatbuffers::ET_SEQUENCE, 0, 63 },
    { flatbuffers::ET_SEQUENCE, 0, 64 },
    { flatbuffers::ET_SEQUENCE, 0, 65 },
    { flatbuffers::ET_SEQUENCE, 0, 66 },
    { flatbuffers::ET_SEQUENCE, 0, 67 },
    { flatbuffers::ET_SEQUENCE, 0, 68 },
    { flatbuffers::ET_SEQUENCE, 0, 69 },
    { flatbuffers::ET_SEQUENCE, 0, 70 },
    { flatbuffers::ET_SEQUENCE, 0, 71 },
    { flatbuffers::ET_SEQUENCE, 0, 72 },
    { flatbuffers::ET_SEQUENCE, 0, 73 },
    { flatbuffers::ET_SEQUENCE, 0, 74 },
    { flatbuffers::ET_SEQUENCE, 0, 75 },
    { flatbuffers::ET_SEQUENCE, 0, 76 },
    { flatbuffers::ET_SEQUENCE, 0, 77 },
    { flatbuffers::ET_SEQUENCE, 0, 78 },
    { flatbuffers::ET_SEQUENCE, 0, 79 },
    { flatbuffers::ET_SEQUENCE, 0, 80 },
    { flatbuffers::ET_SEQUENCE, 0, 81 },
    { flatbuffers::ET_SEQUENCE, 0, 82 },
    { flatbuffers::ET_SEQUENCE, 0, 83 },
    { flatbuffers::ET_SEQUENCE, 0, 84 },
    { flatbuffers::ET_SEQUENCE, 0, 85 },
    { flatbuffers::ET_SEQUENCE, 0, 86 },
    { flatbuffers::ET_SEQUENCE, 0, 87 },
    { flatbuffers::ET_SEQUENCE, 0, 88 },
    { flatbuffers::ET_SEQUENCE, 0, 89 },
    { flatbuffers::ET_SEQUENCE, 0, 90 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::QuantizedAddTypeTable,
    MNN::ArgMaxTypeTable,
    MNN::AsStringTypeTable,
    MNN::AxisTypeTable,
    MNN::BatchNormTypeTable,
    MNN::BinaryOpTypeTable,
    MNN::BlobTypeTable,
    MNN::CastParamTypeTable,
    MNN::Convolution2DTypeTable,
    MNN::CropTypeTable,
    MNN::CropAndResizeTypeTable,
    MNN::DequantizeTypeTable,
    MNN::DetectionOutputTypeTable,
    MNN::EltwiseTypeTable,
    MNN::ExpandDimsTypeTable,
    MNN::FillTypeTable,
    MNN::FlattenTypeTable,
    MNN::GatherTypeTable,
    MNN::GatherV2TypeTable,
    MNN::InnerProductTypeTable,
    MNN::InputTypeTable,
    MNN::InterpTypeTable,
    MNN::LRNTypeTable,
    MNN::LSTMTypeTable,
    MNN::MatMulTypeTable,
    MNN::NonMaxSuppressionV2TypeTable,
    MNN::NormalizeTypeTable,
    MNN::PackParamTypeTable,
    MNN::PermuteTypeTable,
    MNN::PluginTypeTable,
    MNN::PoolTypeTable,
    MNN::PReluTypeTable,
    MNN::PriorBoxTypeTable,
    MNN::ProposalTypeTable,
    MNN::QuantizedAvgPoolTypeTable,
    MNN::QuantizedBiasAddTypeTable,
    MNN::QuantizedConcatTypeTable,
    MNN::QuantizedLogisticTypeTable,
    MNN::QuantizedMatMulTypeTable,
    MNN::QuantizedMaxPoolTypeTable,
    MNN::QuantizedReluTypeTable,
    MNN::QuantizedRelu6TypeTable,
    MNN::QuantizedReshapeTypeTable,
    MNN::QuantizedSoftmaxTypeTable,
    MNN::QuantizeMaxMinTypeTable,
    MNN::QuantizeV2TypeTable,
    MNN::RangeTypeTable,
    MNN::RankTypeTable,
    MNN::ReduceJoinTypeTable,
    MNN::ReductionParamTypeTable,
    MNN::ReluTypeTable,
    MNN::Relu6TypeTable,
    MNN::RequantizationRangeTypeTable,
    MNN::RequantizeTypeTable,
    MNN::ReshapeTypeTable,
    MNN::ResizeTypeTable,
    MNN::RoiPoolingTypeTable,
    MNN::ScaleTypeTable,
    MNN::SeluTypeTable,
    MNN::SizeTypeTable,
    MNN::SliceTypeTable,
    MNN::SliceTfTypeTable,
    MNN::SpaceBatchTypeTable,
    MNN::SqueezeParamTypeTable,
    MNN::StridedSliceParamTypeTable,
    MNN::TensorConvertInfoTypeTable,
    MNN::TfQuantizedConv2DTypeTable,
    MNN::TopKV2TypeTable,
    MNN::TransposeTypeTable,
    MNN::UnaryOpTypeTable,
    MNN::MomentsParamTypeTable,
    MNN::RNNParamTypeTable,
    MNN::BatchMatMulParamTypeTable,
    MNN::QuantizedFloatParamTypeTable,
    MNN::DepthSpaceParamTypeTable,
    MNN::EltwiseInt8TypeTable,
    MNN::ReverseSequenceParamTypeTable,
    MNN::ExtraTypeTable,
    MNN::Pool3DTypeTable,
    MNN::Convolution3DTypeTable,
    MNN::ELUTypeTable,
    MNN::DetectionPostProcessParamTypeTable,
    MNN::OneHotParamTypeTable,
    MNN::PadParamTypeTable,
    MNN::WhileParamTypeTable,
    MNN::IfParamTypeTable,
    MNN::RandomUniformTypeTable,
    MNN::LayerNormTypeTable,
    MNN::TensorArrayTypeTable,
    MNN::LSTMBlockCellTypeTable,
    MNN::GridSampleTypeTable
  };
  static const char * const names[] = {
    "NONE",
    "QuantizedAdd",
    "ArgMax",
    "AsString",
    "Axis",
    "BatchNorm",
    "BinaryOp",
    "Blob",
    "CastParam",
    "Convolution2D",
    "Crop",
    "CropAndResize",
    "Dequantize",
    "DetectionOutput",
    "Eltwise",
    "ExpandDims",
    "Fill",
    "Flatten",
    "Gather",
    "GatherV2",
    "InnerProduct",
    "Input",
    "Interp",
    "LRN",
    "LSTM",
    "MatMul",
    "NonMaxSuppressionV2",
    "Normalize",
    "PackParam",
    "Permute",
    "Plugin",
    "Pool",
    "PRelu",
    "PriorBox",
    "Proposal",
    "QuantizedAvgPool",
    "QuantizedBiasAdd",
    "QuantizedConcat",
    "QuantizedLogistic",
    "QuantizedMatMul",
    "QuantizedMaxPool",
    "QuantizedRelu",
    "QuantizedRelu6",
    "QuantizedReshape",
    "QuantizedSoftmax",
    "QuantizeMaxMin",
    "QuantizeV2",
    "Range",
    "Rank",
    "ReduceJoin",
    "ReductionParam",
    "Relu",
    "Relu6",
    "RequantizationRange",
    "Requantize",
    "Reshape",
    "Resize",
    "RoiPooling",
    "Scale",
    "Selu",
    "Size",
    "Slice",
    "SliceTf",
    "SpaceBatch",
    "SqueezeParam",
    "StridedSliceParam",
    "TensorConvertInfo",
    "TfQuantizedConv2D",
    "TopKV2",
    "Transpose",
    "UnaryOp",
    "MomentsParam",
    "RNNParam",
    "BatchMatMulParam",
    "QuantizedFloatParam",
    "DepthSpaceParam",
    "EltwiseInt8",
    "ReverseSequenceParam",
    "Extra",
    "Pool3D",
    "Convolution3D",
    "ELU",
    "DetectionPostProcessParam",
    "OneHotParam",
    "PadParam",
    "WhileParam",
    "IfParam",
    "RandomUniform",
    "LayerNorm",
    "TensorArray",
    "LSTMBlockCell",
    "GridSample"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_UNION, 92, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *ForwardTypeTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::ForwardTypeTypeTable
  };
  static const char * const names[] = {
    "CPU",
    "METAL",
    "OPENCL",
    "OPENGLES",
    "VULKAN"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_ENUM, 5, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *UsageTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 },
    { flatbuffers::ET_CHAR, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::UsageTypeTable
  };
  static const char * const names[] = {
    "INFERENCE",
    "TRAIN",
    "INFERENCE_STATIC"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_ENUM, 3, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *PluginTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_SEQUENCE, 1, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::AttributeTypeTable
  };
  static const char * const names[] = {
    "type",
    "attr"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 2, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *ExtraTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_CHAR, 1, -1 },
    { flatbuffers::ET_SEQUENCE, 1, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::AttributeTypeTable
  };
  static const char * const names[] = {
    "type",
    "engine",
    "info",
    "attr"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *StringVecTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_STRING, 1, -1 }
  };
  static const char * const names[] = {
    "data"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 1, type_codes, nullptr, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *WhileParamTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_SEQUENCE, 1, 0 },
    { flatbuffers::ET_STRING, 1, -1 },
    { flatbuffers::ET_SEQUENCE, 1, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::StringVecTypeTable
  };
  static const char * const names[] = {
    "cond_graph",
    "body_graph",
    "aliases_inputs",
    "aliases_outputs",
    "aliases_updates"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *IfParamTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_SEQUENCE, 1, 0 },
    { flatbuffers::ET_SEQUENCE, 1, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::StringVecTypeTable
  };
  static const char * const names[] = {
    "then_graph",
    "else_graph",
    "aliases_inputs",
    "aliases_outputs"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *OpTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 1, -1 },
    { flatbuffers::ET_UTYPE, 0, 0 },
    { flatbuffers::ET_SEQUENCE, 0, 0 },
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_INT, 1, -1 },
    { flatbuffers::ET_INT, 0, 1 },
    { flatbuffers::ET_CHAR, 0, 2 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::OpParameterTypeTable,
    MNN::OpTypeTypeTable,
    MNN::MNN_DATA_FORMATTypeTable
  };
  static const char * const names[] = {
    "inputIndexes",
    "main_type",
    "main",
    "name",
    "outputIndexes",
    "type",
    "defaultDimentionFormat"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 7, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *ViewTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_INT, 1, -1 }
  };
  static const char * const names[] = {
    "offset",
    "stride"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 2, type_codes, nullptr, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *RegionTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_SEQUENCE, 0, 0 },
    { flatbuffers::ET_SEQUENCE, 0, 0 },
    { flatbuffers::ET_INT, 1, -1 },
    { flatbuffers::ET_INT, 0, -1 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::ViewTypeTable
  };
  static const char * const names[] = {
    "src",
    "dst",
    "size",
    "origin"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 4, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *TensorDescribeTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_SEQUENCE, 0, 0 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_SEQUENCE, 1, 1 },
    { flatbuffers::ET_SEQUENCE, 0, 2 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::BlobTypeTable,
    MNN::RegionTypeTable,
    MNN::TensorQuantInfoTypeTable
  };
  static const char * const names[] = {
    "blob",
    "index",
    "name",
    "regions",
    "quantInfo"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *SubGraphProtoTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_INT, 1, -1 },
    { flatbuffers::ET_INT, 1, -1 },
    { flatbuffers::ET_STRING, 1, -1 },
    { flatbuffers::ET_SEQUENCE, 1, 0 },
    { flatbuffers::ET_SEQUENCE, 1, 1 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::OpTypeTable,
    MNN::TensorDescribeTypeTable
  };
  static const char * const names[] = {
    "name",
    "inputs",
    "outputs",
    "tensors",
    "nodes",
    "extraTensorDescribe"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 6, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *TensorQuantInfoTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_FLOAT, 0, -1 },
    { flatbuffers::ET_FLOAT, 0, -1 },
    { flatbuffers::ET_FLOAT, 0, -1 },
    { flatbuffers::ET_FLOAT, 0, -1 },
    { flatbuffers::ET_INT, 0, 0 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::DataTypeTypeTable
  };
  static const char * const names[] = {
    "scale",
    "zero",
    "min",
    "max",
    "type"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 5, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const flatbuffers::TypeTable *NetTypeTable() {
  static const flatbuffers::TypeCode type_codes[] = {
    { flatbuffers::ET_STRING, 0, -1 },
    { flatbuffers::ET_SEQUENCE, 1, 0 },
    { flatbuffers::ET_SEQUENCE, 0, 1 },
    { flatbuffers::ET_SEQUENCE, 1, 2 },
    { flatbuffers::ET_STRING, 1, -1 },
    { flatbuffers::ET_CHAR, 0, 3 },
    { flatbuffers::ET_CHAR, 0, 4 },
    { flatbuffers::ET_STRING, 1, -1 },
    { flatbuffers::ET_INT, 0, -1 },
    { flatbuffers::ET_CHAR, 0, 5 },
    { flatbuffers::ET_SEQUENCE, 1, 6 }
  };
  static const flatbuffers::TypeFunction type_refs[] = {
    MNN::TensorDescribeTypeTable,
    MNN::GpuLibraryTypeTable,
    MNN::OpTypeTable,
    MNN::ForwardTypeTypeTable,
    MNN::NetSourceTypeTable,
    MNN::UsageTypeTable,
    MNN::SubGraphProtoTypeTable
  };
  static const char * const names[] = {
    "bizCode",
    "extraTensorDescribe",
    "gpulibrary",
    "oplists",
    "outputName",
    "preferForwardType",
    "sourceType",
    "tensorName",
    "tensorNumber",
    "usage",
    "subgraphs"
  };
  static const flatbuffers::TypeTable tt = {
    flatbuffers::ST_TABLE, 11, type_codes, type_refs, nullptr, names
  };
  return &tt;
}

inline const MNN::Net *GetNet(const void *buf) {
  return flatbuffers::GetRoot<MNN::Net>(buf);
}

inline const MNN::Net *GetSizePrefixedNet(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<MNN::Net>(buf);
}

inline bool VerifyNetBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<MNN::Net>(nullptr);
}

inline bool VerifySizePrefixedNetBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<MNN::Net>(nullptr);
}

inline void FinishNetBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<MNN::Net> root) {
  fbb.Finish(root);
}

inline void FinishSizePrefixedNetBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<MNN::Net> root) {
  fbb.FinishSizePrefixed(root);
}

inline std::unique_ptr<MNN::NetT> UnPackNet(
    const void *buf,
    const flatbuffers::resolver_function_t *res = nullptr) {
  return std::unique_ptr<MNN::NetT>(GetNet(buf)->UnPack(res));
}

inline std::unique_ptr<MNN::NetT> UnPackSizePrefixedNet(
    const void *buf,
    const flatbuffers::resolver_function_t *res = nullptr) {
  return std::unique_ptr<MNN::NetT>(GetSizePrefixedNet(buf)->UnPack(res));
}

}  // namespace MNN

#endif  // FLATBUFFERS_GENERATED_MNN_MNN_H_
